{\rtf1\adeflang1025\ansi\ansicpg1252\uc1\adeff31507\deff0\stshfdbch31505\stshfloch31506\stshfhich31506\stshfbi31507\deflang1033\deflangfe2052\themelang1033\themelangfe0\themelangcs0{\fonttbl{\f0\fbidi \froman\fcharset0\fprq2{\*\panose 02020603050405020304}Times New Roman;}{\f34\fbidi \froman\fcharset0\fprq2{\*\panose 02040503050406030204}Cambria Math;}
{\f36\fbidi \fnil\fcharset134\fprq2{\*\panose 02010600030101010101}DengXian{\*\falt \'b5\'c8\'cf\'df};}{\f44\fbidi \fswiss\fcharset0\fprq2 Aptos;}{\f46\fbidi \fnil\fcharset134\fprq2{\*\panose 02010600030101010101}@DengXian;}
{\flomajor\f31500\fbidi \froman\fcharset0\fprq2{\*\panose 02020603050405020304}Times New Roman;}{\fdbmajor\f31501\fbidi \fnil\fcharset134\fprq2{\*\panose 02010600030101010101}DengXian Light{\*\falt \'b5\'c8\'cf\'df Light};}
{\fhimajor\f31502\fbidi \fswiss\fcharset0\fprq2 Aptos Display;}{\fbimajor\f31503\fbidi \froman\fcharset0\fprq2{\*\panose 02020603050405020304}Times New Roman;}{\flominor\f31504\fbidi \froman\fcharset0\fprq2{\*\panose 02020603050405020304}Times New Roman;}
{\fdbminor\f31505\fbidi \fnil\fcharset134\fprq2{\*\panose 02010600030101010101}DengXian{\*\falt \'b5\'c8\'cf\'df};}{\fhiminor\f31506\fbidi \fswiss\fcharset0\fprq2 Aptos;}
{\fbiminor\f31507\fbidi \froman\fcharset0\fprq2{\*\panose 02020603050405020304}Times New Roman;}{\f47\fbidi \froman\fcharset238\fprq2 Times New Roman CE;}{\f48\fbidi \froman\fcharset204\fprq2 Times New Roman Cyr;}
{\f50\fbidi \froman\fcharset161\fprq2 Times New Roman Greek;}{\f51\fbidi \froman\fcharset162\fprq2 Times New Roman Tur;}{\f52\fbidi \froman\fcharset177\fprq2 Times New Roman (Hebrew);}{\f53\fbidi \froman\fcharset178\fprq2 Times New Roman (Arabic);}
{\f54\fbidi \froman\fcharset186\fprq2 Times New Roman Baltic;}{\f55\fbidi \froman\fcharset163\fprq2 Times New Roman (Vietnamese);}{\f387\fbidi \froman\fcharset238\fprq2 Cambria Math CE;}{\f388\fbidi \froman\fcharset204\fprq2 Cambria Math Cyr;}
{\f390\fbidi \froman\fcharset161\fprq2 Cambria Math Greek;}{\f391\fbidi \froman\fcharset162\fprq2 Cambria Math Tur;}{\f394\fbidi \froman\fcharset186\fprq2 Cambria Math Baltic;}{\f395\fbidi \froman\fcharset163\fprq2 Cambria Math (Vietnamese);}
{\f409\fbidi \fnil\fcharset0\fprq2 DengXian Western{\*\falt \'b5\'c8\'cf\'df};}{\f407\fbidi \fnil\fcharset238\fprq2 DengXian CE{\*\falt \'b5\'c8\'cf\'df};}{\f408\fbidi \fnil\fcharset204\fprq2 DengXian Cyr{\*\falt \'b5\'c8\'cf\'df};}
{\f410\fbidi \fnil\fcharset161\fprq2 DengXian Greek{\*\falt \'b5\'c8\'cf\'df};}{\f487\fbidi \fswiss\fcharset238\fprq2 Aptos CE;}{\f488\fbidi \fswiss\fcharset204\fprq2 Aptos Cyr;}{\f490\fbidi \fswiss\fcharset161\fprq2 Aptos Greek;}
{\f491\fbidi \fswiss\fcharset162\fprq2 Aptos Tur;}{\f494\fbidi \fswiss\fcharset186\fprq2 Aptos Baltic;}{\f495\fbidi \fswiss\fcharset163\fprq2 Aptos (Vietnamese);}{\f509\fbidi \fnil\fcharset0\fprq2 @DengXian Western;}
{\f507\fbidi \fnil\fcharset238\fprq2 @DengXian CE;}{\f508\fbidi \fnil\fcharset204\fprq2 @DengXian Cyr;}{\f510\fbidi \fnil\fcharset161\fprq2 @DengXian Greek;}{\flomajor\f31508\fbidi \froman\fcharset238\fprq2 Times New Roman CE;}
{\flomajor\f31509\fbidi \froman\fcharset204\fprq2 Times New Roman Cyr;}{\flomajor\f31511\fbidi \froman\fcharset161\fprq2 Times New Roman Greek;}{\flomajor\f31512\fbidi \froman\fcharset162\fprq2 Times New Roman Tur;}
{\flomajor\f31513\fbidi \froman\fcharset177\fprq2 Times New Roman (Hebrew);}{\flomajor\f31514\fbidi \froman\fcharset178\fprq2 Times New Roman (Arabic);}{\flomajor\f31515\fbidi \froman\fcharset186\fprq2 Times New Roman Baltic;}
{\flomajor\f31516\fbidi \froman\fcharset163\fprq2 Times New Roman (Vietnamese);}{\fdbmajor\f31520\fbidi \fnil\fcharset0\fprq2 DengXian Light Western{\*\falt \'b5\'c8\'cf\'df Light};}
{\fdbmajor\f31518\fbidi \fnil\fcharset238\fprq2 DengXian Light CE{\*\falt \'b5\'c8\'cf\'df Light};}{\fdbmajor\f31519\fbidi \fnil\fcharset204\fprq2 DengXian Light Cyr{\*\falt \'b5\'c8\'cf\'df Light};}
{\fdbmajor\f31521\fbidi \fnil\fcharset161\fprq2 DengXian Light Greek{\*\falt \'b5\'c8\'cf\'df Light};}{\fhimajor\f31528\fbidi \fswiss\fcharset238\fprq2 Aptos Display CE;}{\fhimajor\f31529\fbidi \fswiss\fcharset204\fprq2 Aptos Display Cyr;}
{\fhimajor\f31531\fbidi \fswiss\fcharset161\fprq2 Aptos Display Greek;}{\fhimajor\f31532\fbidi \fswiss\fcharset162\fprq2 Aptos Display Tur;}{\fhimajor\f31535\fbidi \fswiss\fcharset186\fprq2 Aptos Display Baltic;}
{\fhimajor\f31536\fbidi \fswiss\fcharset163\fprq2 Aptos Display (Vietnamese);}{\fbimajor\f31538\fbidi \froman\fcharset238\fprq2 Times New Roman CE;}{\fbimajor\f31539\fbidi \froman\fcharset204\fprq2 Times New Roman Cyr;}
{\fbimajor\f31541\fbidi \froman\fcharset161\fprq2 Times New Roman Greek;}{\fbimajor\f31542\fbidi \froman\fcharset162\fprq2 Times New Roman Tur;}{\fbimajor\f31543\fbidi \froman\fcharset177\fprq2 Times New Roman (Hebrew);}
{\fbimajor\f31544\fbidi \froman\fcharset178\fprq2 Times New Roman (Arabic);}{\fbimajor\f31545\fbidi \froman\fcharset186\fprq2 Times New Roman Baltic;}{\fbimajor\f31546\fbidi \froman\fcharset163\fprq2 Times New Roman (Vietnamese);}
{\flominor\f31548\fbidi \froman\fcharset238\fprq2 Times New Roman CE;}{\flominor\f31549\fbidi \froman\fcharset204\fprq2 Times New Roman Cyr;}{\flominor\f31551\fbidi \froman\fcharset161\fprq2 Times New Roman Greek;}
{\flominor\f31552\fbidi \froman\fcharset162\fprq2 Times New Roman Tur;}{\flominor\f31553\fbidi \froman\fcharset177\fprq2 Times New Roman (Hebrew);}{\flominor\f31554\fbidi \froman\fcharset178\fprq2 Times New Roman (Arabic);}
{\flominor\f31555\fbidi \froman\fcharset186\fprq2 Times New Roman Baltic;}{\flominor\f31556\fbidi \froman\fcharset163\fprq2 Times New Roman (Vietnamese);}{\fdbminor\f31560\fbidi \fnil\fcharset0\fprq2 DengXian Western{\*\falt \'b5\'c8\'cf\'df};}
{\fdbminor\f31558\fbidi \fnil\fcharset238\fprq2 DengXian CE{\*\falt \'b5\'c8\'cf\'df};}{\fdbminor\f31559\fbidi \fnil\fcharset204\fprq2 DengXian Cyr{\*\falt \'b5\'c8\'cf\'df};}
{\fdbminor\f31561\fbidi \fnil\fcharset161\fprq2 DengXian Greek{\*\falt \'b5\'c8\'cf\'df};}{\fhiminor\f31568\fbidi \fswiss\fcharset238\fprq2 Aptos CE;}{\fhiminor\f31569\fbidi \fswiss\fcharset204\fprq2 Aptos Cyr;}
{\fhiminor\f31571\fbidi \fswiss\fcharset161\fprq2 Aptos Greek;}{\fhiminor\f31572\fbidi \fswiss\fcharset162\fprq2 Aptos Tur;}{\fhiminor\f31575\fbidi \fswiss\fcharset186\fprq2 Aptos Baltic;}
{\fhiminor\f31576\fbidi \fswiss\fcharset163\fprq2 Aptos (Vietnamese);}{\fbiminor\f31578\fbidi \froman\fcharset238\fprq2 Times New Roman CE;}{\fbiminor\f31579\fbidi \froman\fcharset204\fprq2 Times New Roman Cyr;}
{\fbiminor\f31581\fbidi \froman\fcharset161\fprq2 Times New Roman Greek;}{\fbiminor\f31582\fbidi \froman\fcharset162\fprq2 Times New Roman Tur;}{\fbiminor\f31583\fbidi \froman\fcharset177\fprq2 Times New Roman (Hebrew);}
{\fbiminor\f31584\fbidi \froman\fcharset178\fprq2 Times New Roman (Arabic);}{\fbiminor\f31585\fbidi \froman\fcharset186\fprq2 Times New Roman Baltic;}{\fbiminor\f31586\fbidi \froman\fcharset163\fprq2 Times New Roman (Vietnamese);}}
{\colortbl;\red0\green0\blue0;\red0\green0\blue255;\red0\green255\blue255;\red0\green255\blue0;\red255\green0\blue255;\red255\green0\blue0;\red255\green255\blue0;\red255\green255\blue255;\red0\green0\blue128;\red0\green128\blue128;\red0\green128\blue0;
\red128\green0\blue128;\red128\green0\blue0;\red128\green128\blue0;\red128\green128\blue128;\red192\green192\blue192;\red0\green0\blue0;\red0\green0\blue0;}{\*\defchp \fs24\kerning2\loch\af31506\hich\af31506\dbch\af31505 }{\*\defpap 
\ql \li0\ri0\sa160\sl278\slmult1\widctlpar\wrapdefault\aspalpha\aspnum\faauto\adjustright\rin0\lin0\itap0 }\noqfpromote {\stylesheet{\ql \li0\ri0\sa160\sl278\slmult1\widctlpar\wrapdefault\aspalpha\aspnum\faauto\adjustright\rin0\lin0\itap0 \rtlch\fcs1 
\af31507\afs24\alang1025 \ltrch\fcs0 \fs24\lang1033\langfe2052\kerning2\loch\f31506\hich\af31506\dbch\af31505\cgrid\langnp1033\langfenp2052 \snext0 \sqformat \spriority0 Normal;}{\*\cs10 \additive \ssemihidden \sunhideused \spriority1 
Default Paragraph Font;}{\*\ts11\tsrowd\trftsWidthB3\trpaddl108\trpaddr108\trpaddfl3\trpaddft3\trpaddfb3\trpaddfr3\trcbpat1\trcfpat1\tblind0\tblindtype3\tsvertalt\tsbrdrt\tsbrdrl\tsbrdrb\tsbrdrr\tsbrdrdgl\tsbrdrdgr\tsbrdrh\tsbrdrv 
\ql \li0\ri0\sa160\sl278\slmult1\widctlpar\wrapdefault\aspalpha\aspnum\faauto\adjustright\rin0\lin0\itap0 \rtlch\fcs1 \af31507\afs24\alang1025 \ltrch\fcs0 
\fs24\lang1033\langfe2052\kerning2\loch\f31506\hich\af31506\dbch\af31505\cgrid\langnp1033\langfenp2052 \snext11 \ssemihidden \sunhideused Normal Table;}}{\*\rsidtbl \rsid14429948\rsid16209942}{\mmathPr\mmathFont34\mbrkBin0\mbrkBinSub0\msmallFrac0
\mdispDef1\mlMargin0\mrMargin0\mdefJc1\mwrapIndent1440\mintLim0\mnaryLim1}{\info{\operator Jinyu Rao}{\creatim\yr2024\mo4\dy27\hr13\min46}{\revtim\yr2024\mo4\dy27\hr13\min46}{\version2}{\edmins0}{\nofpages36}{\nofwords7801}{\nofchars44467}
{\nofcharsws52164}{\vern93}}{\*\xmlnstbl {\xmlns1 http://schemas.microsoft.com/office/word/2003/wordml}}\paperw12240\paperh15840\margl1440\margr1440\margt1440\margb1440\gutter0\ltrsect 
\widowctrl\ftnbj\aenddoc\trackmoves0\trackformatting1\donotembedsysfont0\relyonvml0\donotembedlingdata1\grfdocevents0\validatexml0\showplaceholdtext0\ignoremixedcontent0\saveinvalidxml0\showxmlerrors0\horzdoc\dghspace120\dgvspace120\dghorigin1701
\dgvorigin1984\dghshow0\dgvshow3\jcompress\viewkind1\viewscale130\rsidroot14429948 \fet0{\*\wgrffmtfilter 2450}\ilfomacatclnup0\ltrpar \sectd \ltrsect\linex0\sectdefaultcl\sftnbj {\*\pnseclvl1\pnucrm\pnstart1\pnindent720\pnhang {\pntxta .}}{\*\pnseclvl2
\pnucltr\pnstart1\pnindent720\pnhang {\pntxta .}}{\*\pnseclvl3\pndec\pnstart1\pnindent720\pnhang {\pntxta .}}{\*\pnseclvl4\pnlcltr\pnstart1\pnindent720\pnhang {\pntxta )}}{\*\pnseclvl5\pndec\pnstart1\pnindent720\pnhang {\pntxtb (}{\pntxta )}}{\*\pnseclvl6
\pnlcltr\pnstart1\pnindent720\pnhang {\pntxtb (}{\pntxta )}}{\*\pnseclvl7\pnlcrm\pnstart1\pnindent720\pnhang {\pntxtb (}{\pntxta )}}{\*\pnseclvl8\pnlcltr\pnstart1\pnindent720\pnhang {\pntxtb (}{\pntxta )}}{\*\pnseclvl9\pnlcrm\pnstart1\pnindent720\pnhang 
{\pntxtb (}{\pntxta )}}\pard\plain \ltrpar\ql \li0\ri0\sa160\sl278\slmult1\widctlpar\wrapdefault\aspalpha\aspnum\faauto\adjustright\rin0\lin0\itap0\pararsid14429948 \rtlch\fcs1 \af31507\afs24\alang1025 \ltrch\fcs0 
\fs24\lang1033\langfe2052\kerning2\loch\af31506\hich\af31506\dbch\af31505\cgrid\langnp1033\langfenp2052 {\rtlch\fcs1 \af31507 \ltrch\fcs0 \insrsid14429948 \hich\af31506\dbch\af31505\loch\f31506 (H:\\CondaEnv\\CNNDDIV4) PS H:\\CodeV3\\
CS598_DLH_Project-CNN_DDI\\CS598_DLH_Project-CNN_DDI> pdm run python CNN_DDI_final.py -c CNN_DDI -lf kl_divergence
\par \hich\af31506\dbch\af31505\loch\f31506 Inside an active virtualenv H:\\CondaEnv\\CNNDDIV4, reusing it.
\par \hich\af31506\dbch\af31505\loch\f31506 Set env var PDM_IGNORE_ACTIVE_VENV to ignore it.
\par \hich\af31506\dbch\af31505\loch\f31506 2024-04-27 13:09:24.654277: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cudart64_101.dll
\par \hich\af31506\dbch\af31505\loch\f31506 2024-04-27 13:09:25.744033: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library nvcuda.dll
\par \hich\af31506\dbch\af31505\loch\f31506 2024-04-27 13:09:25.764636: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
\par \hich\af31506\dbch\af31505\loch\f31506 pciBusID: 0000:01:00.0 name: NVIDIA GeForce RTX 2080 Ti compu\hich\af31506\dbch\af31505\loch\f31506 teCapability: 7.5
\par \hich\af31506\dbch\af31505\loch\f31506 coreClock: 1.545GHz coreCount: 68 deviceMemorySize: 11.00GiB deviceMemoryBandwidth: 573.69GiB/s
\par \hich\af31506\dbch\af31505\loch\f31506 2024-04-27 13:09:25.764787: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cudart64_101.dll
\par \hich\af31506\dbch\af31505\loch\f31506 2024-04-27 13:09:25.769636: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cublas64_10.dll
\par \hich\af31506\dbch\af31505\loch\f31506 2024-04-27 13:09:25.772066: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully open\hich\af31506\dbch\af31505\loch\f31506 ed dynamic library cufft64_10.dll
\par \hich\af31506\dbch\af31505\loch\f31506 2024-04-27 13:09:25.772779: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library curand64_10.dll
\par \hich\af31506\dbch\af31505\loch\f31506 2024-04-27 13:09:25.775583: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cusolver64_10.dll
\par \hich\af31506\dbch\af31505\loch\f31506 2024-04-27 13:09:25.776999: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cusparse64_10.dll
\par \hich\af31506\dbch\af31505\loch\f31506 2024-04-27 13:09:25.783074: I tensorflow/s\hich\af31506\dbch\af31505\loch\f31506 tream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cudnn64_7.dll
\par \hich\af31506\dbch\af31505\loch\f31506 2024-04-27 13:09:25.783199: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0
\par \hich\af31506\dbch\af31505\loch\f31506 Setting GPU memory limit to 10GB.
\par \hich\af31506\dbch\af31505\loch\f31506 
2024-04-27 13:09:25.783651: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2
\par \hich\af31506\dbch\af31505\loch\f31506 To enable them in \hich\af31506\dbch\af31505\loch\f31506 other operations, rebuild TensorFlow with the appropriate compiler flags.
\par \hich\af31506\dbch\af31505\loch\f31506 2024-04-27 13:09:25.791442: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x13a0bdbcbc0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
\par \hich\af31506\dbch\af31505\loch\f31506 2024-04-27 13:09:25.791606: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
\par \hich\af31506\dbch\af31505\loch\f31506 2024-04-27 13:09:25.791856: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties:
\par \hich\af31506\dbch\af31505\loch\f31506 pciBusID: 0000:01:00.0 name: NVIDIA GeForce RTX 2080 Ti computeCapability: 7.5
\par \hich\af31506\dbch\af31505\loch\f31506 coreClock: 1.545GHz coreCount: 68 deviceMemorySize: 11.00GiB deviceMemoryBandwidth: 573.69GiB/s
\par \hich\af31506\dbch\af31505\loch\f31506 2024-04-27 13:09:25.791963: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cudart64_101.dll
\par \hich\af31506\dbch\af31505\loch\f31506 2024-04-27 13:09:25.792052: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cublas64_10.dll
\par \hich\af31506\dbch\af31505\loch\f31506 2024-04-27 13:09:25.792122: I tensorflow/stream_\hich\af31506\dbch\af31505\loch\f31506 executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cufft64_10.dll
\par \hich\af31506\dbch\af31505\loch\f31506 2024-04-27 13:09:25.792180: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library curand64_10.dll
\par \hich\af31506\dbch\af31505\loch\f31506 2024-04-27 13:09:25.792285: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cusolver64_10.dll
\par \hich\af31506\dbch\af31505\loch\f31506 2024-04-27 13:09:25.792372: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library\hich\af31506\dbch\af31505\loch\f31506  cusparse64_10.dll
\par \hich\af31506\dbch\af31505\loch\f31506 2024-04-27 13:09:25.792465: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cudnn64_7.dll
\par \hich\af31506\dbch\af31505\loch\f31506 2024-04-27 13:09:25.792531: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0
\par \hich\af31506\dbch\af31505\loch\f31506 2024-04-27 13:09:26.213737: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
\par \hich\af31506\dbch\af31505\loch\f31506 2024-04-27 13:09:26.213848: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0
\par \hich\af31506\dbch\af31505\loch\f31506 2024-04-27 13:09:26.213901: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N
\par \hich\af31506\dbch\af31505\loch\f31506 2024-04-27 13:09:26.214090: I tensorflow/core/common_runtime/gpu\hich\af31506\dbch\af31505\loch\f31506 
/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10240 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5)
\par \hich\af31506\dbch\af31505\loch\f31506 2024-04-27 13:09:26.216627: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x13a80e130e0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
\par \hich\af31506\dbch\af31505\loch\f31506 2024-04-27 13:09:26.216723: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecut\hich\af31506\dbch\af31505\loch\f31506 or device (0): NVIDIA GeForce RTX 2080 Ti, Compute Capability 7.5
\par \hich\af31506\dbch\af31505\loch\f31506 1 Physical GPU, 1 Logical GPU(s) with memory limit:10240
\par \hich\af31506\dbch\af31505\loch\f31506 TensorFlow version: 2.3.4
\par \hich\af31506\dbch\af31505\loch\f31506 Num GPUs Available:  1
\par \{\hich\af31506\dbch\af31505\loch\f31506 
'featureList': ['pathway', 'target', 'enzyme', 'category'], 'classifier': ['CNN_DDI'], 'NLPProcess': 'read', 'similarity_measure': 'Jaccard', 'num_folds': 5, 'num_epochs': 100, 'batch_size': 128, 'evaluate_only': False, 'save_weights': False, 'loss_fn': 
\hich\af31506\dbch\af31505\loch\f31506 'kl_divergence'\}
\par \hich\af31506\dbch\af31505\loch\f31506 pathway
\par \hich\af31506\dbch\af31505\loch\f31506 target
\par \hich\af31506\dbch\af31505\loch\f31506 enzyme
\par \hich\af31506\dbch\af31505\loch\f31506 category
\par \hich\af31506\dbch\af31505\loch\f31506 4
\par \hich\af31506\dbch\af31505\loch\f31506 running cross validation for CNN_DD\hich\af31506\dbch\af31505\loch\f31506 I
\par \hich\af31506\dbch\af31505\loch\f31506 process = 16196.75136 total = 34176.229376 available = 15647.223808 used = 18529.005568 free = 15647.223808 percent = 54.2
\par \hich\af31506\dbch\af31505\loch\f31506 No weights found or loading not requested for fold 1, feature 1. Starting training.
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 1/100
\par \hich\af31506\dbch\af31505\loch\f31506 2024-04-27 13:09:36.708669: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cublas64_10.dll
\par \hich\af31506\dbch\af31505\loch\f31506 2024-04-27 13:09:36.965301: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cudnn64_7.dll
\par \hich\af31506\dbch\af31505\loch\f31506 2024-\hich\af31506\dbch\af31505\loch\f31506 04-27 13:09:37.746598: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: Invoking GPU asm compilation is supported on Cuda non-Windows platforms only

\par \hich\af31506\dbch\af31505\loch\f31506 Relying on driver to perform ptx compilation.
\par \hich\af31506\dbch\af31505\loch\f31506 Modify $PATH to customize ptxas location.
\par \hich\af31506\dbch\af31505\loch\f31506 This message will be only logged once.
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 29ms/step - loss: 1.1756 - accuracy: 0.6549 - val_loss: 0.7440 - val_accuracy: 0.7633
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 2/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 6s 28ms/step - loss: 0.5863 -\hich\af31506\dbch\af31505\loch\f31506  accuracy: 0.8022 - val_loss: 0.6315 - val_accuracy: 0.7826
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 3/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 0.4362 - accuracy: 0.8460 - val_loss: 0.6164 - val_accuracy: 0.7922
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 4/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 0.3524 - accuracy: 0.8728 - val_loss: 0.6015 - val_accuracy: 0.7994
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 5/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 29ms/step - loss: 0.3035 - accuracy: 0.8911 - val_loss: 0.6369 - val_accuracy: 0.8051
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 6/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 6s 27ms/step - loss: 0.2700 - accurac\hich\af31506\dbch\af31505\loch\f31506 y: 0.9023 - val_loss: 0.6289 - val_accuracy: 0.8151
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 7/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 6s 26ms/step - loss: 0.2476 - accuracy: 0.9107 - val_loss: 0.6208 - val_accuracy: 0.8109
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 8/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 6s 26ms/step - loss: 0.2301 - accuracy: 0.9146 - val_loss: 0.6224 - val_accuracy: 0.8101
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 9/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 6s 27ms/step - loss: 0.2178 - accuracy: 0.9174 - val_loss: 0.6374 - val_accuracy: 0.8147
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 10/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [======\hich\af31506\dbch\af31505\loch\f31506 ========================] - 6s 27ms/step - loss: 0.2056 - accuracy: 0.9229 - val_loss: 0.6473 - val_accuracy: 0.8060
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 11/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 6s 27ms/step - loss: 0.2054 - accuracy: 0.9217 - val_loss: 0.6316 - val_accuracy: 0.8119
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 12/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 6s 27ms/step - loss: 0.1992 - accuracy: 0.9236 - val_loss: 0.6329 - val_accuracy: 0.8111
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 13/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 6s 28ms/step - loss: 0.1918 - accuracy: 0.9253 - \hich\af31506\dbch\af31505\loch\f31506 val_loss: 0.6234 - val_accuracy: 0.8120
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 14/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 6s 28ms/step - loss: 0.1873 - accuracy: 0.9262 - val_loss: 0.6706 - val_accuracy: 0.8127
\par \hich\af31506\dbch\af31505\loch\f31506 process = 18362.585088 total = 34176.229376 available = 14110.887936 used = 20065.34144 free = 14110.887936 percent = 58.7
\par \hich\af31506\dbch\af31505\loch\f31506 No weights found or loading not requested for fold 1, feature 2. Starting training.
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 1/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 1.1915 - accuracy: 0.6475 - val_loss: 0.7396\hich\af31506\dbch\af31505\loch\f31506  - val_accuracy: 0.7589
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 2/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 0.5731 - accuracy: 0.8054 - val_loss: 0.5990 - val_accuracy: 0.7972
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 3/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 0.4132 - accuracy: 0.8546 - val_loss: 0.5711 - val_accuracy: 0.8044
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 4/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 0.3317 - accuracy: 0.8819 - val_loss: 0.5805 - val_accuracy: 0.8130
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 5/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 0.2853 - accurac\hich\af31506\dbch\af31505\loch\f31506 y: 0.8978 - val_loss: 0.6055 - val_accuracy: 0.8064
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 6/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 0.2496 - accuracy: 0.9095 - val_loss: 0.5900 - val_accuracy: 0.8152
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 7/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 6s 28ms/step - loss: 0.2186 - accuracy: 0.9203 - val_loss: 0.5948 - val_accuracy: 0.8172
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 8/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 0.2066 - accuracy: 0.9263 - val_loss: 0.5818 - val_accuracy: 0.8184
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 9/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [=======\hich\af31506\dbch\af31505\loch\f31506 =======================] - 6s 28ms/step - loss: 0.1910 - accuracy: 0.9313 - val_loss: 0.6020 - val_accuracy: 0.8216
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 10/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 0.1822 - accuracy: 0.9331 - val_loss: 0.6174 - val_accuracy: 0.8194
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 11/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 6s 28ms/step - loss: 0.1767 - accuracy: 0.9350 - val_loss: 0.5958 - val_accuracy: 0.8223
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 12/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 6s 28ms/step - loss: 0.1720 - accuracy: 0.9366 - v\hich\af31506\dbch\af31505\loch\f31506 al_loss: 0.5801 - val_accuracy: 0.8234
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 13/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 0.1700 - accuracy: 0.9357 - val_loss: 0.6135 - val_accuracy: 0.8211
\par \hich\af31506\dbch\af31505\loch\f31506 process = 18596.327424 total = 34176.229376 available = 13808.49664 used = 20367.732736 free = 13808.49664 percent = 59.6
\par \hich\af31506\dbch\af31505\loch\f31506 No weights found or loading not requested for fold 1, feature 3. Starting training.
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 1/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 1.6435 - accuracy: 0.5271 - val_loss: 1.2605 -\hich\af31506\dbch\af31505\loch\f31506  val_accuracy: 0.6112
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 2/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 1.0998 - accuracy: 0.6470 - val_loss: 1.0925 - val_accuracy: 0.6413
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 3/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 0.9413 - accuracy: 0.6806 - val_loss: 1.0435 - val_accuracy: 0.6539
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 4/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 0.8568 - accuracy: 0.7041 - val_loss: 1.0408 - val_accuracy: 0.6660
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 5/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 0.7959 - accuracy: 0.7199 - val_loss: 1.0578 - val_accuracy: 0.6557
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 6/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 0.7529 - accurac\hich\af31506\dbch\af31505\loch\f31506 y: 0.7335 - val_loss: 1.0569 - val_accuracy: 0.6552
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 7/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 0.7243 - accuracy: 0.7425 - val_loss: 1.0835 - val_accuracy: 0.6630
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 8/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 0.6938 - accuracy: 0.7485 - val_loss: 1.0628 - val_accuracy: 0.6631
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 9/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 0.6758 - accuracy: 0.7543 - val_loss: 1.0746 - val_accuracy: 0.6544
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 10/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [======\hich\af31506\dbch\af31505\loch\f31506 ========================] - 7s 28ms/step - loss: 0.6648 - accuracy: 0.7554 - val_loss: 1.0631 - val_accuracy: 0.6584
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 11/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 0.6474 - accuracy: 0.7626 - val_loss: 1.1217 - val_accuracy: 0.6560
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 12/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 6s 28ms/step - loss: 0.6412 - accuracy: 0.7649 - val_loss: 1.1597 - val_accuracy: 0.6512
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 13/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 0.6292 - accuracy: 0.7669 - \hich\af31506\dbch\af31505\loch\f31506 val_loss: 1.1352 - val_accuracy: 0.6484
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 14/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 0.6185 - accuracy: 0.7723 - val_loss: 1.1124 - val_accuracy: 0.6579
\par \hich\af31506\dbch\af31505\loch\f31506 process = 18795.008 total = 34176.229376 available = 13680.570368 used = 20495.659008 free = 13680.570368 percent = 60.0
\par \hich\af31506\dbch\af31505\loch\f31506 No weights found or loading not requested for fold 1, feature 4. Starting training.
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 1/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 29ms/step - loss: 1.0259 - accuracy: 0.7023 - val_loss: 0.5795 -\hich\af31506\dbch\af31505\loch\f31506  val_accuracy: 0.8183
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 2/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 29ms/step - loss: 0.4057 - accuracy: 0.8621 - val_loss: 0.4362 - val_accuracy: 0.8611
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 3/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 29ms/step - loss: 0.2536 - accuracy: 0.9130 - val_loss: 0.4266 - val_accuracy: 0.8698
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 4/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 0.1737 - accuracy: 0.9409 - val_loss: 0.4570 - val_accuracy: 0.8776
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 5/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 0.1258 - accurac\hich\af31506\dbch\af31505\loch\f31506 y: 0.9571 - val_loss: 0.4808 - val_accuracy: 0.8836
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 6/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 0.1020 - accuracy: 0.9655 - val_loss: 0.4696 - val_accuracy: 0.8762
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 7/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 0.0795 - accuracy: 0.9743 - val_loss: 0.5063 - val_accuracy: 0.8847
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 8/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 0.0606 - accuracy: 0.9809 - val_loss: 0.5717 - val_accuracy: 0.8823
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 9/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [=======\hich\af31506\dbch\af31505\loch\f31506 =======================] - 6s 28ms/step - loss: 0.0615 - accuracy: 0.9813 - val_loss: 0.5549 - val_accuracy: 0.8813
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 10/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 0.0470 - accuracy: 0.9851 - val_loss: 0.6237 - val_accuracy: 0.8805
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 11/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 0.0443 - accuracy: 0.9863 - val_loss: 0.6029 - val_accuracy: 0.8849
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 12/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 29ms/step - loss: 0.0391 - accuracy: 0.9884 - v\hich\af31506\dbch\af31505\loch\f31506 al_loss: 0.6419 - val_accuracy: 0.8849
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 13/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 29ms/step - loss: 0.0440 - accuracy: 0.9875 - val_loss: 0.5875 - val_accuracy: 0.8847
\par \hich\af31506\dbch\af31505\loch\f31506 process = 18241.45408 total = 34176.229376 available = 14086.668288 used = 20089.561088 free = 14086.668288 percent = 58.8
\par \hich\af31506\dbch\af31505\loch\f31506 No weights found or loading not requested for fold 2, feature 1. Starting training.
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 1/100
\par \hich\af31506\dbch\af31505\loch\f31506   1/233 [..............................] - ETA: 0s - loss: 4.1733 - accuracy: 0.0000e+00WARNING:tensorflow:Ca\hich\af31506\dbch\af31505\loch\f31506 
llbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0090s vs `on_train_batch_end` time: 0.0140s). Check your callbacks.
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 29ms/step - loss: 1.1486 - accuracy: 0.6597 - val_loss: 0.7557 - val_accuracy: 0.7488
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 2/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 0.5752 - accuracy: 0.8047 - val_loss: 0.6194 - val_accuracy: 0.7895
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 3/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 0.4361 - accuracy: 0.8463 - val_loss: 0.6129 - val_accuracy: 0.7929
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 4/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 0.3589 - accuracy: 0.8697 - val_loss: 0.6008 - val_accuracy: 0.8049
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 5/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 0.3052 - accurac\hich\af31506\dbch\af31505\loch\f31506 y: 0.8906 - val_loss: 0.6245 - val_accuracy: 0.7968
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 6/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 0.2689 - accuracy: 0.9005 - val_loss: 0.6191 - val_accuracy: 0.8017
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 7/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 0.2454 - accuracy: 0.9105 - val_loss: 0.6241 - val_accuracy: 0.8039
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 8/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 0.2284 - accuracy: 0.9148 - val_loss: 0.6186 - val_accuracy: 0.8068
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 9/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [=======\hich\af31506\dbch\af31505\loch\f31506 =======================] - 7s 28ms/step - loss: 0.2161 - accuracy: 0.9198 - val_loss: 0.6168 - val_accuracy: 0.8055
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 10/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 0.2075 - accuracy: 0.9212 - val_loss: 0.6369 - val_accuracy: 0.8029
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 11/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 0.1965 - accuracy: 0.9252 - val_loss: 0.6160 - val_accuracy: 0.8077
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 12/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 0.1974 - accuracy: 0.9241 - v\hich\af31506\dbch\af31505\loch\f31506 al_loss: 0.6309 - val_accuracy: 0.8099
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 13/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 0.1878 - accuracy: 0.9263 - val_loss: 0.6678 - val_accuracy: 0.8010
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 14/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 0.1883 - accuracy: 0.9262 - val_loss: 0.6560 - val_accuracy: 0.8079
\par \hich\af31506\dbch\af31505\loch\f31506 process = 18456.354816 total = 34176.229376 available = 13940.809728 used = 20235.419648 free = 13940.809728 percent = 59.2
\par \hich\af31506\dbch\af31505\loch\f31506 No weights found or loading not requested for fold 2, featu\hich\af31506\dbch\af31505\loch\f31506 re 2. Starting training.
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 1/100
\par \hich\af31506\dbch\af31505\loch\f31506 
  1/233 [..............................] - ETA: 0s - loss: 4.1723 - accuracy: 0.0781WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0090s vs `on_train_batch_end` time: 0.0140s). Check your callbac
\hich\af31506\dbch\af31505\loch\f31506 ks.
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 1.1019 - accuracy: 0.6722 - val_loss: 0.7273 - val_accuracy: 0.7643
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 2/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 0.5543 - accuracy: 0.8116 - val_loss: 0.6209 - val_accuracy: 0.7950
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 3/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 0.4083 - accuracy: 0.8566 - val_loss: 0.5839 - val_accuracy: 0.8028
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 4/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 0.3291 - accurac\hich\af31506\dbch\af31505\loch\f31506 y: 0.8822 - val_loss: 0.5768 - val_accuracy: 0.8089
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 5/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 0.2761 - accuracy: 0.9013 - val_loss: 0.6048 - val_accuracy: 0.8127
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 6/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 0.2452 - accuracy: 0.9120 - val_loss: 0.6340 - val_accuracy: 0.8096
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 7/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 0.2183 - accuracy: 0.9233 - val_loss: 0.6525 - val_accuracy: 0.8119
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 8/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [=======\hich\af31506\dbch\af31505\loch\f31506 =======================] - 7s 28ms/step - loss: 0.2077 - accuracy: 0.9250 - val_loss: 0.6422 - val_accuracy: 0.8158
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 9/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 0.1922 - accuracy: 0.9296 - val_loss: 0.6310 - val_accuracy: 0.8134
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 10/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 0.1836 - accuracy: 0.9326 - val_loss: 0.6512 - val_accuracy: 0.8193
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 11/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 0.1794 - accuracy: 0.9342 - va\hich\af31506\dbch\af31505\loch\f31506 l_loss: 0.6675 - val_accuracy: 0.8162
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 12/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 0.1739 - accuracy: 0.9359 - val_loss: 0.6459 - val_accuracy: 0.8148
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 13/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 0.1683 - accuracy: 0.9369 - val_loss: 0.5977 - val_accuracy: 0.8205
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 14/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 0.1649 - accuracy: 0.9382 - val_loss: 0.6235 - val_accuracy: 0.8185
\par \hich\af31506\dbch\af31505\loch\f31506 process = 18637.627392 total = 34176.22\hich\af31506\dbch\af31505\loch\f31506 9376 available = 14059.778048 used = 20116.451328 free = 14059.778048 percent = 58.9
\par \hich\af31506\dbch\af31505\loch\f31506 No weights found or loading not requested for fold 2, feature 3. Starting training.
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 1/100
\par \hich\af31506\dbch\af31505\loch\f31506 
  1/233 [..............................] - ETA: 0s - loss: 4.1718 - accuracy: 0.0156WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0090s vs `on_train_batch_end` time: 0.0139s). Check your callbac
\hich\af31506\dbch\af31505\loch\f31506 ks.
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 1.6110 - accuracy: 0.5298 - val_loss: 1.2442 - val_accuracy: 0.6199
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 2/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 1.0826 - accuracy: 0.6463 - val_loss: 1.1030 \hich\af31506\dbch\af31505\loch\f31506 - val_accuracy: 0.6444
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 3/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 0.9347 - accuracy: 0.6833 - val_loss: 1.0624 - val_accuracy: 0.6565
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 4/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 6s 28ms/step - loss: 0.8474 - accuracy: 0.7068 - val_loss: 1.0472 - val_accuracy: 0.6566
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 5/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 0.7925 - accuracy: 0.7203 - val_loss: 1.0697 - val_accuracy: 0.6551
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 6/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s\hich\af31506\dbch\af31505\loch\f31506  28ms/step - loss: 0.7539 - accuracy: 0.7287 - val_loss: 1.0728 - val_accuracy: 0.6588
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 7/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 0.7191 - accuracy: 0.7417 - val_loss: 1.0653 - val_accuracy: 0.6551
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 8/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 6s 28ms/step - loss: 0.6931 - accuracy: 0.7481 - val_loss: 1.0894 - val_accuracy: 0.6566
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 9/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 0.6739 - accuracy: 0.7564 - val_loss: 1.0903 - val_accuracy: \hich\af31506\dbch\af31505\loch\f31506 0.6542
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 10/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 6s 28ms/step - loss: 0.6559 - accuracy: 0.7615 - val_loss: 1.1676 - val_accuracy: 0.6474
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 11/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 0.6465 - accuracy: 0.7644 - val_loss: 1.1415 - val_accuracy: 0.6584
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 12/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 0.6352 - accuracy: 0.7685 - val_loss: 1.0969 - val_accuracy: 0.6517
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 13/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step -\hich\af31506\dbch\af31505\loch\f31506  loss: 0.6251 - accuracy: 0.7680 - val_loss: 1.1803 - val_accuracy: 0.6509
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 14/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 0.6153 - accuracy: 0.7707 - val_loss: 1.1416 - val_accuracy: 0.6515
\par \hich\af31506\dbch\af31505\loch\f31506 process = 18724.216832 total = 34176.229376 available = 13917.569024 used = 20258.660352 free = 13917.569024 percent = 59.3
\par \hich\af31506\dbch\af31505\loch\f31506 No weights found or loading not requested for fold 2, feature 4. Starting training.
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 1/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 0.9844 - accuracy: 0.7130 - val_loss: 0.5622 - val_accuracy: 0.8203
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 2/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 6s 28ms/step - loss: 0.3982 - accuracy: 0.8692 - val_loss: 0.4646 - val_accuracy: 0.8495
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 3/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/\hich\af31506\dbch\af31505\loch\f31506 233 [==============================] - 7s 28ms/step - loss: 0.2570 - accuracy: 0.9115 - val_loss: 0.4227 - val_accuracy: 0.8692
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 4/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 6s 28ms/step - loss: 0.1804 - accuracy: 0.9370 - val_loss: 0.4302 - val_accuracy: 0.8754
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 5/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 6s 27ms/step - loss: 0.1303 - accuracy: 0.9572 - val_loss: 0.4775 - val_accuracy: 0.8733
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 6/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 0.0987 - accuracy: 0\hich\af31506\dbch\af31505\loch\f31506 .9674 - val_loss: 0.5010 - val_accuracy: 0.8750
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 7/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 0.0826 - accuracy: 0.9717 - val_loss: 0.5079 - val_accuracy: 0.8783
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 8/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 0.0679 - accuracy: 0.9777 - val_loss: 0.4881 - val_accuracy: 0.8853
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 9/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 6s 27ms/step - loss: 0.0469 - accuracy: 0.9846 - val_loss: 0.6146 - val_accuracy: 0.8751
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 10/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==========\hich\af31506\dbch\af31505\loch\f31506 ====================] - 7s 28ms/step - loss: 0.0532 - accuracy: 0.9837 - val_loss: 0.6433 - val_accuracy: 0.8846
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 11/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 0.0497 - accuracy: 0.9855 - val_loss: 0.5815 - val_accuracy: 0.8869
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 12/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 0.0357 - accuracy: 0.9886 - val_loss: 0.6433 - val_accuracy: 0.8758
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 13/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 0.0407 - accuracy: 0.9883 - val_\hich\af31506\dbch\af31505\loch\f31506 loss: 0.6535 - val_accuracy: 0.8797
\par \hich\af31506\dbch\af31505\loch\f31506 process = 18275.876864 total = 34176.229376 available = 14293.712896 used = 19882.51648 free = 14293.712896 percent = 58.2
\par \hich\af31506\dbch\af31505\loch\f31506 No weights found or loading not requested for fold 3, feature 1. Starting training.
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 1/100
\par \hich\af31506\dbch\af31505\loch\f31506 
  1/233 [..............................] - ETA: 0s - loss: 4.1734 - accuracy: 0.0078WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0090s vs `on_train_batch_end` time: 0.0140s). Check your callbac
\hich\af31506\dbch\af31505\loch\f31506 ks.
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 29ms/step - loss: 1.1532 - accuracy: 0.6571 - val_loss: 0.7343 - val_accuracy: 0.7634
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 2/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [====\hich\af31506\dbch\af31505\loch\f31506 ==========================] - 7s 29ms/step - loss: 0.5809 - accuracy: 0.8029 - val_loss: 0.6409 - val_accuracy: 0.7906
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 3/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 29ms/step - loss: 0.4331 - accuracy: 0.8436 - val_loss: 0.6329 - val_accuracy: 0.7977
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 4/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 30ms/step - loss: 0.3527 - accuracy: 0.8732 - val_loss: 0.6236 - val_accuracy: 0.7992
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 5/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 29ms/step - loss: 0.3043 - accuracy: 0.8914 - v\hich\af31506\dbch\af31505\loch\f31506 al_loss: 0.6283 - val_accuracy: 0.8002
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 6/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 30ms/step - loss: 0.2700 - accuracy: 0.9038 - val_loss: 0.6083 - val_accuracy: 0.8113
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 7/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 31ms/step - loss: 0.2459 - accuracy: 0.9114 - val_loss: 0.6441 - val_accuracy: 0.8039
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 8/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 31ms/step - loss: 0.2264 - accuracy: 0.9167 - val_loss: 0.6309 - val_accuracy: 0.8057
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 9/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [====================\hich\af31506\dbch\af31505\loch\f31506 ==========] - 7s 30ms/step - loss: 0.2159 - accuracy: 0.9195 - val_loss: 0.6568 - val_accuracy: 0.8079
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 10/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 29ms/step - loss: 0.2062 - accuracy: 0.9233 - val_loss: 0.6564 - val_accuracy: 0.8053
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 11/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 29ms/step - loss: 0.1972 - accuracy: 0.9249 - val_loss: 0.6999 - val_accuracy: 0.8054
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 12/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 0.1952 - accuracy: 0.9249 - val_loss: 0.69\hich\af31506\dbch\af31505\loch\f31506 57 - val_accuracy: 0.8043
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 13/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 6s 28ms/step - loss: 0.1876 - accuracy: 0.9282 - val_loss: 0.6951 - val_accuracy: 0.8047
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 14/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 0.1863 - accuracy: 0.9281 - val_loss: 0.6922 - val_accuracy: 0.8063
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 15/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 0.1795 - accuracy: 0.9276 - val_loss: 0.7263 - val_accuracy: 0.8045
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 16/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 0.1817 - accuracy: 0.9279 - val_loss: 0.6763 - val_accuracy: 0.8061
\par \hich\af31506\dbch\af31505\loch\f31506 process = 18490.724352 total = 34176.229376 available = 14069.559296 used = 20106.67008 fr\hich\af31506\dbch\af31505\loch\f31506 ee = 14069.559296 percent = 58.8
\par \hich\af31506\dbch\af31505\loch\f31506 No weights found or loading not requested for fold 3, feature 2. Starting training.
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 1/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 29ms/step - loss: 1.1740 - accuracy: 0.6534 - val_loss: 0.7512 - val_accuracy: 0.7611
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 2/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 0.5576 - accuracy: 0.8120 - val_loss: 0.6178 - val_accuracy: 0.7925
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 3/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 6s 28ms/step - loss: 0.4062 - accuracy: 0.8564 - val\hich\af31506\dbch\af31505\loch\f31506 _loss: 0.5841 - val_accuracy: 0.8046
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 4/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 0.3233 - accuracy: 0.8865 - val_loss: 0.5912 - val_accuracy: 0.8022
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 5/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 0.2771 - accuracy: 0.9015 - val_loss: 0.6243 - val_accuracy: 0.8071
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 6/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 6s 28ms/step - loss: 0.2385 - accuracy: 0.9136 - val_loss: 0.6407 - val_accuracy: 0.8124
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 7/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [======================\hich\af31506\dbch\af31505\loch\f31506 ========] - 6s 27ms/step - loss: 0.2143 - accuracy: 0.9238 - val_loss: 0.6600 - val_accuracy: 0.8117
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 8/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 6s 28ms/step - loss: 0.2012 - accuracy: 0.9283 - val_loss: 0.6268 - val_accuracy: 0.8106
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 9/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 0.1874 - accuracy: 0.9321 - val_loss: 0.6830 - val_accuracy: 0.8077
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 10/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 6s 28ms/step - loss: 0.1768 - accuracy: 0.9351 - val_loss: 0.6360 -\hich\af31506\dbch\af31505\loch\f31506  val_accuracy: 0.8109
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 11/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 0.1761 - accuracy: 0.9353 - val_loss: 0.6823 - val_accuracy: 0.8106
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 12/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 0.1701 - accuracy: 0.9359 - val_loss: 0.6945 - val_accuracy: 0.8130
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 13/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 0.1685 - accuracy: 0.9372 - val_loss: 0.6970 - val_accuracy: 0.8129
\par \hich\af31506\dbch\af31505\loch\f31506 process = 18671.39072 total = 34176.229376 available = 13963.870208 used = 20212.359168 free = 13963.870208 percent = 59.1
\par \hich\af31506\dbch\af31505\loch\f31506 No weights found or loading not requested for fold 3, feature 3. Starting training.
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 1/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [=======\hich\af31506\dbch\af31505\loch\f31506 =======================] - 7s 29ms/step - loss: 1.6545 - accuracy: 0.5215 - val_loss: 1.2384 - val_accuracy: 0.6154
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 2/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 29ms/step - loss: 1.0912 - accuracy: 0.6491 - val_loss: 1.0856 - val_accuracy: 0.6462
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 3/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 0.9395 - accuracy: 0.6845 - val_loss: 1.0373 - val_accuracy: 0.6662
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 4/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 0.8510 - accuracy: 0.7059 - val_\hich\af31506\dbch\af31505\loch\f31506 loss: 1.0367 - val_accuracy: 0.6618
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 5/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 0.7958 - accuracy: 0.7211 - val_loss: 1.0680 - val_accuracy: 0.6575
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 6/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 0.7546 - accuracy: 0.7319 - val_loss: 1.0419 - val_accuracy: 0.6520
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 7/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 0.7164 - accuracy: 0.7433 - val_loss: 1.0751 - val_accuracy: 0.6621
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 8/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [=======================\hich\af31506\dbch\af31505\loch\f31506 =======] - 7s 28ms/step - loss: 0.6921 - accuracy: 0.7504 - val_loss: 1.0724 - val_accuracy: 0.6572
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 9/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 0.6690 - accuracy: 0.7582 - val_loss: 1.0772 - val_accuracy: 0.6496
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 10/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 0.6554 - accuracy: 0.7606 - val_loss: 1.0926 - val_accuracy: 0.6521
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 11/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 0.6444 - accuracy: 0.7636 - val_loss: 1.1197 -\hich\af31506\dbch\af31505\loch\f31506  val_accuracy: 0.6587
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 12/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 0.6352 - accuracy: 0.7662 - val_loss: 1.1157 - val_accuracy: 0.6533
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 13/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 29ms/step - loss: 0.6244 - accuracy: 0.7699 - val_loss: 1.1212 - val_accuracy: 0.6523
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 14/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 0.6191 - accuracy: 0.7697 - val_loss: 1.0920 - val_accuracy: 0.6603
\par \hich\af31506\dbch\af31505\loch\f31506 process = 18745.708544 total = 34176.229376 available = 13813.354496 used = 20362.87488 fr\hich\af31506\dbch\af31505\loch\f31506 ee = 13813.354496 percent = 59.6
\par \hich\af31506\dbch\af31505\loch\f31506 No weights found or loading not requested for fold 3, feature 4. Starting training.
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 1/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 1.0198 - accuracy: 0.7050 - val_loss: 0.5739 - val_accuracy: 0.8121
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 2/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 0.4018 - accuracy: 0.8660 - val_loss: 0.4499 - val_accuracy: 0.8603
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 3/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 0.2537 - accuracy: 0.9154 - val\hich\af31506\dbch\af31505\loch\f31506 _loss: 0.4268 - val_accuracy: 0.8677
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 4/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 0.1764 - accuracy: 0.9390 - val_loss: 0.4392 - val_accuracy: 0.8752
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 5/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 0.1270 - accuracy: 0.9565 - val_loss: 0.4885 - val_accuracy: 0.8682
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 6/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 0.0964 - accuracy: 0.9682 - val_loss: 0.5342 - val_accuracy: 0.8745
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 7/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [======================\hich\af31506\dbch\af31505\loch\f31506 ========] - 7s 28ms/step - loss: 0.0732 - accuracy: 0.9763 - val_loss: 0.5925 - val_accuracy: 0.8682
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 8/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 0.0632 - accuracy: 0.9787 - val_loss: 0.5802 - val_accuracy: 0.8757
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 9/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 6s 27ms/step - loss: 0.0566 - accuracy: 0.9804 - val_loss: 0.6275 - val_accuracy: 0.8779
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 10/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 6s 28ms/step - loss: 0.0516 - accuracy: 0.9843 - val_loss: 0.6500 -\hich\af31506\dbch\af31505\loch\f31506  val_accuracy: 0.8757
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 11/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 6s 27ms/step - loss: 0.0448 - accuracy: 0.9859 - val_loss: 0.6100 - val_accuracy: 0.8751
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 12/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 0.0370 - accuracy: 0.9882 - val_loss: 0.6570 - val_accuracy: 0.8796
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 13/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 6s 28ms/step - loss: 0.0321 - accuracy: 0.9907 - val_loss: 0.6491 - val_accuracy: 0.8812
\par \hich\af31506\dbch\af31505\loch\f31506 process = 18284.224512 total = 34176.229376 available = 14348.222464 used = 19828.006912 free = 14348.222464 percent = 58.0
\par \hich\af31506\dbch\af31505\loch\f31506 No weights found or loading not requested for fold 4, feature 1. Starting training.
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 1/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [======\hich\af31506\dbch\af31505\loch\f31506 ========================] - 7s 29ms/step - loss: 1.1820 - accuracy: 0.6538 - val_loss: 0.7455 - val_accuracy: 0.7562
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 2/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 29ms/step - loss: 0.5759 - accuracy: 0.8019 - val_loss: 0.6198 - val_accuracy: 0.7894
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 3/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 29ms/step - loss: 0.4298 - accuracy: 0.8478 - val_loss: 0.5995 - val_accuracy: 0.8035
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 4/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 0.3522 - accuracy: 0.8748 - val\hich\af31506\dbch\af31505\loch\f31506 _loss: 0.6087 - val_accuracy: 0.8024
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 5/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 0.3036 - accuracy: 0.8907 - val_loss: 0.6038 - val_accuracy: 0.8059
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 6/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 0.2683 - accuracy: 0.9036 - val_loss: 0.6225 - val_accuracy: 0.8091
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 7/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 0.2482 - accuracy: 0.9092 - val_loss: 0.6417 - val_accuracy: 0.8105
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 8/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [======================\hich\af31506\dbch\af31505\loch\f31506 ========] - 6s 28ms/step - loss: 0.2255 - accuracy: 0.9168 - val_loss: 0.6554 - val_accuracy: 0.8070
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 9/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 6s 28ms/step - loss: 0.2146 - accuracy: 0.9206 - val_loss: 0.6554 - val_accuracy: 0.8009
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 10/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 0.2070 - accuracy: 0.9221 - val_loss: 0.6233 - val_accuracy: 0.8123
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 11/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 6s 28ms/step - loss: 0.2006 - accuracy: 0.9240 - val_loss: 0.6342 \hich\af31506\dbch\af31505\loch\f31506 - val_accuracy: 0.8142
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 12/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 6s 28ms/step - loss: 0.1933 - accuracy: 0.9260 - val_loss: 0.6200 - val_accuracy: 0.8169
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 13/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 0.1910 - accuracy: 0.9266 - val_loss: 0.6413 - val_accuracy: 0.8125
\par \hich\af31506\dbch\af31505\loch\f31506 process = 18499.039232 total = 34176.229376 available = 14048.95232 used = 20127.277056 free = 14048.95232 percent = 58.9
\par \hich\af31506\dbch\af31505\loch\f31506 No weights found or loading not requested for fold 4, feature 2. Starting training.
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 1/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [========\hich\af31506\dbch\af31505\loch\f31506 ======================] - 7s 28ms/step - loss: 1.1189 - accuracy: 0.6693 - val_loss: 0.6952 - val_accuracy: 0.7739
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 2/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 0.5516 - accuracy: 0.8111 - val_loss: 0.5914 - val_accuracy: 0.8021
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 3/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 0.4118 - accuracy: 0.8554 - val_loss: 0.5803 - val_accuracy: 0.8056
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 4/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 0.3296 - accuracy: 0.8815 - val_l\hich\af31506\dbch\af31505\loch\f31506 oss: 0.5794 - val_accuracy: 0.8092
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 5/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 0.2839 - accuracy: 0.8982 - val_loss: 0.5976 - val_accuracy: 0.8110
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 6/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 0.2535 - accuracy: 0.9095 - val_loss: 0.6079 - val_accuracy: 0.8152
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 7/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 0.2257 - accuracy: 0.9196 - val_loss: 0.6198 - val_accuracy: 0.8164
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 8/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [========================\hich\af31506\dbch\af31505\loch\f31506 ======] - 7s 28ms/step - loss: 0.2104 - accuracy: 0.9228 - val_loss: 0.5977 - val_accuracy: 0.8193
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 9/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 0.1994 - accuracy: 0.9281 - val_loss: 0.6068 - val_accuracy: 0.8238
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 10/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 0.1903 - accuracy: 0.9309 - val_loss: 0.6016 - val_accuracy: 0.8231
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 11/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 0.1818 - accuracy: 0.9331 - val_loss: 0.6447 - \hich\af31506\dbch\af31505\loch\f31506 val_accuracy: 0.8199
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 12/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 0.1743 - accuracy: 0.9340 - val_loss: 0.6106 - val_accuracy: 0.8189
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 13/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 0.1716 - accuracy: 0.9354 - val_loss: 0.6072 - val_accuracy: 0.8220
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 14/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 0.1655 - accuracy: 0.9369 - val_loss: 0.6016 - val_accuracy: 0.8254
\par \hich\af31506\dbch\af31505\loch\f31506 process = 18679.721984 total = 34176.229376 available = 13929.951232 used = 20246.278144 free = 13929.951232 percent = 59.2
\par \hich\af31506\dbch\af31505\loch\f31506 No weights found or loading not requested for fold 4, feature 3. Starting training.
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 1/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [======\hich\af31506\dbch\af31505\loch\f31506 ========================] - 7s 28ms/step - loss: 1.5917 - accuracy: 0.5378 - val_loss: 1.2338 - val_accuracy: 0.6181
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 2/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 1.0659 - accuracy: 0.6478 - val_loss: 1.1101 - val_accuracy: 0.6404
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 3/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 6s 27ms/step - loss: 0.9144 - accuracy: 0.6854 - val_loss: 1.0614 - val_accuracy: 0.6511
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 4/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 6s 28ms/step - loss: 0.8345 - accuracy: 0.7093 - val\hich\af31506\dbch\af31505\loch\f31506 _loss: 1.0820 - val_accuracy: 0.6427
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 5/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 6s 28ms/step - loss: 0.7804 - accuracy: 0.7229 - val_loss: 1.0618 - val_accuracy: 0.6495
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 6/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 6s 28ms/step - loss: 0.7399 - accuracy: 0.7345 - val_loss: 1.0675 - val_accuracy: 0.6514
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 7/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 6s 28ms/step - loss: 0.7079 - accuracy: 0.7467 - val_loss: 1.0932 - val_accuracy: 0.6458
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 8/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [======================\hich\af31506\dbch\af31505\loch\f31506 ========] - 6s 28ms/step - loss: 0.6853 - accuracy: 0.7513 - val_loss: 1.0767 - val_accuracy: 0.6527
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 9/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 6s 28ms/step - loss: 0.6657 - accuracy: 0.7575 - val_loss: 1.1322 - val_accuracy: 0.6488
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 10/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 6s 28ms/step - loss: 0.6511 - accuracy: 0.7611 - val_loss: 1.1578 - val_accuracy: 0.6538
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 11/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 6s 27ms/step - loss: 0.6349 - accuracy: 0.7649 - val_loss: 1.1227 \hich\af31506\dbch\af31505\loch\f31506 - val_accuracy: 0.6432
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 12/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 6s 27ms/step - loss: 0.6254 - accuracy: 0.7694 - val_loss: 1.1630 - val_accuracy: 0.6404
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 13/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 6s 28ms/step - loss: 0.6157 - accuracy: 0.7712 - val_loss: 1.2018 - val_accuracy: 0.6331
\par \hich\af31506\dbch\af31505\loch\f31506 process = 18754.70336 total = 34176.229376 available = 13759.008768 used = 20417.220608 free = 13759.008768 percent = 59.7
\par \hich\af31506\dbch\af31505\loch\f31506 No weights found or loading not requested for fold 4, feature 4. Starting training.
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 1/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [=======\hich\af31506\dbch\af31505\loch\f31506 =======================] - 7s 29ms/step - loss: 1.0091 - accuracy: 0.7059 - val_loss: 0.5841 - val_accuracy: 0.8141
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 2/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 0.4024 - accuracy: 0.8674 - val_loss: 0.4769 - val_accuracy: 0.8446
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 3/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 0.2600 - accuracy: 0.9108 - val_loss: 0.4260 - val_accuracy: 0.8677
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 4/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 0.1772 - accuracy: 0.9407 - val_\hich\af31506\dbch\af31505\loch\f31506 loss: 0.4294 - val_accuracy: 0.8718
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 5/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 0.1273 - accuracy: 0.9567 - val_loss: 0.4342 - val_accuracy: 0.8787
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 6/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 6s 28ms/step - loss: 0.1036 - accuracy: 0.9642 - val_loss: 0.5015 - val_accuracy: 0.8776
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 7/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 6s 28ms/step - loss: 0.0752 - accuracy: 0.9751 - val_loss: 0.5046 - val_accuracy: 0.8818
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 8/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [=======================\hich\af31506\dbch\af31505\loch\f31506 =======] - 6s 28ms/step - loss: 0.0635 - accuracy: 0.9790 - val_loss: 0.5575 - val_accuracy: 0.8779
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 9/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 6s 28ms/step - loss: 0.0629 - accuracy: 0.9794 - val_loss: 0.5093 - val_accuracy: 0.8838
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 10/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 0.0502 - accuracy: 0.9841 - val_loss: 0.5135 - val_accuracy: 0.8829
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 11/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 6s 27ms/step - loss: 0.0428 - accuracy: 0.9862 - val_loss: 0.5748 -\hich\af31506\dbch\af31505\loch\f31506  val_accuracy: 0.8821
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 12/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 6s 27ms/step - loss: 0.0366 - accuracy: 0.9880 - val_loss: 0.5877 - val_accuracy: 0.8880
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 13/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 6s 28ms/step - loss: 0.0421 - accuracy: 0.9867 - val_loss: 0.5663 - val_accuracy: 0.8886
\par \hich\af31506\dbch\af31505\loch\f31506 process = 18291.89632 total = 34176.229376 available = 14239.461376 used = 19936.768 free = 14239.461376 percent = 58.3
\par \hich\af31506\dbch\af31505\loch\f31506 No weights found or loading not requested for fold 5, feature 1. Starting training.
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 1/100
\par \hich\af31506\dbch\af31505\loch\f31506 234/234 [==============================] - 7s 28ms/step - loss: 1.1546 - accuracy: 0.6564 - val_loss: 0.7419 - val_accuracy: 0.7517
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 2/100
\par \hich\af31506\dbch\af31505\loch\f31506 234/234 [===========\hich\af31506\dbch\af31505\loch\f31506 ===================] - 7s 28ms/step - loss: 0.5924 - accuracy: 0.7976 - val_loss: 0.6013 - val_accuracy: 0.7984
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 3/100
\par \hich\af31506\dbch\af31505\loch\f31506 234/234 [==============================] - 7s 28ms/step - loss: 0.4441 - accuracy: 0.8440 - val_loss: 0.5595 - val_accuracy: 0.8132
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 4/100
\par \hich\af31506\dbch\af31505\loch\f31506 234/234 [==============================] - 7s 29ms/step - loss: 0.3634 - accuracy: 0.8700 - val_loss: 0.5593 - val_accuracy: 0.8112
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 5/100
\par \hich\af31506\dbch\af31505\loch\f31506 234/234 [==============================] - 7s 28ms/step - loss: 0.3112 - accuracy: 0.8878 - val_loss\hich\af31506\dbch\af31505\loch\f31506 : 0.5613 - val_accuracy: 0.8125
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 6/100
\par \hich\af31506\dbch\af31505\loch\f31506 234/234 [==============================] - 7s 28ms/step - loss: 0.2796 - accuracy: 0.8980 - val_loss: 0.5909 - val_accuracy: 0.8139
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 7/100
\par \hich\af31506\dbch\af31505\loch\f31506 234/234 [==============================] - 6s 27ms/step - loss: 0.2524 - accuracy: 0.9085 - val_loss: 0.5889 - val_accuracy: 0.8140
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 8/100
\par \hich\af31506\dbch\af31505\loch\f31506 234/234 [==============================] - 6s 28ms/step - loss: 0.2353 - accuracy: 0.9127 - val_loss: 0.5815 - val_accuracy: 0.8177
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 9/100
\par \hich\af31506\dbch\af31505\loch\f31506 234/234 [===========================\hich\af31506\dbch\af31505\loch\f31506 ===] - 6s 27ms/step - loss: 0.2214 - accuracy: 0.9160 - val_loss: 0.5920 - val_accuracy: 0.8202
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 10/100
\par \hich\af31506\dbch\af31505\loch\f31506 234/234 [==============================] - 6s 27ms/step - loss: 0.2141 - accuracy: 0.9190 - val_loss: 0.5969 - val_accuracy: 0.8175
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 11/100
\par \hich\af31506\dbch\af31505\loch\f31506 234/234 [==============================] - 7s 28ms/step - loss: 0.2179 - accuracy: 0.9180 - val_loss: 0.6243 - val_accuracy: 0.8194
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 12/100
\par \hich\af31506\dbch\af31505\loch\f31506 234/234 [==============================] - 6s 27ms/step - loss: 0.1985 - accuracy: 0.9248 - val_loss: 0.6096 - va\hich\af31506\dbch\af31505\loch\f31506 l_accuracy: 0.8202
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 13/100
\par \hich\af31506\dbch\af31505\loch\f31506 234/234 [==============================] - 7s 29ms/step - loss: 0.1928 - accuracy: 0.9243 - val_loss: 0.5838 - val_accuracy: 0.8225
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 14/100
\par \hich\af31506\dbch\af31505\loch\f31506 234/234 [==============================] - 7s 28ms/step - loss: 0.1905 - accuracy: 0.9250 - val_loss: 0.6187 - val_accuracy: 0.8179
\par \hich\af31506\dbch\af31505\loch\f31506 process = 18506.645504 total = 34176.229376 available = 14025.199616 used = 20151.02976 free = 14025.199616 percent = 59.0
\par \hich\af31506\dbch\af31505\loch\f31506 No weights found or loading not requested for fold 5, feature 2. Starting training.
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 1/100
\par \hich\af31506\dbch\af31505\loch\f31506 234/234 [=======\hich\af31506\dbch\af31505\loch\f31506 =======================] - 7s 29ms/step - loss: 1.1606 - accuracy: 0.6606 - val_loss: 0.6904 - val_accuracy: 0.7728
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 2/100
\par \hich\af31506\dbch\af31505\loch\f31506 234/234 [==============================] - 7s 28ms/step - loss: 0.5613 - accuracy: 0.8079 - val_loss: 0.5788 - val_accuracy: 0.8039
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 3/100
\par \hich\af31506\dbch\af31505\loch\f31506 234/234 [==============================] - 7s 28ms/step - loss: 0.4185 - accuracy: 0.8526 - val_loss: 0.5325 - val_accuracy: 0.8214
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 4/100
\par \hich\af31506\dbch\af31505\loch\f31506 234/234 [==============================] - 7s 28ms/step - loss: 0.3317 - accuracy: 0.8825 - val_\hich\af31506\dbch\af31505\loch\f31506 loss: 0.5577 - val_accuracy: 0.8127
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 5/100
\par \hich\af31506\dbch\af31505\loch\f31506 234/234 [==============================] - 7s 28ms/step - loss: 0.2785 - accuracy: 0.8995 - val_loss: 0.5674 - val_accuracy: 0.8206
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 6/100
\par \hich\af31506\dbch\af31505\loch\f31506 234/234 [==============================] - 7s 28ms/step - loss: 0.2468 - accuracy: 0.9114 - val_loss: 0.6133 - val_accuracy: 0.8159
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 7/100
\par \hich\af31506\dbch\af31505\loch\f31506 234/234 [==============================] - 7s 28ms/step - loss: 0.2241 - accuracy: 0.9187 - val_loss: 0.5805 - val_accuracy: 0.8238
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 8/100
\par \hich\af31506\dbch\af31505\loch\f31506 234/234 [=======================\hich\af31506\dbch\af31505\loch\f31506 =======] - 7s 28ms/step - loss: 0.2097 - accuracy: 0.9245 - val_loss: 0.5592 - val_accuracy: 0.8295
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 9/100
\par \hich\af31506\dbch\af31505\loch\f31506 234/234 [==============================] - 7s 28ms/step - loss: 0.1933 - accuracy: 0.9302 - val_loss: 0.5625 - val_accuracy: 0.8269
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 10/100
\par \hich\af31506\dbch\af31505\loch\f31506 234/234 [==============================] - 7s 28ms/step - loss: 0.1896 - accuracy: 0.9318 - val_loss: 0.5659 - val_accuracy: 0.8261
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 11/100
\par \hich\af31506\dbch\af31505\loch\f31506 234/234 [==============================] - 7s 28ms/step - loss: 0.1764 - accuracy: 0.9337 - val_loss: 0.5792 -\hich\af31506\dbch\af31505\loch\f31506  val_accuracy: 0.8280
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 12/100
\par \hich\af31506\dbch\af31505\loch\f31506 234/234 [==============================] - 6s 28ms/step - loss: 0.1757 - accuracy: 0.9344 - val_loss: 0.5702 - val_accuracy: 0.8277
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 13/100
\par \hich\af31506\dbch\af31505\loch\f31506 234/234 [==============================] - 6s 27ms/step - loss: 0.1727 - accuracy: 0.9345 - val_loss: 0.5714 - val_accuracy: 0.8273
\par \hich\af31506\dbch\af31505\loch\f31506 process = 18687.328256 total = 34176.229376 available = 13891.088384 used = 20285.140992 free = 13891.088384 percent = 59.4
\par \hich\af31506\dbch\af31505\loch\f31506 No weights found or loading not requested for fold 5, feature 3. Starting training.
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 1/100
\par \hich\af31506\dbch\af31505\loch\f31506 234/234 [==============================] - 7s 29ms/step - loss: 1.6171 - accuracy: 0.5300 - val_loss: 1.2098 - val_accuracy: 0.6275
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 2/100
\par \hich\af31506\dbch\af31505\loch\f31506 234/234 [=======\hich\af31506\dbch\af31505\loch\f31506 =======================] - 7s 29ms/step - loss: 1.0873 - accuracy: 0.6473 - val_loss: 1.0759 - val_accuracy: 0.6528
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 3/100
\par \hich\af31506\dbch\af31505\loch\f31506 234/234 [==============================] - 7s 28ms/step - loss: 0.9428 - accuracy: 0.6792 - val_loss: 1.0446 - val_accuracy: 0.6489
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 4/100
\par \hich\af31506\dbch\af31505\loch\f31506 234/234 [==============================] - 7s 29ms/step - loss: 0.8607 - accuracy: 0.7006 - val_loss: 0.9980 - val_accuracy: 0.6585
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 5/100
\par \hich\af31506\dbch\af31505\loch\f31506 234/234 [==============================] - 7s 28ms/step - loss: 0.7973 - accuracy: 0.7199 - val_\hich\af31506\dbch\af31505\loch\f31506 loss: 1.0186 - val_accuracy: 0.6719
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 6/100
\par \hich\af31506\dbch\af31505\loch\f31506 234/234 [==============================] - 7s 28ms/step - loss: 0.7599 - accuracy: 0.7280 - val_loss: 0.9875 - val_accuracy: 0.6735
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 7/100
\par \hich\af31506\dbch\af31505\loch\f31506 234/234 [==============================] - 7s 28ms/step - loss: 0.7225 - accuracy: 0.7406 - val_loss: 1.0273 - val_accuracy: 0.6708
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 8/100
\par \hich\af31506\dbch\af31505\loch\f31506 234/234 [==============================] - 7s 28ms/step - loss: 0.7029 - accuracy: 0.7438 - val_loss: 1.0181 - val_accuracy: 0.6677
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 9/100
\par \hich\af31506\dbch\af31505\loch\f31506 234/234 [=======================\hich\af31506\dbch\af31505\loch\f31506 =======] - 7s 28ms/step - loss: 0.6768 - accuracy: 0.7541 - val_loss: 1.0695 - val_accuracy: 0.6677
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 10/100
\par \hich\af31506\dbch\af31505\loch\f31506 234/234 [==============================] - 7s 28ms/step - loss: 0.6663 - accuracy: 0.7554 - val_loss: 1.1020 - val_accuracy: 0.6692
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 11/100
\par \hich\af31506\dbch\af31505\loch\f31506 234/234 [==============================] - 7s 28ms/step - loss: 0.6521 - accuracy: 0.7577 - val_loss: 1.0269 - val_accuracy: 0.6704
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 12/100
\par \hich\af31506\dbch\af31505\loch\f31506 234/234 [==============================] - 7s 28ms/step - loss: 0.6374 - accuracy: 0.7635 - val_loss: 1.0585 \hich\af31506\dbch\af31505\loch\f31506 - val_accuracy: 0.6648
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 13/100
\par \hich\af31506\dbch\af31505\loch\f31506 234/234 [==============================] - 7s 28ms/step - loss: 0.6303 - accuracy: 0.7638 - val_loss: 1.0276 - val_accuracy: 0.6634
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 14/100
\par \hich\af31506\dbch\af31505\loch\f31506 234/234 [==============================] - 7s 28ms/step - loss: 0.6204 - accuracy: 0.7669 - val_loss: 1.0502 - val_accuracy: 0.6568
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 15/100
\par \hich\af31506\dbch\af31505\loch\f31506 234/234 [==============================] - 6s 28ms/step - loss: 0.6222 - accuracy: 0.7684 - val_loss: 1.0606 - val_accuracy: 0.6680
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 16/100
\par \hich\af31506\dbch\af31505\loch\f31506 234/234 [==============================] - 6s 28ms/step - loss: 0.6100 - accu\hich\af31506\dbch\af31505\loch\f31506 racy: 0.7695 - val_loss: 1.0572 - val_accuracy: 0.6644
\par \hich\af31506\dbch\af31505\loch\f31506 process = 18762.510336 total = 34176.229376 available = 14048.93184 used = 20127.297536 free = 14048.93184 percent = 58.9
\par \hich\af31506\dbch\af31505\loch\f31506 No weights found or loading not requested for fold 5, feature 4. Starting training.
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 1/100
\par \hich\af31506\dbch\af31505\loch\f31506 234/234 [==============================] - 7s 28ms/step - loss: 1.0205 - accuracy: 0.7025 - val_loss: 0.5694 - val_accuracy: 0.8125
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 2/100
\par \hich\af31506\dbch\af31505\loch\f31506 234/234 [==============================] - 7s 28ms/step - loss: 0.4213 - accuracy: 0.8631 - val\hich\af31506\dbch\af31505\loch\f31506 _loss: 0.4223 - val_accuracy: 0.8567
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 3/100
\par \hich\af31506\dbch\af31505\loch\f31506 234/234 [==============================] - 6s 28ms/step - loss: 0.2681 - accuracy: 0.9103 - val_loss: 0.3871 - val_accuracy: 0.8734
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 4/100
\par \hich\af31506\dbch\af31505\loch\f31506 234/234 [==============================] - 6s 27ms/step - loss: 0.1851 - accuracy: 0.9363 - val_loss: 0.4074 - val_accuracy: 0.8727
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 5/100
\par \hich\af31506\dbch\af31505\loch\f31506 234/234 [==============================] - 6s 27ms/step - loss: 0.1343 - accuracy: 0.9532 - val_loss: 0.4571 - val_accuracy: 0.8755
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 6/100
\par \hich\af31506\dbch\af31505\loch\f31506 234/234 [======================\hich\af31506\dbch\af31505\loch\f31506 ========] - 6s 27ms/step - loss: 0.1162 - accuracy: 0.9610 - val_loss: 0.4610 - val_accuracy: 0.8806
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 7/100
\par \hich\af31506\dbch\af31505\loch\f31506 234/234 [==============================] - 6s 27ms/step - loss: 0.0807 - accuracy: 0.9725 - val_loss: 0.4678 - val_accuracy: 0.8827
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 8/100
\par \hich\af31506\dbch\af31505\loch\f31506 234/234 [==============================] - 6s 27ms/step - loss: 0.0685 - accuracy: 0.9779 - val_loss: 0.4858 - val_accuracy: 0.8797
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 9/100
\par \hich\af31506\dbch\af31505\loch\f31506 234/234 [==============================] - 6s 27ms/step - loss: 0.0698 - accuracy: 0.9794 - val_loss: 0.5221 - \hich\af31506\dbch\af31505\loch\f31506 val_accuracy: 0.8923
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 10/100
\par \hich\af31506\dbch\af31505\loch\f31506 234/234 [==============================] - 6s 27ms/step - loss: 0.0480 - accuracy: 0.9854 - val_loss: 0.5566 - val_accuracy: 0.8781
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 11/100
\par \hich\af31506\dbch\af31505\loch\f31506 234/234 [==============================] - 6s 27ms/step - loss: 0.0518 - accuracy: 0.9833 - val_loss: 0.5034 - val_accuracy: 0.8921
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 12/100
\par \hich\af31506\dbch\af31505\loch\f31506 234/234 [==============================] - 6s 27ms/step - loss: 0.0374 - accuracy: 0.9882 - val_loss: 0.5533 - val_accuracy: 0.8857
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 13/100
\par \hich\af31506\dbch\af31505\loch\f31506 234/234 [==============================] - 6s 27ms/step - loss: 0.0368 - accuracy: 0.9885 - val_loss: 0.5531 - val_accuracy: 0.8837
\par \hich\af31506\dbch\af31505\loch\f31506 H:\\CondaEnv\\CNNDDIV4\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMe\hich\af31506\dbch\af31505\loch\f31506 
tricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
\par \hich\af31506\dbch\af31505\loch\f31506   'precision', 'predicted', average, warn_for)
\par \hich\af31506\dbch\af31505\loch\f31506 H:\\CondaEnv\\CNNDDIV4\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
\par \hich\af31506\dbch\af31505\loch\f31506   'precision', 'predicted', average, warn_for)
\par \hich\af31506\dbch\af31505\loch\f31506 H:\\CondaEnv\\CNNDDIV4\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being se\hich\af31506\dbch\af31505\loch\f31506 
t to 0.0 due to no predicted samples.
\par \hich\af31506\dbch\af31505\loch\f31506   'precision', 'predicted', average, warn_for)
\par \hich\af31506\dbch\af31505\loch\f31506 H:\\CondaEnv\\CNNDDIV4\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.
\par \hich\af31506\dbch\af31505\loch\f31506   'precision', 'predicted', average, warn_for)
\par \hich\af31506\dbch\af31505\loch\f31506    Accuracy  AUPR (micro-averaged)  AUPR (macro-averaged)  AUC (micro-averaged)  AUC (macro-averaged)  ...  Precision (micro-averaged)  Precision (macro-averaged)  Recall (micro-averaged)  Recall (macro
\hich\af31506\dbch\af31505\loch\f31506 -averaged)     Time (s)
\par \hich\af31506\dbch\af31505\loch\f31506 
0  0.879965               0.937938               0.835341              0.997868              0.986549  ...                    0.879965                    0.842605                 0.879965                 0.740078  1834.386924
\par 
\par \hich\af31506\dbch\af31505\loch\f31506 [1 rows x 12 columns]
\par \hich\af31506\dbch\af31505\loch\f31506 time used for CNN_DDI: 1834.3869244
\par \hich\af31506\dbch\af31505\loch\f31506 Total time used: 1834.4020791
\par \hich\af31506\dbch\af31505\loch\f31506 done}{\rtlch\fcs1 \af31507 \ltrch\fcs0 \insrsid16209942 
\par }{\*\themedata 504b030414000600080000002100e9de0fbfff0000001c020000130000005b436f6e74656e745f54797065735d2e786d6cac91cb4ec3301045f748fc83e52d4a
9cb2400825e982c78ec7a27cc0c8992416c9d8b2a755fbf74cd25442a820166c2cd933f79e3be372bd1f07b5c3989ca74aaff2422b24eb1b475da5df374fd9ad
5689811a183c61a50f98f4babebc2837878049899a52a57be670674cb23d8e90721f90a4d2fa3802cb35762680fd800ecd7551dc18eb899138e3c943d7e503b6
b01d583deee5f99824e290b4ba3f364eac4a430883b3c092d4eca8f946c916422ecab927f52ea42b89a1cd59c254f919b0e85e6535d135a8de20f20b8c12c3b0
0c895fcf6720192de6bf3b9e89ecdbd6596cbcdd8eb28e7c365ecc4ec1ff1460f53fe813d3cc7f5b7f020000ffff0300504b030414000600080000002100a5d6
a7e7c0000000360100000b0000005f72656c732f2e72656c73848fcf6ac3300c87ef85bd83d17d51d2c31825762fa590432fa37d00e1287f68221bdb1bebdb4f
c7060abb0884a4eff7a93dfeae8bf9e194e720169aaa06c3e2433fcb68e1763dbf7f82c985a4a725085b787086a37bdbb55fbc50d1a33ccd311ba548b6309512
0f88d94fbc52ae4264d1c910d24a45db3462247fa791715fd71f989e19e0364cd3f51652d73760ae8fa8c9ffb3c330cc9e4fc17faf2ce545046e37944c69e462
a1a82fe353bd90a865aad41ed0b5b8f9d6fd010000ffff0300504b0304140006000800000021006b799616830000008a0000001c0000007468656d652f746865
6d652f7468656d654d616e616765722e786d6c0ccc4d0ac3201040e17da17790d93763bb284562b2cbaebbf600439c1a41c7a0d29fdbd7e5e38337cedf14d59b
4b0d592c9c070d8a65cd2e88b7f07c2ca71ba8da481cc52c6ce1c715e6e97818c9b48d13df49c873517d23d59085adb5dd20d6b52bd521ef2cdd5eb9246a3d8b
4757e8d3f729e245eb2b260a0238fd010000ffff0300504b03041400060008000000210094a9528694070000c7200000160000007468656d652f7468656d652f
7468656d65312e786d6cec595f8b1bc9117f0fe43b0cf32e6b66248da4c5f2a1bfdeb3776d63c90ef7d82bb566dadb333d4cb7762d8e83e07bca4b207077e421
0779cb430839c8418ebce4c3186c92cb874875cf68d42db5bc7f30c184dd7dd1b47e55fd9baaeaaa52f5fdcf5e27d4b9c039272cedb9fe3dcf75703a670b9246
3df7c56c52ebb80e17285d20ca52dc73d798bb9f3df8e52feea32311e3043b209ff223d4736321b2a37a9dcf6119f17b2cc3297cb7647982043ce6517d91a34b
d09bd07ae079613d4124759d1425a0f6e97249e6d8994995ee838df23185c75470b930a7f954aac68684c22ece7d89e06b3ea4b9738168cf857d16ec72865f0b
d7a1880bf8a2e77aeacfad3fb85f4747a51015076435b989fa2be54a81c579a0f6cca3b36a536f1c749a7ea55f01a8d8c78d3bf2bfd2a700683e87372db8e83a
fd56e8758212ab818a8f16ddddb6df30f19afec61e67bf1b0e82a6a15f810afdcd3dbc37e98e472d03af4005beb587ef7bc1a0db30f00a54e0c33d7c73dc6f07
6303af403125e9f93e3a6c773a6189ae204b468fadf06e187aed5109dfa2201aaae8925b2c592a0ec55a825eb17c020009a44890d411eb0c2fd11ca2b89f09c6
9d11e119456bd7c950ca382c7b81ef43e835bda0fa571647471869d2921730e17b4b928fc3e739c944cf7d045a5d0df2eea79fdebef9f1ed9bbfbffdfaebb76f
feea9c902816852a43ee18a5912ef7f39f7ef79fef7fedfcfb6f7ffcf99b6fed78aee3dfffe537effff1cf0fa987a3b635c5bbef7e78ffe30fef7effdb7ffdf9
1b8bf67e8ece74f88c24983b4ff0a5f39c25f082ca14267f7c96df4c621623a24bf4d388a314c95d2cfac72236d04fd688220b6e804d3bbecc21d5d8800f57af
0cc2d3385f0962d1f8384e0ce0296374c072ab151ecbbd3433cf566964df3c5fe9b8e7085dd8f61ea2d4f0f27895418e253695c3181b349f51940a14e1140b47
7ec7ce31b6bcdd178418763d25f39c71b614ce17c419206235c98c9c19d1b4153a2609f8656d2308fe366c73fad219306a7beb11be3091703610b5909f616a98
f1215a0994d854ce504275839f2011db484ed7f95cc78db9004f47983267bcc09cdb649ee6f0be9ad31f23c86e56b79fd27562227341ce6d3a4f10633a72c4ce
87314a321b764ad258c77ececf214491f38c091bfc949927443e831f507ad0dd2f0936dc7d75367801594ea7b40d10f9cd2ab7f8f2216646fc4ed77489b02dd5
f4f3c448b1fd9c58a363b08a8cd03ec198a24bb4c0d879f1b985c1806586cdb7a41fc590558eb12db01e213356e5738a39f44ab2b9d9cf9327841b213bc5113b
c0e774bd9378d6284d507e48f313f0ba6ef3f1590e87d142e1299d9febc027047a408817ab519e72d0a105f741adcf62641430f9ccedf1bace0dff5de78cc1b9
7c65d0b8c6b904197c631948ecbacc076d3343d4d8601b3033449c135bba0511c3fd5b11595c95d8ca2ab7340fedd60dd01d194d4f42d22b3aa0ff5de703fdc5
bb3f7c6f09c18fd3edd8151ba9ea867dcea15472bcd3dd1cc2edf63443962fc8a7dfd28cd02a7d86a18aece7abbb8ee6aea371ffef3b9a43e7f9ae8f39d46ddc
f5312ef417777d4c395af9387dccb67581ae468e178a318f1afa2407673e4b42e954ac293ee16aecc3e1d7cc62028b524ecd3b713503cc62f828cb1c6c60e0a2
1c29192767e25744c4d31865301bf25da924e2a5ea883b19e3303252cb56dd124f57c9295b14a34e355bf28acaca91d8ae7b2d183a15eb30a612053a6c978b92
9f9aa7025fc5365263d60d01297b1312da6626898685447bb37805093935fb382cba16161da97ee3aa3d5300b5ca2bf073db811fe93db7d594846046cee7d09a
2fa49f0a576fbcab9cf9313d7dc8984604c058b1781318ca579eee4aae075f4fbe5d116ad7f0b4414239a5082b9384b28c6af0780c3f82cbe894abd7a171535f
77b72e35e84953a8fd20beb734da9d0fb1b8adaf416e3737d054cf1434752e7b6ed86841c8cc51d673973032868f4906b1c3e52f2e4423b877998bbc38f0b7c9
2c59cec508f1b830b84a3a857b122270ee5092f45cf9fa951b68aa7288e2e60790103e59725d482b9f1a3970bae964bc5ce2b9d0ddaead484b178f90e18b5c61
fd5689df1e2c25d90adc3d8d1797ce195de5cf118458abed4b032e08879b03bfb0e682c0555895c8b6f1b75398cae4afdf45a9182ad611cd625456143d991770
554f2a3aeaa9b281f654be33185433495908cf22596075a31ad5b42a5d05878355f76a2169392d696e6ba6915564d5b4673163874d19d8b1e5ed8abcc66a6362
c8697a852f52f76ecaed6e72dd4e9f505509307865bfdb957e8dda7633839a64bc9f8665ce2e57cddab179c12ba85da74868593fdca8ddb15b5523acdbc1e2ad
2a3fc8ed462d2c2d377da5b2b4ba33d7afb5d9d92b481e23e872575470e54a98ebe608bab2a9ea498ab40147e4b5288f067c725639e9b95f7aad7e7318b48635
afd31ad79a8da657ebb4fa8d5abfd56af8e396ef8d06c1575058449cf8ade2be7e02d717745ddedaabf5bd9bfb647343736fce923a5337f375455cdddcfbc1e1
9b7b8740d2f93218fbcda01f0c6bc3911fd69ac128ac75da8d7e6d1884a3a00f293d9cf4bf729d0b05f607a3d164d20a6ae110704dafdfaaf5078d612dec8c07
c1c41f37471e80cbccf91afa6fb0e9c616f051f17af05f000000ffff0300504b0304140006000800000021000dd1909fb60000001b010000270000007468656d
652f7468656d652f5f72656c732f7468656d654d616e616765722e786d6c2e72656c73848f4d0ac2301484f78277086f6fd3ba109126dd88d0add40384e4350d
363f2451eced0dae2c082e8761be9969bb979dc9136332de3168aa1a083ae995719ac16db8ec8e4052164e89d93b64b060828e6f37ed1567914b284d26245228
2e3198720e274a939cd08a54f980ae38a38f56e422a3a641c8bbd048f7757da0f19b017cc524bd62107bd5001996509affb3fd381a89672f1f165dfe514173d9
850528a2c6cce0239baa4c04ca5bbabac4df000000ffff0300504b01022d0014000600080000002100e9de0fbfff0000001c0200001300000000000000000000
000000000000005b436f6e74656e745f54797065735d2e786d6c504b01022d0014000600080000002100a5d6a7e7c0000000360100000b000000000000000000
00000000300100005f72656c732f2e72656c73504b01022d00140006000800000021006b799616830000008a0000001c00000000000000000000000000190200
007468656d652f7468656d652f7468656d654d616e616765722e786d6c504b01022d001400060008000000210094a9528694070000c720000016000000000000
00000000000000d60200007468656d652f7468656d652f7468656d65312e786d6c504b01022d00140006000800000021000dd1909fb60000001b010000270000
00000000000000000000009e0a00007468656d652f7468656d652f5f72656c732f7468656d654d616e616765722e786d6c2e72656c73504b050600000000050005005d010000990b00000000}
{\*\colorschememapping 3c3f786d6c2076657273696f6e3d22312e302220656e636f64696e673d225554462d3822207374616e64616c6f6e653d22796573223f3e0d0a3c613a636c724d
617020786d6c6e733a613d22687474703a2f2f736368656d61732e6f70656e786d6c666f726d6174732e6f72672f64726177696e676d6c2f323030362f6d6169
6e22206267313d226c743122207478313d22646b3122206267323d226c743222207478323d22646b322220616363656e74313d22616363656e74312220616363
656e74323d22616363656e74322220616363656e74333d22616363656e74332220616363656e74343d22616363656e74342220616363656e74353d22616363656e74352220616363656e74363d22616363656e74362220686c696e6b3d22686c696e6b2220666f6c486c696e6b3d22666f6c486c696e6b222f3e}
{\*\latentstyles\lsdstimax376\lsdlockeddef0\lsdsemihiddendef0\lsdunhideuseddef0\lsdqformatdef0\lsdprioritydef99{\lsdlockedexcept \lsdqformat1 \lsdpriority0 \lsdlocked0 Normal;\lsdqformat1 \lsdpriority9 \lsdlocked0 heading 1;
\lsdsemihidden1 \lsdunhideused1 \lsdqformat1 \lsdpriority9 \lsdlocked0 heading 2;\lsdsemihidden1 \lsdunhideused1 \lsdqformat1 \lsdpriority9 \lsdlocked0 heading 3;\lsdsemihidden1 \lsdunhideused1 \lsdqformat1 \lsdpriority9 \lsdlocked0 heading 4;
\lsdsemihidden1 \lsdunhideused1 \lsdqformat1 \lsdpriority9 \lsdlocked0 heading 5;\lsdsemihidden1 \lsdunhideused1 \lsdqformat1 \lsdpriority9 \lsdlocked0 heading 6;\lsdsemihidden1 \lsdunhideused1 \lsdqformat1 \lsdpriority9 \lsdlocked0 heading 7;
\lsdsemihidden1 \lsdunhideused1 \lsdqformat1 \lsdpriority9 \lsdlocked0 heading 8;\lsdsemihidden1 \lsdunhideused1 \lsdqformat1 \lsdpriority9 \lsdlocked0 heading 9;\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 index 1;
\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 index 2;\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 index 3;\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 index 4;\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 index 5;
\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 index 6;\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 index 7;\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 index 8;\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 index 9;
\lsdsemihidden1 \lsdunhideused1 \lsdpriority39 \lsdlocked0 toc 1;\lsdsemihidden1 \lsdunhideused1 \lsdpriority39 \lsdlocked0 toc 2;\lsdsemihidden1 \lsdunhideused1 \lsdpriority39 \lsdlocked0 toc 3;
\lsdsemihidden1 \lsdunhideused1 \lsdpriority39 \lsdlocked0 toc 4;\lsdsemihidden1 \lsdunhideused1 \lsdpriority39 \lsdlocked0 toc 5;\lsdsemihidden1 \lsdunhideused1 \lsdpriority39 \lsdlocked0 toc 6;
\lsdsemihidden1 \lsdunhideused1 \lsdpriority39 \lsdlocked0 toc 7;\lsdsemihidden1 \lsdunhideused1 \lsdpriority39 \lsdlocked0 toc 8;\lsdsemihidden1 \lsdunhideused1 \lsdpriority39 \lsdlocked0 toc 9;\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 Normal Indent;
\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 footnote text;\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 annotation text;\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 header;\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 footer;
\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 index heading;\lsdsemihidden1 \lsdunhideused1 \lsdqformat1 \lsdpriority35 \lsdlocked0 caption;\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 table of figures;
\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 envelope address;\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 envelope return;\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 footnote reference;\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 annotation reference;
\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 line number;\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 page number;\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 endnote reference;\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 endnote text;
\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 table of authorities;\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 macro;\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 toa heading;\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 List;
\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 List Bullet;\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 List Number;\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 List 2;\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 List 3;
\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 List 4;\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 List 5;\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 List Bullet 2;\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 List Bullet 3;
\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 List Bullet 4;\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 List Bullet 5;\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 List Number 2;\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 List Number 3;
\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 List Number 4;\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 List Number 5;\lsdqformat1 \lsdpriority10 \lsdlocked0 Title;\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 Closing;
\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 Signature;\lsdsemihidden1 \lsdunhideused1 \lsdpriority1 \lsdlocked0 Default Paragraph Font;\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 Body Text;\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 Body Text Indent;
\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 List Continue;\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 List Continue 2;\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 List Continue 3;\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 List Continue 4;
\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 List Continue 5;\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 Message Header;\lsdqformat1 \lsdpriority11 \lsdlocked0 Subtitle;\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 Salutation;
\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 Date;\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 Body Text First Indent;\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 Body Text First Indent 2;\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 Note Heading;
\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 Body Text 2;\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 Body Text 3;\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 Body Text Indent 2;\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 Body Text Indent 3;
\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 Block Text;\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 Hyperlink;\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 FollowedHyperlink;\lsdqformat1 \lsdpriority22 \lsdlocked0 Strong;
\lsdqformat1 \lsdpriority20 \lsdlocked0 Emphasis;\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 Document Map;\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 Plain Text;\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 E-mail Signature;
\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 HTML Top of Form;\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 HTML Bottom of Form;\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 Normal (Web);\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 HTML Acronym;
\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 HTML Address;\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 HTML Cite;\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 HTML Code;\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 HTML Definition;
\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 HTML Keyboard;\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 HTML Preformatted;\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 HTML Sample;\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 HTML Typewriter;
\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 HTML Variable;\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 Normal Table;\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 annotation subject;\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 No List;
\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 Outline List 1;\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 Outline List 2;\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 Outline List 3;\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 Table Simple 1;
\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 Table Simple 2;\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 Table Simple 3;\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 Table Classic 1;\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 Table Classic 2;
\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 Table Classic 3;\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 Table Classic 4;\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 Table Colorful 1;\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 Table Colorful 2;
\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 Table Colorful 3;\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 Table Columns 1;\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 Table Columns 2;\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 Table Columns 3;
\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 Table Columns 4;\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 Table Columns 5;\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 Table Grid 1;\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 Table Grid 2;
\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 Table Grid 3;\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 Table Grid 4;\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 Table Grid 5;\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 Table Grid 6;
\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 Table Grid 7;\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 Table Grid 8;\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 Table List 1;\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 Table List 2;
\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 Table List 3;\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 Table List 4;\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 Table List 5;\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 Table List 6;
\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 Table List 7;\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 Table List 8;\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 Table 3D effects 1;\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 Table 3D effects 2;
\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 Table 3D effects 3;\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 Table Contemporary;\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 Table Elegant;\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 Table Professional;
\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 Table Subtle 1;\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 Table Subtle 2;\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 Table Web 1;\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 Table Web 2;
\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 Table Web 3;\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 Balloon Text;\lsdpriority39 \lsdlocked0 Table Grid;\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 Table Theme;\lsdsemihidden1 \lsdlocked0 Placeholder Text;
\lsdqformat1 \lsdpriority1 \lsdlocked0 No Spacing;\lsdpriority60 \lsdlocked0 Light Shading;\lsdpriority61 \lsdlocked0 Light List;\lsdpriority62 \lsdlocked0 Light Grid;\lsdpriority63 \lsdlocked0 Medium Shading 1;\lsdpriority64 \lsdlocked0 Medium Shading 2;
\lsdpriority65 \lsdlocked0 Medium List 1;\lsdpriority66 \lsdlocked0 Medium List 2;\lsdpriority67 \lsdlocked0 Medium Grid 1;\lsdpriority68 \lsdlocked0 Medium Grid 2;\lsdpriority69 \lsdlocked0 Medium Grid 3;\lsdpriority70 \lsdlocked0 Dark List;
\lsdpriority71 \lsdlocked0 Colorful Shading;\lsdpriority72 \lsdlocked0 Colorful List;\lsdpriority73 \lsdlocked0 Colorful Grid;\lsdpriority60 \lsdlocked0 Light Shading Accent 1;\lsdpriority61 \lsdlocked0 Light List Accent 1;
\lsdpriority62 \lsdlocked0 Light Grid Accent 1;\lsdpriority63 \lsdlocked0 Medium Shading 1 Accent 1;\lsdpriority64 \lsdlocked0 Medium Shading 2 Accent 1;\lsdpriority65 \lsdlocked0 Medium List 1 Accent 1;\lsdsemihidden1 \lsdlocked0 Revision;
\lsdqformat1 \lsdpriority34 \lsdlocked0 List Paragraph;\lsdqformat1 \lsdpriority29 \lsdlocked0 Quote;\lsdqformat1 \lsdpriority30 \lsdlocked0 Intense Quote;\lsdpriority66 \lsdlocked0 Medium List 2 Accent 1;\lsdpriority67 \lsdlocked0 Medium Grid 1 Accent 1;
\lsdpriority68 \lsdlocked0 Medium Grid 2 Accent 1;\lsdpriority69 \lsdlocked0 Medium Grid 3 Accent 1;\lsdpriority70 \lsdlocked0 Dark List Accent 1;\lsdpriority71 \lsdlocked0 Colorful Shading Accent 1;\lsdpriority72 \lsdlocked0 Colorful List Accent 1;
\lsdpriority73 \lsdlocked0 Colorful Grid Accent 1;\lsdpriority60 \lsdlocked0 Light Shading Accent 2;\lsdpriority61 \lsdlocked0 Light List Accent 2;\lsdpriority62 \lsdlocked0 Light Grid Accent 2;\lsdpriority63 \lsdlocked0 Medium Shading 1 Accent 2;
\lsdpriority64 \lsdlocked0 Medium Shading 2 Accent 2;\lsdpriority65 \lsdlocked0 Medium List 1 Accent 2;\lsdpriority66 \lsdlocked0 Medium List 2 Accent 2;\lsdpriority67 \lsdlocked0 Medium Grid 1 Accent 2;\lsdpriority68 \lsdlocked0 Medium Grid 2 Accent 2;
\lsdpriority69 \lsdlocked0 Medium Grid 3 Accent 2;\lsdpriority70 \lsdlocked0 Dark List Accent 2;\lsdpriority71 \lsdlocked0 Colorful Shading Accent 2;\lsdpriority72 \lsdlocked0 Colorful List Accent 2;\lsdpriority73 \lsdlocked0 Colorful Grid Accent 2;
\lsdpriority60 \lsdlocked0 Light Shading Accent 3;\lsdpriority61 \lsdlocked0 Light List Accent 3;\lsdpriority62 \lsdlocked0 Light Grid Accent 3;\lsdpriority63 \lsdlocked0 Medium Shading 1 Accent 3;\lsdpriority64 \lsdlocked0 Medium Shading 2 Accent 3;
\lsdpriority65 \lsdlocked0 Medium List 1 Accent 3;\lsdpriority66 \lsdlocked0 Medium List 2 Accent 3;\lsdpriority67 \lsdlocked0 Medium Grid 1 Accent 3;\lsdpriority68 \lsdlocked0 Medium Grid 2 Accent 3;\lsdpriority69 \lsdlocked0 Medium Grid 3 Accent 3;
\lsdpriority70 \lsdlocked0 Dark List Accent 3;\lsdpriority71 \lsdlocked0 Colorful Shading Accent 3;\lsdpriority72 \lsdlocked0 Colorful List Accent 3;\lsdpriority73 \lsdlocked0 Colorful Grid Accent 3;\lsdpriority60 \lsdlocked0 Light Shading Accent 4;
\lsdpriority61 \lsdlocked0 Light List Accent 4;\lsdpriority62 \lsdlocked0 Light Grid Accent 4;\lsdpriority63 \lsdlocked0 Medium Shading 1 Accent 4;\lsdpriority64 \lsdlocked0 Medium Shading 2 Accent 4;\lsdpriority65 \lsdlocked0 Medium List 1 Accent 4;
\lsdpriority66 \lsdlocked0 Medium List 2 Accent 4;\lsdpriority67 \lsdlocked0 Medium Grid 1 Accent 4;\lsdpriority68 \lsdlocked0 Medium Grid 2 Accent 4;\lsdpriority69 \lsdlocked0 Medium Grid 3 Accent 4;\lsdpriority70 \lsdlocked0 Dark List Accent 4;
\lsdpriority71 \lsdlocked0 Colorful Shading Accent 4;\lsdpriority72 \lsdlocked0 Colorful List Accent 4;\lsdpriority73 \lsdlocked0 Colorful Grid Accent 4;\lsdpriority60 \lsdlocked0 Light Shading Accent 5;\lsdpriority61 \lsdlocked0 Light List Accent 5;
\lsdpriority62 \lsdlocked0 Light Grid Accent 5;\lsdpriority63 \lsdlocked0 Medium Shading 1 Accent 5;\lsdpriority64 \lsdlocked0 Medium Shading 2 Accent 5;\lsdpriority65 \lsdlocked0 Medium List 1 Accent 5;\lsdpriority66 \lsdlocked0 Medium List 2 Accent 5;
\lsdpriority67 \lsdlocked0 Medium Grid 1 Accent 5;\lsdpriority68 \lsdlocked0 Medium Grid 2 Accent 5;\lsdpriority69 \lsdlocked0 Medium Grid 3 Accent 5;\lsdpriority70 \lsdlocked0 Dark List Accent 5;\lsdpriority71 \lsdlocked0 Colorful Shading Accent 5;
\lsdpriority72 \lsdlocked0 Colorful List Accent 5;\lsdpriority73 \lsdlocked0 Colorful Grid Accent 5;\lsdpriority60 \lsdlocked0 Light Shading Accent 6;\lsdpriority61 \lsdlocked0 Light List Accent 6;\lsdpriority62 \lsdlocked0 Light Grid Accent 6;
\lsdpriority63 \lsdlocked0 Medium Shading 1 Accent 6;\lsdpriority64 \lsdlocked0 Medium Shading 2 Accent 6;\lsdpriority65 \lsdlocked0 Medium List 1 Accent 6;\lsdpriority66 \lsdlocked0 Medium List 2 Accent 6;
\lsdpriority67 \lsdlocked0 Medium Grid 1 Accent 6;\lsdpriority68 \lsdlocked0 Medium Grid 2 Accent 6;\lsdpriority69 \lsdlocked0 Medium Grid 3 Accent 6;\lsdpriority70 \lsdlocked0 Dark List Accent 6;\lsdpriority71 \lsdlocked0 Colorful Shading Accent 6;
\lsdpriority72 \lsdlocked0 Colorful List Accent 6;\lsdpriority73 \lsdlocked0 Colorful Grid Accent 6;\lsdqformat1 \lsdpriority19 \lsdlocked0 Subtle Emphasis;\lsdqformat1 \lsdpriority21 \lsdlocked0 Intense Emphasis;
\lsdqformat1 \lsdpriority31 \lsdlocked0 Subtle Reference;\lsdqformat1 \lsdpriority32 \lsdlocked0 Intense Reference;\lsdqformat1 \lsdpriority33 \lsdlocked0 Book Title;\lsdsemihidden1 \lsdunhideused1 \lsdpriority37 \lsdlocked0 Bibliography;
\lsdsemihidden1 \lsdunhideused1 \lsdqformat1 \lsdpriority39 \lsdlocked0 TOC Heading;\lsdpriority41 \lsdlocked0 Plain Table 1;\lsdpriority42 \lsdlocked0 Plain Table 2;\lsdpriority43 \lsdlocked0 Plain Table 3;\lsdpriority44 \lsdlocked0 Plain Table 4;
\lsdpriority45 \lsdlocked0 Plain Table 5;\lsdpriority40 \lsdlocked0 Grid Table Light;\lsdpriority46 \lsdlocked0 Grid Table 1 Light;\lsdpriority47 \lsdlocked0 Grid Table 2;\lsdpriority48 \lsdlocked0 Grid Table 3;\lsdpriority49 \lsdlocked0 Grid Table 4;
\lsdpriority50 \lsdlocked0 Grid Table 5 Dark;\lsdpriority51 \lsdlocked0 Grid Table 6 Colorful;\lsdpriority52 \lsdlocked0 Grid Table 7 Colorful;\lsdpriority46 \lsdlocked0 Grid Table 1 Light Accent 1;\lsdpriority47 \lsdlocked0 Grid Table 2 Accent 1;
\lsdpriority48 \lsdlocked0 Grid Table 3 Accent 1;\lsdpriority49 \lsdlocked0 Grid Table 4 Accent 1;\lsdpriority50 \lsdlocked0 Grid Table 5 Dark Accent 1;\lsdpriority51 \lsdlocked0 Grid Table 6 Colorful Accent 1;
\lsdpriority52 \lsdlocked0 Grid Table 7 Colorful Accent 1;\lsdpriority46 \lsdlocked0 Grid Table 1 Light Accent 2;\lsdpriority47 \lsdlocked0 Grid Table 2 Accent 2;\lsdpriority48 \lsdlocked0 Grid Table 3 Accent 2;
\lsdpriority49 \lsdlocked0 Grid Table 4 Accent 2;\lsdpriority50 \lsdlocked0 Grid Table 5 Dark Accent 2;\lsdpriority51 \lsdlocked0 Grid Table 6 Colorful Accent 2;\lsdpriority52 \lsdlocked0 Grid Table 7 Colorful Accent 2;
\lsdpriority46 \lsdlocked0 Grid Table 1 Light Accent 3;\lsdpriority47 \lsdlocked0 Grid Table 2 Accent 3;\lsdpriority48 \lsdlocked0 Grid Table 3 Accent 3;\lsdpriority49 \lsdlocked0 Grid Table 4 Accent 3;
\lsdpriority50 \lsdlocked0 Grid Table 5 Dark Accent 3;\lsdpriority51 \lsdlocked0 Grid Table 6 Colorful Accent 3;\lsdpriority52 \lsdlocked0 Grid Table 7 Colorful Accent 3;\lsdpriority46 \lsdlocked0 Grid Table 1 Light Accent 4;
\lsdpriority47 \lsdlocked0 Grid Table 2 Accent 4;\lsdpriority48 \lsdlocked0 Grid Table 3 Accent 4;\lsdpriority49 \lsdlocked0 Grid Table 4 Accent 4;\lsdpriority50 \lsdlocked0 Grid Table 5 Dark Accent 4;
\lsdpriority51 \lsdlocked0 Grid Table 6 Colorful Accent 4;\lsdpriority52 \lsdlocked0 Grid Table 7 Colorful Accent 4;\lsdpriority46 \lsdlocked0 Grid Table 1 Light Accent 5;\lsdpriority47 \lsdlocked0 Grid Table 2 Accent 5;
\lsdpriority48 \lsdlocked0 Grid Table 3 Accent 5;\lsdpriority49 \lsdlocked0 Grid Table 4 Accent 5;\lsdpriority50 \lsdlocked0 Grid Table 5 Dark Accent 5;\lsdpriority51 \lsdlocked0 Grid Table 6 Colorful Accent 5;
\lsdpriority52 \lsdlocked0 Grid Table 7 Colorful Accent 5;\lsdpriority46 \lsdlocked0 Grid Table 1 Light Accent 6;\lsdpriority47 \lsdlocked0 Grid Table 2 Accent 6;\lsdpriority48 \lsdlocked0 Grid Table 3 Accent 6;
\lsdpriority49 \lsdlocked0 Grid Table 4 Accent 6;\lsdpriority50 \lsdlocked0 Grid Table 5 Dark Accent 6;\lsdpriority51 \lsdlocked0 Grid Table 6 Colorful Accent 6;\lsdpriority52 \lsdlocked0 Grid Table 7 Colorful Accent 6;
\lsdpriority46 \lsdlocked0 List Table 1 Light;\lsdpriority47 \lsdlocked0 List Table 2;\lsdpriority48 \lsdlocked0 List Table 3;\lsdpriority49 \lsdlocked0 List Table 4;\lsdpriority50 \lsdlocked0 List Table 5 Dark;
\lsdpriority51 \lsdlocked0 List Table 6 Colorful;\lsdpriority52 \lsdlocked0 List Table 7 Colorful;\lsdpriority46 \lsdlocked0 List Table 1 Light Accent 1;\lsdpriority47 \lsdlocked0 List Table 2 Accent 1;\lsdpriority48 \lsdlocked0 List Table 3 Accent 1;
\lsdpriority49 \lsdlocked0 List Table 4 Accent 1;\lsdpriority50 \lsdlocked0 List Table 5 Dark Accent 1;\lsdpriority51 \lsdlocked0 List Table 6 Colorful Accent 1;\lsdpriority52 \lsdlocked0 List Table 7 Colorful Accent 1;
\lsdpriority46 \lsdlocked0 List Table 1 Light Accent 2;\lsdpriority47 \lsdlocked0 List Table 2 Accent 2;\lsdpriority48 \lsdlocked0 List Table 3 Accent 2;\lsdpriority49 \lsdlocked0 List Table 4 Accent 2;
\lsdpriority50 \lsdlocked0 List Table 5 Dark Accent 2;\lsdpriority51 \lsdlocked0 List Table 6 Colorful Accent 2;\lsdpriority52 \lsdlocked0 List Table 7 Colorful Accent 2;\lsdpriority46 \lsdlocked0 List Table 1 Light Accent 3;
\lsdpriority47 \lsdlocked0 List Table 2 Accent 3;\lsdpriority48 \lsdlocked0 List Table 3 Accent 3;\lsdpriority49 \lsdlocked0 List Table 4 Accent 3;\lsdpriority50 \lsdlocked0 List Table 5 Dark Accent 3;
\lsdpriority51 \lsdlocked0 List Table 6 Colorful Accent 3;\lsdpriority52 \lsdlocked0 List Table 7 Colorful Accent 3;\lsdpriority46 \lsdlocked0 List Table 1 Light Accent 4;\lsdpriority47 \lsdlocked0 List Table 2 Accent 4;
\lsdpriority48 \lsdlocked0 List Table 3 Accent 4;\lsdpriority49 \lsdlocked0 List Table 4 Accent 4;\lsdpriority50 \lsdlocked0 List Table 5 Dark Accent 4;\lsdpriority51 \lsdlocked0 List Table 6 Colorful Accent 4;
\lsdpriority52 \lsdlocked0 List Table 7 Colorful Accent 4;\lsdpriority46 \lsdlocked0 List Table 1 Light Accent 5;\lsdpriority47 \lsdlocked0 List Table 2 Accent 5;\lsdpriority48 \lsdlocked0 List Table 3 Accent 5;
\lsdpriority49 \lsdlocked0 List Table 4 Accent 5;\lsdpriority50 \lsdlocked0 List Table 5 Dark Accent 5;\lsdpriority51 \lsdlocked0 List Table 6 Colorful Accent 5;\lsdpriority52 \lsdlocked0 List Table 7 Colorful Accent 5;
\lsdpriority46 \lsdlocked0 List Table 1 Light Accent 6;\lsdpriority47 \lsdlocked0 List Table 2 Accent 6;\lsdpriority48 \lsdlocked0 List Table 3 Accent 6;\lsdpriority49 \lsdlocked0 List Table 4 Accent 6;
\lsdpriority50 \lsdlocked0 List Table 5 Dark Accent 6;\lsdpriority51 \lsdlocked0 List Table 6 Colorful Accent 6;\lsdpriority52 \lsdlocked0 List Table 7 Colorful Accent 6;\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 Mention;
\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 Smart Hyperlink;\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 Hashtag;\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 Unresolved Mention;\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 Smart Link;}}{\*\datastore 01050000
02000000180000004d73786d6c322e534158584d4c5265616465722e362e3000000000000000000000060000
d0cf11e0a1b11ae1000000000000000000000000000000003e000300feff090006000000000000000000000001000000010000000000000000100000feffffff00000000feffffff0000000000000000ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
fffffffffffffffffdfffffffeffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
ffffffffffffffffffffffffffffffff52006f006f007400200045006e00740072007900000000000000000000000000000000000000000000000000000000000000000000000000000000000000000016000500ffffffffffffffffffffffff0c6ad98892f1d411a65f0040963251e50000000000000000000000007015
f0f9e398da01feffffff00000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000ffffffffffffffffffffffff00000000000000000000000000000000000000000000000000000000
00000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000ffffffffffffffffffffffff0000000000000000000000000000000000000000000000000000
000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000ffffffffffffffffffffffff000000000000000000000000000000000000000000000000
0000000000000000000000000000000000000000000000000105000000000000}}