{\rtf1\adeflang1025\ansi\ansicpg1252\uc1\adeff31507\deff0\stshfdbch31505\stshfloch31506\stshfhich31506\stshfbi31507\deflang1033\deflangfe2052\themelang1033\themelangfe0\themelangcs0{\fonttbl{\f0\fbidi \froman\fcharset0\fprq2{\*\panose 02020603050405020304}Times New Roman;}{\f34\fbidi \froman\fcharset0\fprq2{\*\panose 02040503050406030204}Cambria Math;}
{\f36\fbidi \fnil\fcharset134\fprq2{\*\panose 02010600030101010101}DengXian{\*\falt \'b5\'c8\'cf\'df};}{\f44\fbidi \fswiss\fcharset0\fprq2 Aptos;}{\f46\fbidi \fnil\fcharset134\fprq2{\*\panose 02010600030101010101}@DengXian;}
{\flomajor\f31500\fbidi \froman\fcharset0\fprq2{\*\panose 02020603050405020304}Times New Roman;}{\fdbmajor\f31501\fbidi \fnil\fcharset134\fprq2{\*\panose 02010600030101010101}DengXian Light{\*\falt \'b5\'c8\'cf\'df Light};}
{\fhimajor\f31502\fbidi \fswiss\fcharset0\fprq2 Aptos Display;}{\fbimajor\f31503\fbidi \froman\fcharset0\fprq2{\*\panose 02020603050405020304}Times New Roman;}{\flominor\f31504\fbidi \froman\fcharset0\fprq2{\*\panose 02020603050405020304}Times New Roman;}
{\fdbminor\f31505\fbidi \fnil\fcharset134\fprq2{\*\panose 02010600030101010101}DengXian{\*\falt \'b5\'c8\'cf\'df};}{\fhiminor\f31506\fbidi \fswiss\fcharset0\fprq2 Aptos;}
{\fbiminor\f31507\fbidi \froman\fcharset0\fprq2{\*\panose 02020603050405020304}Times New Roman;}{\f47\fbidi \froman\fcharset238\fprq2 Times New Roman CE;}{\f48\fbidi \froman\fcharset204\fprq2 Times New Roman Cyr;}
{\f50\fbidi \froman\fcharset161\fprq2 Times New Roman Greek;}{\f51\fbidi \froman\fcharset162\fprq2 Times New Roman Tur;}{\f52\fbidi \froman\fcharset177\fprq2 Times New Roman (Hebrew);}{\f53\fbidi \froman\fcharset178\fprq2 Times New Roman (Arabic);}
{\f54\fbidi \froman\fcharset186\fprq2 Times New Roman Baltic;}{\f55\fbidi \froman\fcharset163\fprq2 Times New Roman (Vietnamese);}{\f387\fbidi \froman\fcharset238\fprq2 Cambria Math CE;}{\f388\fbidi \froman\fcharset204\fprq2 Cambria Math Cyr;}
{\f390\fbidi \froman\fcharset161\fprq2 Cambria Math Greek;}{\f391\fbidi \froman\fcharset162\fprq2 Cambria Math Tur;}{\f394\fbidi \froman\fcharset186\fprq2 Cambria Math Baltic;}{\f395\fbidi \froman\fcharset163\fprq2 Cambria Math (Vietnamese);}
{\f409\fbidi \fnil\fcharset0\fprq2 DengXian Western{\*\falt \'b5\'c8\'cf\'df};}{\f407\fbidi \fnil\fcharset238\fprq2 DengXian CE{\*\falt \'b5\'c8\'cf\'df};}{\f408\fbidi \fnil\fcharset204\fprq2 DengXian Cyr{\*\falt \'b5\'c8\'cf\'df};}
{\f410\fbidi \fnil\fcharset161\fprq2 DengXian Greek{\*\falt \'b5\'c8\'cf\'df};}{\f487\fbidi \fswiss\fcharset238\fprq2 Aptos CE;}{\f488\fbidi \fswiss\fcharset204\fprq2 Aptos Cyr;}{\f490\fbidi \fswiss\fcharset161\fprq2 Aptos Greek;}
{\f491\fbidi \fswiss\fcharset162\fprq2 Aptos Tur;}{\f494\fbidi \fswiss\fcharset186\fprq2 Aptos Baltic;}{\f495\fbidi \fswiss\fcharset163\fprq2 Aptos (Vietnamese);}{\f509\fbidi \fnil\fcharset0\fprq2 @DengXian Western;}
{\f507\fbidi \fnil\fcharset238\fprq2 @DengXian CE;}{\f508\fbidi \fnil\fcharset204\fprq2 @DengXian Cyr;}{\f510\fbidi \fnil\fcharset161\fprq2 @DengXian Greek;}{\flomajor\f31508\fbidi \froman\fcharset238\fprq2 Times New Roman CE;}
{\flomajor\f31509\fbidi \froman\fcharset204\fprq2 Times New Roman Cyr;}{\flomajor\f31511\fbidi \froman\fcharset161\fprq2 Times New Roman Greek;}{\flomajor\f31512\fbidi \froman\fcharset162\fprq2 Times New Roman Tur;}
{\flomajor\f31513\fbidi \froman\fcharset177\fprq2 Times New Roman (Hebrew);}{\flomajor\f31514\fbidi \froman\fcharset178\fprq2 Times New Roman (Arabic);}{\flomajor\f31515\fbidi \froman\fcharset186\fprq2 Times New Roman Baltic;}
{\flomajor\f31516\fbidi \froman\fcharset163\fprq2 Times New Roman (Vietnamese);}{\fdbmajor\f31520\fbidi \fnil\fcharset0\fprq2 DengXian Light Western{\*\falt \'b5\'c8\'cf\'df Light};}
{\fdbmajor\f31518\fbidi \fnil\fcharset238\fprq2 DengXian Light CE{\*\falt \'b5\'c8\'cf\'df Light};}{\fdbmajor\f31519\fbidi \fnil\fcharset204\fprq2 DengXian Light Cyr{\*\falt \'b5\'c8\'cf\'df Light};}
{\fdbmajor\f31521\fbidi \fnil\fcharset161\fprq2 DengXian Light Greek{\*\falt \'b5\'c8\'cf\'df Light};}{\fhimajor\f31528\fbidi \fswiss\fcharset238\fprq2 Aptos Display CE;}{\fhimajor\f31529\fbidi \fswiss\fcharset204\fprq2 Aptos Display Cyr;}
{\fhimajor\f31531\fbidi \fswiss\fcharset161\fprq2 Aptos Display Greek;}{\fhimajor\f31532\fbidi \fswiss\fcharset162\fprq2 Aptos Display Tur;}{\fhimajor\f31535\fbidi \fswiss\fcharset186\fprq2 Aptos Display Baltic;}
{\fhimajor\f31536\fbidi \fswiss\fcharset163\fprq2 Aptos Display (Vietnamese);}{\fbimajor\f31538\fbidi \froman\fcharset238\fprq2 Times New Roman CE;}{\fbimajor\f31539\fbidi \froman\fcharset204\fprq2 Times New Roman Cyr;}
{\fbimajor\f31541\fbidi \froman\fcharset161\fprq2 Times New Roman Greek;}{\fbimajor\f31542\fbidi \froman\fcharset162\fprq2 Times New Roman Tur;}{\fbimajor\f31543\fbidi \froman\fcharset177\fprq2 Times New Roman (Hebrew);}
{\fbimajor\f31544\fbidi \froman\fcharset178\fprq2 Times New Roman (Arabic);}{\fbimajor\f31545\fbidi \froman\fcharset186\fprq2 Times New Roman Baltic;}{\fbimajor\f31546\fbidi \froman\fcharset163\fprq2 Times New Roman (Vietnamese);}
{\flominor\f31548\fbidi \froman\fcharset238\fprq2 Times New Roman CE;}{\flominor\f31549\fbidi \froman\fcharset204\fprq2 Times New Roman Cyr;}{\flominor\f31551\fbidi \froman\fcharset161\fprq2 Times New Roman Greek;}
{\flominor\f31552\fbidi \froman\fcharset162\fprq2 Times New Roman Tur;}{\flominor\f31553\fbidi \froman\fcharset177\fprq2 Times New Roman (Hebrew);}{\flominor\f31554\fbidi \froman\fcharset178\fprq2 Times New Roman (Arabic);}
{\flominor\f31555\fbidi \froman\fcharset186\fprq2 Times New Roman Baltic;}{\flominor\f31556\fbidi \froman\fcharset163\fprq2 Times New Roman (Vietnamese);}{\fdbminor\f31560\fbidi \fnil\fcharset0\fprq2 DengXian Western{\*\falt \'b5\'c8\'cf\'df};}
{\fdbminor\f31558\fbidi \fnil\fcharset238\fprq2 DengXian CE{\*\falt \'b5\'c8\'cf\'df};}{\fdbminor\f31559\fbidi \fnil\fcharset204\fprq2 DengXian Cyr{\*\falt \'b5\'c8\'cf\'df};}
{\fdbminor\f31561\fbidi \fnil\fcharset161\fprq2 DengXian Greek{\*\falt \'b5\'c8\'cf\'df};}{\fhiminor\f31568\fbidi \fswiss\fcharset238\fprq2 Aptos CE;}{\fhiminor\f31569\fbidi \fswiss\fcharset204\fprq2 Aptos Cyr;}
{\fhiminor\f31571\fbidi \fswiss\fcharset161\fprq2 Aptos Greek;}{\fhiminor\f31572\fbidi \fswiss\fcharset162\fprq2 Aptos Tur;}{\fhiminor\f31575\fbidi \fswiss\fcharset186\fprq2 Aptos Baltic;}
{\fhiminor\f31576\fbidi \fswiss\fcharset163\fprq2 Aptos (Vietnamese);}{\fbiminor\f31578\fbidi \froman\fcharset238\fprq2 Times New Roman CE;}{\fbiminor\f31579\fbidi \froman\fcharset204\fprq2 Times New Roman Cyr;}
{\fbiminor\f31581\fbidi \froman\fcharset161\fprq2 Times New Roman Greek;}{\fbiminor\f31582\fbidi \froman\fcharset162\fprq2 Times New Roman Tur;}{\fbiminor\f31583\fbidi \froman\fcharset177\fprq2 Times New Roman (Hebrew);}
{\fbiminor\f31584\fbidi \froman\fcharset178\fprq2 Times New Roman (Arabic);}{\fbiminor\f31585\fbidi \froman\fcharset186\fprq2 Times New Roman Baltic;}{\fbiminor\f31586\fbidi \froman\fcharset163\fprq2 Times New Roman (Vietnamese);}}
{\colortbl;\red0\green0\blue0;\red0\green0\blue255;\red0\green255\blue255;\red0\green255\blue0;\red255\green0\blue255;\red255\green0\blue0;\red255\green255\blue0;\red255\green255\blue255;\red0\green0\blue128;\red0\green128\blue128;\red0\green128\blue0;
\red128\green0\blue128;\red128\green0\blue0;\red128\green128\blue0;\red128\green128\blue128;\red192\green192\blue192;\red0\green0\blue0;\red0\green0\blue0;}{\*\defchp \fs24\kerning2\loch\af31506\hich\af31506\dbch\af31505 }{\*\defpap 
\ql \li0\ri0\sa160\sl278\slmult1\widctlpar\wrapdefault\aspalpha\aspnum\faauto\adjustright\rin0\lin0\itap0 }\noqfpromote {\stylesheet{\ql \li0\ri0\sa160\sl278\slmult1\widctlpar\wrapdefault\aspalpha\aspnum\faauto\adjustright\rin0\lin0\itap0 \rtlch\fcs1 
\af31507\afs24\alang1025 \ltrch\fcs0 \fs24\lang1033\langfe2052\kerning2\loch\f31506\hich\af31506\dbch\af31505\cgrid\langnp1033\langfenp2052 \snext0 \sqformat \spriority0 Normal;}{\*\cs10 \additive \ssemihidden \sunhideused \spriority1 
Default Paragraph Font;}{\*\ts11\tsrowd\trftsWidthB3\trpaddl108\trpaddr108\trpaddfl3\trpaddft3\trpaddfb3\trpaddfr3\trcbpat1\trcfpat1\tblind0\tblindtype3\tsvertalt\tsbrdrt\tsbrdrl\tsbrdrb\tsbrdrr\tsbrdrdgl\tsbrdrdgr\tsbrdrh\tsbrdrv 
\ql \li0\ri0\sa160\sl278\slmult1\widctlpar\wrapdefault\aspalpha\aspnum\faauto\adjustright\rin0\lin0\itap0 \rtlch\fcs1 \af31507\afs24\alang1025 \ltrch\fcs0 
\fs24\lang1033\langfe2052\kerning2\loch\f31506\hich\af31506\dbch\af31505\cgrid\langnp1033\langfenp2052 \snext11 \ssemihidden \sunhideused Normal Table;}}{\*\rsidtbl \rsid748817\rsid9832040}{\mmathPr\mmathFont34\mbrkBin0\mbrkBinSub0\msmallFrac0\mdispDef1
\mlMargin0\mrMargin0\mdefJc1\mwrapIndent1440\mintLim0\mnaryLim1}{\info{\operator Jinyu Rao}{\creatim\yr2024\mo4\dy27\hr13\min3}{\revtim\yr2024\mo4\dy27\hr13\min3}{\version2}{\edmins0}{\nofpages38}{\nofwords8191}{\nofchars46690}{\nofcharsws54772}{\vern93}}
{\*\xmlnstbl {\xmlns1 http://schemas.microsoft.com/office/word/2003/wordml}}\paperw12240\paperh15840\margl1440\margr1440\margt1440\margb1440\gutter0\ltrsect 
\widowctrl\ftnbj\aenddoc\trackmoves0\trackformatting1\donotembedsysfont0\relyonvml0\donotembedlingdata1\grfdocevents0\validatexml0\showplaceholdtext0\ignoremixedcontent0\saveinvalidxml0\showxmlerrors0\horzdoc\dghspace120\dgvspace120\dghorigin1701
\dgvorigin1984\dghshow0\dgvshow3\jcompress\viewkind1\viewscale130\rsidroot748817 \fet0{\*\wgrffmtfilter 2450}\ilfomacatclnup0\ltrpar \sectd \ltrsect\linex0\sectdefaultcl\sftnbj {\*\pnseclvl1\pnucrm\pnstart1\pnindent720\pnhang {\pntxta .}}{\*\pnseclvl2
\pnucltr\pnstart1\pnindent720\pnhang {\pntxta .}}{\*\pnseclvl3\pndec\pnstart1\pnindent720\pnhang {\pntxta .}}{\*\pnseclvl4\pnlcltr\pnstart1\pnindent720\pnhang {\pntxta )}}{\*\pnseclvl5\pndec\pnstart1\pnindent720\pnhang {\pntxtb (}{\pntxta )}}{\*\pnseclvl6
\pnlcltr\pnstart1\pnindent720\pnhang {\pntxtb (}{\pntxta )}}{\*\pnseclvl7\pnlcrm\pnstart1\pnindent720\pnhang {\pntxtb (}{\pntxta )}}{\*\pnseclvl8\pnlcltr\pnstart1\pnindent720\pnhang {\pntxtb (}{\pntxta )}}{\*\pnseclvl9\pnlcrm\pnstart1\pnindent720\pnhang 
{\pntxtb (}{\pntxta )}}\pard\plain \ltrpar\ql \li0\ri0\sa160\sl278\slmult1\widctlpar\wrapdefault\aspalpha\aspnum\faauto\adjustright\rin0\lin0\itap0\pararsid748817 \rtlch\fcs1 \af31507\afs24\alang1025 \ltrch\fcs0 
\fs24\lang1033\langfe2052\kerning2\loch\af31506\hich\af31506\dbch\af31505\cgrid\langnp1033\langfenp2052 {\rtlch\fcs1 \af31507 \ltrch\fcs0 \insrsid748817 \hich\af31506\dbch\af31505\loch\f31506 (H:\\CondaEnv\\CNNDDIV4) PS H:\\CodeV3\\
CS598_DLH_Project-CNN_DDI\\CS598_DLH_Project-CNN_DDI> pdm run python CNN_DDI_final.py -c CNN_DDI -s Gaussian
\par \hich\af31506\dbch\af31505\loch\f31506 Inside an active virtualenv H:\\CondaEnv\\CNNDDIV4, reusing it.
\par \hich\af31506\dbch\af31505\loch\f31506 Set env var PDM_IGNORE_ACTIVE_VENV to ignore it.
\par \hich\af31506\dbch\af31505\loch\f31506 2024-04-27 12:27:34.391995: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cudart64_101.dll
\par \hich\af31506\dbch\af31505\loch\f31506 2024-04-27 12:27:35.561828: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library nvcuda.dll
\par \hich\af31506\dbch\af31505\loch\f31506 2024-04-27 12:27:35.584335: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
\par \hich\af31506\dbch\af31505\loch\f31506 pciBusID: 0000:01:00.0 name: NVIDIA GeForce RTX 2080 Ti compu\hich\af31506\dbch\af31505\loch\f31506 teCapability: 7.5
\par \hich\af31506\dbch\af31505\loch\f31506 coreClock: 1.545GHz coreCount: 68 deviceMemorySize: 11.00GiB deviceMemoryBandwidth: 573.69GiB/s
\par \hich\af31506\dbch\af31505\loch\f31506 2024-04-27 12:27:35.584496: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cudart64_101.dll
\par \hich\af31506\dbch\af31505\loch\f31506 2024-04-27 12:27:35.589271: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cublas64_10.dll
\par \hich\af31506\dbch\af31505\loch\f31506 2024-04-27 12:27:35.591699: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully open\hich\af31506\dbch\af31505\loch\f31506 ed dynamic library cufft64_10.dll
\par \hich\af31506\dbch\af31505\loch\f31506 2024-04-27 12:27:35.592451: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library curand64_10.dll
\par \hich\af31506\dbch\af31505\loch\f31506 2024-04-27 12:27:35.595443: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cusolver64_10.dll
\par \hich\af31506\dbch\af31505\loch\f31506 2024-04-27 12:27:35.596970: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cusparse64_10.dll
\par \hich\af31506\dbch\af31505\loch\f31506 2024-04-27 12:27:35.603299: I tensorflow/s\hich\af31506\dbch\af31505\loch\f31506 tream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cudnn64_7.dll
\par \hich\af31506\dbch\af31505\loch\f31506 2024-04-27 12:27:35.603540: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0
\par \hich\af31506\dbch\af31505\loch\f31506 Setting GPU memory limit to 10GB.
\par \hich\af31506\dbch\af31505\loch\f31506 
2024-04-27 12:27:35.604073: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2
\par \hich\af31506\dbch\af31505\loch\f31506 To enable them in \hich\af31506\dbch\af31505\loch\f31506 other operations, rebuild TensorFlow with the appropriate compiler flags.
\par \hich\af31506\dbch\af31505\loch\f31506 2024-04-27 12:27:35.611012: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x1885cf2ebe0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
\par \hich\af31506\dbch\af31505\loch\f31506 2024-04-27 12:27:35.611186: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
\par \hich\af31506\dbch\af31505\loch\f31506 2024-04-27 12:27:35.611366: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties:
\par \hich\af31506\dbch\af31505\loch\f31506 pciBusID: 0000:01:00.0 name: NVIDIA GeForce RTX 2080 Ti computeCapability: 7.5
\par \hich\af31506\dbch\af31505\loch\f31506 coreClock: 1.545GHz coreCount: 68 deviceMemorySize: 11.00GiB deviceMemoryBandwidth: 573.69GiB/s
\par \hich\af31506\dbch\af31505\loch\f31506 2024-04-27 12:27:35.611540: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cudart64_101.dll
\par \hich\af31506\dbch\af31505\loch\f31506 2024-04-27 12:27:35.611692: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cublas64_10.dll
\par \hich\af31506\dbch\af31505\loch\f31506 2024-04-27 12:27:35.611796: I tensorflow/stream_\hich\af31506\dbch\af31505\loch\f31506 executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cufft64_10.dll
\par \hich\af31506\dbch\af31505\loch\f31506 2024-04-27 12:27:35.611926: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library curand64_10.dll
\par \hich\af31506\dbch\af31505\loch\f31506 2024-04-27 12:27:35.612051: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cusolver64_10.dll
\par \hich\af31506\dbch\af31505\loch\f31506 2024-04-27 12:27:35.612163: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library\hich\af31506\dbch\af31505\loch\f31506  cusparse64_10.dll
\par \hich\af31506\dbch\af31505\loch\f31506 2024-04-27 12:27:35.612308: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cudnn64_7.dll
\par \hich\af31506\dbch\af31505\loch\f31506 2024-04-27 12:27:35.612455: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0
\par \hich\af31506\dbch\af31505\loch\f31506 2024-04-27 12:27:36.035425: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
\par \hich\af31506\dbch\af31505\loch\f31506 2024-04-27 12:27:36.035534: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0
\par \hich\af31506\dbch\af31505\loch\f31506 2024-04-27 12:27:36.035612: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N
\par \hich\af31506\dbch\af31505\loch\f31506 2024-04-27 12:27:36.035749: I tensorflow/core/common_runtime/gpu\hich\af31506\dbch\af31505\loch\f31506 
/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10240 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5)
\par \hich\af31506\dbch\af31505\loch\f31506 2024-04-27 12:27:36.038137: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x1888b585200 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
\par \hich\af31506\dbch\af31505\loch\f31506 2024-04-27 12:27:36.038224: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecut\hich\af31506\dbch\af31505\loch\f31506 or device (0): NVIDIA GeForce RTX 2080 Ti, Compute Capability 7.5
\par \hich\af31506\dbch\af31505\loch\f31506 1 Physical GPU, 1 Logical GPU(s) with memory limit:10240
\par \hich\af31506\dbch\af31505\loch\f31506 TensorFlow version: 2.3.4
\par \hich\af31506\dbch\af31505\loch\f31506 Num GPUs Available:  1
\par \{\hich\af31506\dbch\af31505\loch\f31506 
'featureList': ['pathway', 'target', 'enzyme', 'category'], 'classifier': ['CNN_DDI'], 'NLPProcess': 'read', 'similarity_measure': 'Gaussian', 'num_folds': 5, 'num_epochs': 100, 'batch_size': 128, 'evaluate_only': False, 'save_weights': False, 'loss_fn':
\hich\af31506\dbch\af31505\loch\f31506  'categorical_crossentropy'\}
\par \hich\af31506\dbch\af31505\loch\f31506 pathway
\par \hich\af31506\dbch\af31505\loch\f31506 target
\par \hich\af31506\dbch\af31505\loch\f31506 enzyme
\par \hich\af31506\dbch\af31505\loch\f31506 category
\par \hich\af31506\dbch\af31505\loch\f31506 4
\par \hich\af31506\dbch\af31505\loch\f31506 running cross validatio\hich\af31506\dbch\af31505\loch\f31506 n for CNN_DDI
\par \hich\af31506\dbch\af31505\loch\f31506 process = 16199.90528 total = 34176.229376 available = 15481.50784 used = 18694.721536 free = 15481.50784 percent = 54.7
\par \hich\af31506\dbch\af31505\loch\f31506 No weights found or loading not requested for fold 1, feature 1. Starting training.
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 1/100
\par \hich\af31506\dbch\af31505\loch\f31506 2024-04-27 12:27:45.468573: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cublas64_10.dll
\par \hich\af31506\dbch\af31505\loch\f31506 2024-04-27 12:27:45.662151: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cudnn64_7\hich\af31506\dbch\af31505\loch\f31506 .dll
\par \hich\af31506\dbch\af31505\loch\f31506 2024-04-27 12:27:46.403659: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: Invoking GPU asm compilation is supported on Cuda non-Windows platforms only
\par \hich\af31506\dbch\af31505\loch\f31506 Relying on driver to perform ptx compilation.
\par \hich\af31506\dbch\af31505\loch\f31506 Modify $PATH to customize ptxas location.
\par \hich\af31506\dbch\af31505\loch\f31506 This message will be only logged once.
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 1.1645 - accuracy: 0.6598 - val_loss: 0.7326 - val_accuracy: 0.7566
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 2/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 6s 27ms/step - loss\hich\af31506\dbch\af31505\loch\f31506 : 0.5799 - accuracy: 0.8005 - val_loss: 0.6198 - val_accuracy: 0.7898
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 3/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 29ms/step - loss: 0.4393 - accuracy: 0.8460 - val_loss: 0.5895 - val_accuracy: 0.8002
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 4/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 0.3550 - accuracy: 0.8730 - val_loss: 0.5826 - val_accuracy: 0.8024
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 5/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 30ms/step - loss: 0.3087 - accuracy: 0.8894 - val_loss: 0.5741 - val_accuracy: 0.8037
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 6/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 29ms/step - loss: 0.2691 - accurac\hich\af31506\dbch\af31505\loch\f31506 y: 0.9025 - val_loss: 0.6027 - val_accuracy: 0.8045
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 7/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 6s 27ms/step - loss: 0.2463 - accuracy: 0.9119 - val_loss: 0.6138 - val_accuracy: 0.8073
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 8/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 6s 27ms/step - loss: 0.2310 - accuracy: 0.9154 - val_loss: 0.6254 - val_accuracy: 0.8128
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 9/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 6s 27ms/step - loss: 0.2149 - accuracy: 0.9195 - val_loss: 0.6028 - val_accuracy: 0.8117
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 10/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [======\hich\af31506\dbch\af31505\loch\f31506 ========================] - 6s 27ms/step - loss: 0.2130 - accuracy: 0.9199 - val_loss: 0.6392 - val_accuracy: 0.8112
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 11/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 6s 28ms/step - loss: 0.2041 - accuracy: 0.9231 - val_loss: 0.6290 - val_accuracy: 0.8126
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 12/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 6s 28ms/step - loss: 0.1954 - accuracy: 0.9252 - val_loss: 0.6578 - val_accuracy: 0.8044
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 13/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 6s 27ms/step - loss: 0.1942 - accuracy: 0.9248 - \hich\af31506\dbch\af31505\loch\f31506 val_loss: 0.6049 - val_accuracy: 0.8148
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 14/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 6s 27ms/step - loss: 0.1881 - accuracy: 0.9259 - val_loss: 0.7816 - val_accuracy: 0.8055
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 15/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 6s 28ms/step - loss: 0.1881 - accuracy: 0.9266 - val_loss: 0.6437 - val_accuracy: 0.8116
\par \hich\af31506\dbch\af31505\loch\f31506 process = 18360.619008 total = 34176.229376 available = 13753.36448 used = 20422.864896 free = 13753.36448 percent = 59.8
\par \hich\af31506\dbch\af31505\loch\f31506 No weights found or loading not requested for fold 1, featur\hich\af31506\dbch\af31505\loch\f31506 e 2. Starting training.
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 1/100
\par \hich\af31506\dbch\af31505\loch\f31506 
  1/233 [..............................] - ETA: 0s - loss: 4.1747 - accuracy: 0.0000e+00WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0090s vs `on_train_batch_end` time: 0.0140s). Check your cal
\hich\af31506\dbch\af31505\loch\f31506 lbacks.
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 1.1093 - accuracy: 0.6689 - val_loss: 0.7155 - val_accuracy: 0.7618
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 2/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 0.5490 - accuracy: 0.8134 - val_loss: 0.6\hich\af31506\dbch\af31505\loch\f31506 095 - val_accuracy: 0.7960
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 3/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 6s 28ms/step - loss: 0.4086 - accuracy: 0.8557 - val_loss: 0.5632 - val_accuracy: 0.8162
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 4/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 6s 28ms/step - loss: 0.3286 - accuracy: 0.8843 - val_loss: 0.5764 - val_accuracy: 0.8124
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 5/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 6s 28ms/step - loss: 0.2735 - accuracy: 0.9018 - val_loss: 0.5690 - val_accuracy: 0.8160
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 6/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] \hich\af31506\dbch\af31505\loch\f31506 - 6s 28ms/step - loss: 0.2404 - accuracy: 0.9158 - val_loss: 0.5713 - val_accuracy: 0.8158
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 7/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 6s 28ms/step - loss: 0.2202 - accuracy: 0.9207 - val_loss: 0.6046 - val_accuracy: 0.8172
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 8/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 6s 28ms/step - loss: 0.2061 - accuracy: 0.9264 - val_loss: 0.6247 - val_accuracy: 0.8222
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 9/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 6s 28ms/step - loss: 0.1932 - accuracy: 0.9298 - val_loss: 0.6095 - val_accura\hich\af31506\dbch\af31505\loch\f31506 cy: 0.8192
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 10/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 0.1838 - accuracy: 0.9322 - val_loss: 0.5978 - val_accuracy: 0.8162
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 11/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 6s 28ms/step - loss: 0.1804 - accuracy: 0.9340 - val_loss: 0.6314 - val_accuracy: 0.8166
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 12/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 6s 28ms/step - loss: 0.1711 - accuracy: 0.9370 - val_loss: 0.6216 - val_accuracy: 0.8223
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 13/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 6s 28ms/st\hich\af31506\dbch\af31505\loch\f31506 ep - loss: 0.1652 - accuracy: 0.9364 - val_loss: 0.6185 - val_accuracy: 0.8270
\par \hich\af31506\dbch\af31505\loch\f31506 process = 18594.947072 total = 34176.229376 available = 13475.708928 used = 20700.520448 free = 13475.708928 percent = 60.6
\par \hich\af31506\dbch\af31505\loch\f31506 No weights found or loading not requested for fold 1, feature 3. Starting training.
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 1/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 1.6374 - accuracy: 0.5256 - val_loss: 1.2606 - val_accuracy: 0.6141
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 2/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 1.0846 - accuracy: 0.6472 - val_loss: 1.1204 - val_accuracy: 0.6422
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 3/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 0.9271 - accuracy: 0.6877 - val_loss: 1.0463 - val_accuracy: 0.6528
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 4/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 6s 28ms/step - loss: 0.8436 - accurac\hich\af31506\dbch\af31505\loch\f31506 y: 0.7059 - val_loss: 1.0446 - val_accuracy: 0.6541
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 5/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 0.7868 - accuracy: 0.7206 - val_loss: 1.0663 - val_accuracy: 0.6547
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 6/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 29ms/step - loss: 0.7409 - accuracy: 0.7353 - val_loss: 1.0698 - val_accuracy: 0.6568
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 7/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 6s 28ms/step - loss: 0.7098 - accuracy: 0.7442 - val_loss: 1.0376 - val_accuracy: 0.6585
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 8/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [=======\hich\af31506\dbch\af31505\loch\f31506 =======================] - 6s 28ms/step - loss: 0.6924 - accuracy: 0.7504 - val_loss: 1.1126 - val_accuracy: 0.6626
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 9/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 6s 28ms/step - loss: 0.6696 - accuracy: 0.7576 - val_loss: 1.0963 - val_accuracy: 0.6532
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 10/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 0.6505 - accuracy: 0.7605 - val_loss: 1.1322 - val_accuracy: 0.6516
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 11/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 0.6410 - accuracy: 0.7647 - va\hich\af31506\dbch\af31505\loch\f31506 l_loss: 1.1823 - val_accuracy: 0.6543
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 12/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 0.6309 - accuracy: 0.7657 - val_loss: 1.1157 - val_accuracy: 0.6571
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 13/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 0.6214 - accuracy: 0.7688 - val_loss: 1.1190 - val_accuracy: 0.6480
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 14/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 0.6130 - accuracy: 0.7711 - val_loss: 1.1147 - val_accuracy: 0.6486
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 15/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [=================\hich\af31506\dbch\af31505\loch\f31506 =============] - 7s 28ms/step - loss: 0.6062 - accuracy: 0.7725 - val_loss: 1.1509 - val_accuracy: 0.6573
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 16/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 0.6055 - accuracy: 0.7732 - val_loss: 1.1475 - val_accuracy: 0.6521
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 17/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 0.5945 - accuracy: 0.7770 - val_loss: 1.2545 - val_accuracy: 0.6527
\par \hich\af31506\dbch\af31505\loch\f31506 process = 18792.456192 total = 34176.229376 available = 13637.16096 used = 20539.068416 free = 13637.16096 percent = 60.1
\par \hich\af31506\dbch\af31505\loch\f31506 No weights found or loading not requested for fold 1, feature 4. Starting training.
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 1/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [========\hich\af31506\dbch\af31505\loch\f31506 ======================] - 7s 29ms/step - loss: 1.0288 - accuracy: 0.7005 - val_loss: 0.5751 - val_accuracy: 0.8167
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 2/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 0.4077 - accuracy: 0.8638 - val_loss: 0.4456 - val_accuracy: 0.8618
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 3/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 0.2594 - accuracy: 0.9104 - val_loss: 0.4144 - val_accuracy: 0.8734
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 4/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 0.1807 - accuracy: 0.9396 - val_l\hich\af31506\dbch\af31505\loch\f31506 oss: 0.4132 - val_accuracy: 0.8784
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 5/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 29ms/step - loss: 0.1280 - accuracy: 0.9562 - val_loss: 0.4552 - val_accuracy: 0.8848
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 6/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 0.0967 - accuracy: 0.9671 - val_loss: 0.5009 - val_accuracy: 0.8757
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 7/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 0.0806 - accuracy: 0.9723 - val_loss: 0.5685 - val_accuracy: 0.8794
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 8/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [========================\hich\af31506\dbch\af31505\loch\f31506 ======] - 7s 28ms/step - loss: 0.0631 - accuracy: 0.9791 - val_loss: 0.5830 - val_accuracy: 0.8797
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 9/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 0.0502 - accuracy: 0.9820 - val_loss: 0.6607 - val_accuracy: 0.8796
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 10/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 0.0547 - accuracy: 0.9825 - val_loss: 0.5712 - val_accuracy: 0.8840
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 11/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 0.0396 - accuracy: 0.9879 - val_loss: 0.6227 - \hich\af31506\dbch\af31505\loch\f31506 val_accuracy: 0.8877
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 12/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 0.0379 - accuracy: 0.9888 - val_loss: 0.5778 - val_accuracy: 0.8848
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 13/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 0.0289 - accuracy: 0.9912 - val_loss: 0.6402 - val_accuracy: 0.8823
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 14/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 0.0351 - accuracy: 0.9894 - val_loss: 0.6050 - val_accuracy: 0.8932
\par \hich\af31506\dbch\af31505\loch\f31506 process = 18236.452864 total = 34176.229376 available = 14256.177152 used = 19920.052224 f\hich\af31506\dbch\af31505\loch\f31506 ree = 14256.177152 percent = 58.3
\par \hich\af31506\dbch\af31505\loch\f31506 No weights found or loading not requested for fold 2, feature 1. Starting training.
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 1/100
\par \hich\af31506\dbch\af31505\loch\f31506 
  1/233 [..............................] - ETA: 0s - loss: 4.1771 - accuracy: 0.0000e+00WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0090s vs `on_train_batch_end` time: 0.0140s). Check your cal
\hich\af31506\dbch\af31505\loch\f31506 lbacks.
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 29ms/step - loss: 1.2047 - accuracy: 0.6490 - val_loss: 0.7646 - val_accu\hich\af31506\dbch\af31505\loch\f31506 racy: 0.7480
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 2/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 0.5824 - accuracy: 0.8025 - val_loss: 0.6145 - val_accuracy: 0.7889
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 3/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 0.4379 - accuracy: 0.8449 - val_loss: 0.6003 - val_accuracy: 0.7919
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 4/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 0.3596 - accuracy: 0.8691 - val_loss: 0.6110 - val_accuracy: 0.8043
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 5/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 6s 28ms/step\hich\af31506\dbch\af31505\loch\f31506  - loss: 0.3111 - accuracy: 0.8877 - val_loss: 0.5849 - val_accuracy: 0.8014
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 6/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 0.2698 - accuracy: 0.9014 - val_loss: 0.6245 - val_accuracy: 0.8036
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 7/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 0.2463 - accuracy: 0.9103 - val_loss: 0.6580 - val_accuracy: 0.8020
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 8/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 0.2309 - accuracy: 0.9152 - val_loss: 0.6465 - val_accuracy: 0.8055
\par \hich\af31506\dbch\af31505\loch\f31506 Epo\hich\af31506\dbch\af31505\loch\f31506 ch 9/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 0.2197 - accuracy: 0.9169 - val_loss: 0.6301 - val_accuracy: 0.8083
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 10/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 0.2059 - accuracy: 0.9228 - val_loss: 0.6474 - val_accuracy: 0.8089
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 11/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 0.2007 - accuracy: 0.9264 - val_loss: 0.6546 - val_accuracy: 0.8065
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 12/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 0.1911 - accuracy: 0.9262 - val_loss: 0.6923 - val_accuracy: 0.8047
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 13/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 0.1917 - accuracy: 0.9262 - val_loss: 0.6785 - val_accuracy: 0.8104
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 14/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 0.1843 - accu\hich\af31506\dbch\af31505\loch\f31506 racy: 0.9292 - val_loss: 0.7135 - val_accuracy: 0.8017
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 15/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 0.1887 - accuracy: 0.9271 - val_loss: 0.6807 - val_accuracy: 0.8051
\par \hich\af31506\dbch\af31505\loch\f31506 process = 18452.557824 total = 34176.229376 available = 14039.539712 used = 20136.689664 free = 14039.539712 percent = 58.9
\par \hich\af31506\dbch\af31505\loch\f31506 No weights found or loading not requested for fold 2, feature 2. Starting training.
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 1/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 1.1234 - accuracy: 0.6676 - \hich\af31506\dbch\af31505\loch\f31506 val_loss: 0.7125 - val_accuracy: 0.7674
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 2/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 0.5499 - accuracy: 0.8123 - val_loss: 0.6027 - val_accuracy: 0.7976
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 3/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 0.4059 - accuracy: 0.8560 - val_loss: 0.5814 - val_accuracy: 0.8060
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 4/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 0.3331 - accuracy: 0.8812 - val_loss: 0.5728 - val_accuracy: 0.8107
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 5/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [===================\hich\af31506\dbch\af31505\loch\f31506 ===========] - 7s 28ms/step - loss: 0.2778 - accuracy: 0.9005 - val_loss: 0.6155 - val_accuracy: 0.8122
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 6/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 0.2440 - accuracy: 0.9135 - val_loss: 0.6136 - val_accuracy: 0.8201
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 7/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 0.2185 - accuracy: 0.9202 - val_loss: 0.6067 - val_accuracy: 0.8167
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 8/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 0.2046 - accuracy: 0.9249 - val_loss: 0.6119\hich\af31506\dbch\af31505\loch\f31506  - val_accuracy: 0.8146
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 9/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 6s 28ms/step - loss: 0.1879 - accuracy: 0.9291 - val_loss: 0.6494 - val_accuracy: 0.8147
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 10/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 0.1844 - accuracy: 0.9318 - val_loss: 0.6395 - val_accuracy: 0.8077
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 11/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 0.1758 - accuracy: 0.9358 - val_loss: 0.6405 - val_accuracy: 0.8138
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 12/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 0.1712 - accuracy: 0.9354 - val_loss: 0.6391 - val_accuracy: 0.8174
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 13/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 0.1690 - accu\hich\af31506\dbch\af31505\loch\f31506 racy: 0.9357 - val_loss: 0.6259 - val_accuracy: 0.8170
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 14/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 29ms/step - loss: 0.1644 - accuracy: 0.9376 - val_loss: 0.6499 - val_accuracy: 0.8134
\par \hich\af31506\dbch\af31505\loch\f31506 process = 18636.775424 total = 34176.229376 available = 13792.149504 used = 20384.079872 free = 13792.149504 percent = 59.6
\par \hich\af31506\dbch\af31505\loch\f31506 No weights found or loading not requested for fold 2, feature 3. Starting training.
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 1/100
\par \hich\af31506\dbch\af31505\loch\f31506   1/233 [..............................] - ETA: 0s - loss: 4.1765 - accuracy: 0.0000e+00WARN\hich\af31506\dbch\af31505\loch\f31506 
ING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0090s vs `on_train_batch_end` time: 0.0145s). Check your callbacks.
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 1.6012 - accuracy: 0.5322 - val_loss: 1.2471 - val_accuracy: 0.6154
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 2/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 1.0743 - accuracy: 0.6494 - val_loss: 1.1053 - val_accuracy: 0.6407
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 3/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/st\hich\af31506\dbch\af31505\loch\f31506 ep - loss: 0.9259 - accuracy: 0.6844 - val_loss: 1.0803 - val_accuracy: 0.6432
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 4/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 0.8422 - accuracy: 0.7080 - val_loss: 1.0860 - val_accuracy: 0.6400
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 5/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 0.7867 - accuracy: 0.7217 - val_loss: 1.0581 - val_accuracy: 0.6517
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 6/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 0.7422 - accuracy: 0.7341 - val_loss: 1.0697 - val_accuracy: 0.6549
\par \hich\af31506\dbch\af31505\loch\f31506 E\hich\af31506\dbch\af31505\loch\f31506 poch 7/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 6s 28ms/step - loss: 0.7119 - accuracy: 0.7439 - val_loss: 1.1094 - val_accuracy: 0.6565
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 8/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 0.6884 - accuracy: 0.7529 - val_loss: 1.0876 - val_accuracy: 0.6510
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 9/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 6s 28ms/step - loss: 0.6691 - accuracy: 0.7553 - val_loss: 1.1363 - val_accuracy: 0.6538
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 10/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 0.6535 - accuracy: 0.7605 - val_loss: 1.0853 - val_accuracy: 0.6537
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 11/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 0.6400 - accuracy: 0.7642 - val_loss: 1.1421 - val_accuracy: 0.6538
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 12/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 0.6309 - accu\hich\af31506\dbch\af31505\loch\f31506 racy: 0.7674 - val_loss: 1.1833 - val_accuracy: 0.6460
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 13/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 6s 28ms/step - loss: 0.6173 - accuracy: 0.7696 - val_loss: 1.1592 - val_accuracy: 0.6430
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 14/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 0.6127 - accuracy: 0.7689 - val_loss: 1.1229 - val_accuracy: 0.6539
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 15/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 0.6084 - accuracy: 0.7747 - val_loss: 1.1655 - val_accuracy: 0.6472
\par \hich\af31506\dbch\af31505\loch\f31506 process = 18793.84064 \hich\af31506\dbch\af31505\loch\f31506 total = 34176.229376 available = 13667.77856 used = 20508.450816 free = 13667.77856 percent = 60.0
\par \hich\af31506\dbch\af31505\loch\f31506 No weights found or loading not requested for fold 2, feature 4. Starting training.
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 1/100
\par \hich\af31506\dbch\af31505\loch\f31506 
  1/233 [..............................] - ETA: 0s - loss: 4.1759 - accuracy: 0.0000e+00WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0090s vs `on_train_batch_end` time: 0.0140s). Check your cal
\hich\af31506\dbch\af31505\loch\f31506 lbacks.
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/ste\hich\af31506\dbch\af31505\loch\f31506 p - loss: 0.9816 - accuracy: 0.7151 - val_loss: 0.5639 - val_accuracy: 0.8237
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 2/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 0.3908 - accuracy: 0.8739 - val_loss: 0.4490 - val_accuracy: 0.8605
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 3/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 0.2493 - accuracy: 0.9149 - val_loss: 0.4228 - val_accuracy: 0.8704
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 4/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 6s 28ms/step - loss: 0.1747 - accuracy: 0.9394 - val_loss: 0.4340 - val_accuracy: 0.8737
\par \hich\af31506\dbch\af31505\loch\f31506 Ep\hich\af31506\dbch\af31505\loch\f31506 och 5/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 6s 27ms/step - loss: 0.1241 - accuracy: 0.9570 - val_loss: 0.5023 - val_accuracy: 0.8692
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 6/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 0.0929 - accuracy: 0.9684 - val_loss: 0.5132 - val_accuracy: 0.8726
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 7/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 6s 28ms/step - loss: 0.0713 - accuracy: 0.9771 - val_loss: 0.5467 - val_accuracy: 0.8766
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 8/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 0.0588 - accuracy: 0.9803 - val_loss: 0.5713 - val_accuracy: 0.8838
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 9/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 6s 27ms/step - loss: 0.0492 - accuracy: 0.9841 - val_loss: 0.6053 - val_accuracy: 0.8762
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 10/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 6s 28ms/step - loss: 0.0493 - accura\hich\af31506\dbch\af31505\loch\f31506 cy: 0.9844 - val_loss: 0.6388 - val_accuracy: 0.8690
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 11/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 6s 28ms/step - loss: 0.0470 - accuracy: 0.9848 - val_loss: 0.6561 - val_accuracy: 0.8753
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 12/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 0.0410 - accuracy: 0.9872 - val_loss: 0.6287 - val_accuracy: 0.8805
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 13/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 6s 28ms/step - loss: 0.0356 - accuracy: 0.9893 - val_loss: 0.6581 - val_accuracy: 0.8844
\par \hich\af31506\dbch\af31505\loch\f31506 process = 18274.758656 t\hich\af31506\dbch\af31505\loch\f31506 otal = 34176.229376 available = 14101.471232 used = 20074.758144 free = 14101.471232 percent = 58.7
\par \hich\af31506\dbch\af31505\loch\f31506 No weights found or loading not requested for fold 3, feature 1. Starting training.
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 1/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 29ms/step - loss: 1.1555 - accuracy: 0.6582 - val_loss: 0.7840 - val_accuracy: 0.7527
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 2/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 6s 28ms/step - loss: 0.5777 - accuracy: 0.8017 - val_loss: 0.6506 - val_accuracy: 0.7875
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 3/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [===================\hich\af31506\dbch\af31505\loch\f31506 ===========] - 7s 28ms/step - loss: 0.4286 - accuracy: 0.8503 - val_loss: 0.6300 - val_accuracy: 0.7992
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 4/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 6s 28ms/step - loss: 0.3568 - accuracy: 0.8738 - val_loss: 0.6454 - val_accuracy: 0.7951
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 5/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 6s 28ms/step - loss: 0.3034 - accuracy: 0.8913 - val_loss: 0.6882 - val_accuracy: 0.7877
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 6/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 0.2692 - accuracy: 0.9033 - val_loss: 0.6299\hich\af31506\dbch\af31505\loch\f31506  - val_accuracy: 0.8039
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 7/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 6s 28ms/step - loss: 0.2427 - accuracy: 0.9110 - val_loss: 0.6861 - val_accuracy: 0.8057
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 8/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 6s 28ms/step - loss: 0.2257 - accuracy: 0.9165 - val_loss: 0.6466 - val_accuracy: 0.7976
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 9/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 6s 28ms/step - loss: 0.2150 - accuracy: 0.9216 - val_loss: 0.6940 - val_accuracy: 0.7994
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 10/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 6s 28ms/step - loss: 0.2082 - accura\hich\af31506\dbch\af31505\loch\f31506 cy: 0.9209 - val_loss: 0.6927 - val_accuracy: 0.7996
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 11/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 0.1982 - accuracy: 0.9248 - val_loss: 0.6700 - val_accuracy: 0.7956
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 12/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 0.1908 - accuracy: 0.9262 - val_loss: 0.6830 - val_accuracy: 0.7986
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 13/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 6s 27ms/step - loss: 0.1894 - accuracy: 0.9267 - val_loss: 0.7296 - val_accuracy: 0.7926
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 14/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==\hich\af31506\dbch\af31505\loch\f31506 ============================] - 7s 28ms/step - loss: 0.1870 - accuracy: 0.9275 - val_loss: 0.6694 - val_accuracy: 0.8041
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 15/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 0.1822 - accuracy: 0.9287 - val_loss: 0.7274 - val_accuracy: 0.7955
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 16/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 0.1802 - accuracy: 0.9287 - val_loss: 0.6886 - val_accuracy: 0.8004
\par \hich\af31506\dbch\af31505\loch\f31506 process = 18489.622528 total = 34176.229376 available = 13868.609536 used = 20307.61984 free = 13868.\hich\af31506\dbch\af31505\loch\f31506 609536 percent = 59.4
\par \hich\af31506\dbch\af31505\loch\f31506 No weights found or loading not requested for fold 3, feature 2. Starting training.
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 1/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 1.1623 - accuracy: 0.6596 - val_loss: 0.7442 - val_accuracy: 0.7595
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 2/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 0.5631 - accuracy: 0.8079 - val_loss: 0.6261 - val_accuracy: 0.7960
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 3/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 6s 28ms/step - loss: 0.4125 - accuracy: 0.8556 - val_loss: 0.60\hich\af31506\dbch\af31505\loch\f31506 55 - val_accuracy: 0.8018
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 4/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 6s 27ms/step - loss: 0.3360 - accuracy: 0.8799 - val_loss: 0.6086 - val_accuracy: 0.8075
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 5/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 0.2772 - accuracy: 0.9011 - val_loss: 0.6049 - val_accuracy: 0.8139
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 6/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 0.2495 - accuracy: 0.9135 - val_loss: 0.6155 - val_accuracy: 0.8106
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 7/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 0.2218 - accuracy: 0.9217 - val_loss: 0.6115 - val_accuracy: 0.8125
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 8/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 6s 28ms/step - loss: 0.2038 - accurac\hich\af31506\dbch\af31505\loch\f31506 y: 0.9276 - val_loss: 0.6554 - val_accuracy: 0.8134
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 9/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 0.1935 - accuracy: 0.9306 - val_loss: 0.6270 - val_accuracy: 0.8125
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 10/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 6s 28ms/step - loss: 0.1799 - accuracy: 0.9351 - val_loss: 0.6956 - val_accuracy: 0.8120
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 11/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 6s 28ms/step - loss: 0.1726 - accuracy: 0.9351 - val_loss: 0.6664 - val_accuracy: 0.8130
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 12/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [====\hich\af31506\dbch\af31505\loch\f31506 ==========================] - 7s 28ms/step - loss: 0.1727 - accuracy: 0.9348 - val_loss: 0.6814 - val_accuracy: 0.8106
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 13/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 0.1665 - accuracy: 0.9380 - val_loss: 0.6974 - val_accuracy: 0.8101
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 14/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 0.1608 - accuracy: 0.9396 - val_loss: 0.6458 - val_accuracy: 0.8105
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 15/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 0.1593 - accuracy: 0.9395 \hich\af31506\dbch\af31505\loch\f31506 - val_loss: 0.6782 - val_accuracy: 0.8214
\par \hich\af31506\dbch\af31505\loch\f31506 process = 18670.297088 total = 34176.229376 available = 13981.360128 used = 20194.869248 free = 13981.360128 percent = 59.1
\par \hich\af31506\dbch\af31505\loch\f31506 No weights found or loading not requested for fold 3, feature 3. Starting training.
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 1/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 1.6043 - accuracy: 0.5342 - val_loss: 1.2287 - val_accuracy: 0.6117
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 2/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 1.0789 - accuracy: 0.6417 - val_loss: 1.08\hich\af31506\dbch\af31505\loch\f31506 03 - val_accuracy: 0.6431
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 3/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 6s 28ms/step - loss: 0.9383 - accuracy: 0.6816 - val_loss: 1.0319 - val_accuracy: 0.6618
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 4/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 0.8500 - accuracy: 0.7055 - val_loss: 1.0594 - val_accuracy: 0.6559
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 5/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 0.7941 - accuracy: 0.7203 - val_loss: 1.0572 - val_accuracy: 0.6631
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 6/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 0.7527 - accurac\hich\af31506\dbch\af31505\loch\f31506 y: 0.7318 - val_loss: 1.0626 - val_accuracy: 0.6610
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 7/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 0.7205 - accuracy: 0.7412 - val_loss: 1.0688 - val_accuracy: 0.6660
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 8/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 0.6910 - accuracy: 0.7498 - val_loss: 1.0916 - val_accuracy: 0.6579
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 9/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 0.6719 - accuracy: 0.7555 - val_loss: 1.0839 - val_accuracy: 0.6535
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 10/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [======\hich\af31506\dbch\af31505\loch\f31506 ========================] - 6s 27ms/step - loss: 0.6574 - accuracy: 0.7602 - val_loss: 1.1112 - val_accuracy: 0.6591
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 11/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 0.6463 - accuracy: 0.7635 - val_loss: 1.1026 - val_accuracy: 0.6501
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 12/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 0.6357 - accuracy: 0.7650 - val_loss: 1.1210 - val_accuracy: 0.6511
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 13/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 0.6275 - accuracy: 0.7650 - \hich\af31506\dbch\af31505\loch\f31506 val_loss: 1.1433 - val_accuracy: 0.6556
\par \hich\af31506\dbch\af31505\loch\f31506 process = 18814.869504 total = 34176.229376 available = 13781.66784 used = 20394.561536 free = 13781.66784 percent = 59.7
\par \hich\af31506\dbch\af31505\loch\f31506 No weights found or loading not requested for fold 3, feature 4. Starting training.
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 1/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 1.0028 - accuracy: 0.7099 - val_loss: 0.5589 - val_accuracy: 0.8287
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 2/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 6s 28ms/step - loss: 0.3952 - accuracy: 0.8666 - val_loss: 0.4534 -\hich\af31506\dbch\af31505\loch\f31506  val_accuracy: 0.8571
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 3/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 0.2500 - accuracy: 0.9167 - val_loss: 0.4308 - val_accuracy: 0.8670
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 4/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 0.1686 - accuracy: 0.9417 - val_loss: 0.4674 - val_accuracy: 0.8665
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 5/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 29ms/step - loss: 0.1270 - accuracy: 0.9569 - val_loss: 0.4813 - val_accuracy: 0.8725
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 6/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 6s 28ms/step - loss: 0.0954 - accuracy: 0.9678 - val_loss: 0.5861 - val_accuracy: 0.8690
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 7/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 0.0773 - accurac\hich\af31506\dbch\af31505\loch\f31506 y: 0.9742 - val_loss: 0.5513 - val_accuracy: 0.8755
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 8/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 29ms/step - loss: 0.0642 - accuracy: 0.9800 - val_loss: 0.5466 - val_accuracy: 0.8800
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 9/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 0.0507 - accuracy: 0.9826 - val_loss: 0.6323 - val_accuracy: 0.8669
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 10/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 0.0521 - accuracy: 0.9837 - val_loss: 0.5963 - val_accuracy: 0.8775
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 11/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [=====\hich\af31506\dbch\af31505\loch\f31506 =========================] - 6s 27ms/step - loss: 0.0394 - accuracy: 0.9878 - val_loss: 0.6295 - val_accuracy: 0.8793
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 12/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 6s 28ms/step - loss: 0.0378 - accuracy: 0.9881 - val_loss: 0.6544 - val_accuracy: 0.8820
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 13/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 6s 28ms/step - loss: 0.0419 - accuracy: 0.9874 - val_loss: 0.6175 - val_accuracy: 0.8890
\par \hich\af31506\dbch\af31505\loch\f31506 process = 18280.992768 total = 34176.229376 available = 14346.846208 used = 19829.383168 free = 14346.84\hich\af31506\dbch\af31505\loch\f31506 6208 percent = 58.0
\par \hich\af31506\dbch\af31505\loch\f31506 No weights found or loading not requested for fold 4, feature 1. Starting training.
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 1/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 29ms/step - loss: 1.1587 - accuracy: 0.6569 - val_loss: 0.7328 - val_accuracy: 0.7598
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 2/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 0.5785 - accuracy: 0.7995 - val_loss: 0.6319 - val_accuracy: 0.7876
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 3/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 0.4315 - accuracy: 0.8485 - val_loss: 0.5839\hich\af31506\dbch\af31505\loch\f31506  - val_accuracy: 0.8008
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 4/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 6s 28ms/step - loss: 0.3590 - accuracy: 0.8711 - val_loss: 0.5865 - val_accuracy: 0.8070
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 5/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 0.3055 - accuracy: 0.8899 - val_loss: 0.6081 - val_accuracy: 0.8040
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 6/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 0.2704 - accuracy: 0.9021 - val_loss: 0.6252 - val_accuracy: 0.8056
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 7/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 0.2493 - accurac\hich\af31506\dbch\af31505\loch\f31506 y: 0.9077 - val_loss: 0.6192 - val_accuracy: 0.8146
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 8/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 6s 28ms/step - loss: 0.2293 - accuracy: 0.9152 - val_loss: 0.6385 - val_accuracy: 0.8076
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 9/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 0.2193 - accuracy: 0.9182 - val_loss: 0.6310 - val_accuracy: 0.8123
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 10/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 0.2098 - accuracy: 0.9225 - val_loss: 0.6518 - val_accuracy: 0.8114
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 11/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [=====\hich\af31506\dbch\af31505\loch\f31506 =========================] - 7s 28ms/step - loss: 0.2038 - accuracy: 0.9232 - val_loss: 0.6467 - val_accuracy: 0.8143
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 12/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 0.1968 - accuracy: 0.9253 - val_loss: 0.6294 - val_accuracy: 0.8150
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 13/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 6s 28ms/step - loss: 0.1907 - accuracy: 0.9270 - val_loss: 0.6315 - val_accuracy: 0.8153
\par \hich\af31506\dbch\af31505\loch\f31506 process = 18495.819776 total = 34176.229376 available = 14099.23072 used = 20076.998656 free = 14099.230\hich\af31506\dbch\af31505\loch\f31506 72 percent = 58.7
\par \hich\af31506\dbch\af31505\loch\f31506 No weights found or loading not requested for fold 4, feature 2. Starting training.
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 1/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 29ms/step - loss: 1.1602 - accuracy: 0.6573 - val_loss: 0.7463 - val_accuracy: 0.7578
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 2/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 0.5590 - accuracy: 0.8098 - val_loss: 0.6394 - val_accuracy: 0.7919
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 3/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 0.4110 - accuracy: 0.8545 - val_loss: 0.5949 -\hich\af31506\dbch\af31505\loch\f31506  val_accuracy: 0.8040
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 4/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 0.3295 - accuracy: 0.8821 - val_loss: 0.5806 - val_accuracy: 0.8137
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 5/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 0.2763 - accuracy: 0.9018 - val_loss: 0.5963 - val_accuracy: 0.8131
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 6/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 0.2444 - accuracy: 0.9139 - val_loss: 0.6031 - val_accuracy: 0.8121
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 7/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 0.2191 - accuracy: 0.9212 - val_loss: 0.6188 - val_accuracy: 0.8172
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 8/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 0.2076 - accurac\hich\af31506\dbch\af31505\loch\f31506 y: 0.9249 - val_loss: 0.6083 - val_accuracy: 0.8157
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 9/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 6s 28ms/step - loss: 0.1934 - accuracy: 0.9289 - val_loss: 0.6130 - val_accuracy: 0.8213
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 10/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 6s 28ms/step - loss: 0.1854 - accuracy: 0.9332 - val_loss: 0.6259 - val_accuracy: 0.8229
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 11/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 0.1802 - accuracy: 0.9329 - val_loss: 0.6039 - val_accuracy: 0.8149
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 12/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [====\hich\af31506\dbch\af31505\loch\f31506 ==========================] - 7s 28ms/step - loss: 0.1746 - accuracy: 0.9344 - val_loss: 0.6087 - val_accuracy: 0.8270
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 13/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 0.1676 - accuracy: 0.9355 - val_loss: 0.6653 - val_accuracy: 0.8178
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 14/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 0.1695 - accuracy: 0.9354 - val_loss: 0.6221 - val_accuracy: 0.8196
\par \hich\af31506\dbch\af31505\loch\f31506 process = 18677.08416 total = 34176.229376 available = 13925.187584 used = 20251.041792 free = 13925.18\hich\af31506\dbch\af31505\loch\f31506 7584 percent = 59.3
\par \hich\af31506\dbch\af31505\loch\f31506 No weights found or loading not requested for fold 4, feature 3. Starting training.
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 1/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 29ms/step - loss: 1.5947 - accuracy: 0.5351 - val_loss: 1.2813 - val_accuracy: 0.5975
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 2/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 1.0783 - accuracy: 0.6456 - val_loss: 1.1201 - val_accuracy: 0.6393
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 3/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 0.9275 - accuracy: 0.6840 - val_loss: 1.0612\hich\af31506\dbch\af31505\loch\f31506  - val_accuracy: 0.6576
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 4/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 29ms/step - loss: 0.8419 - accuracy: 0.7064 - val_loss: 1.0665 - val_accuracy: 0.6553
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 5/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 29ms/step - loss: 0.7865 - accuracy: 0.7212 - val_loss: 1.0840 - val_accuracy: 0.6458
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 6/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 29ms/step - loss: 0.7431 - accuracy: 0.7356 - val_loss: 1.0579 - val_accuracy: 0.6475
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 7/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 0.7101 - accurac\hich\af31506\dbch\af31505\loch\f31506 y: 0.7427 - val_loss: 1.0735 - val_accuracy: 0.6444
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 8/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 0.6880 - accuracy: 0.7512 - val_loss: 1.1186 - val_accuracy: 0.6409
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 9/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 0.6667 - accuracy: 0.7577 - val_loss: 1.1062 - val_accuracy: 0.6487
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 10/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 0.6547 - accuracy: 0.7612 - val_loss: 1.1257 - val_accuracy: 0.6392
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 11/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [=====\hich\af31506\dbch\af31505\loch\f31506 =========================] - 7s 29ms/step - loss: 0.6376 - accuracy: 0.7643 - val_loss: 1.0922 - val_accuracy: 0.6358
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 12/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 0.6249 - accuracy: 0.7702 - val_loss: 1.1463 - val_accuracy: 0.6467
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 13/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 29ms/step - loss: 0.6159 - accuracy: 0.7716 - val_loss: 1.1891 - val_accuracy: 0.6412
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 14/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 0.6057 - accuracy: 0.7744 -\hich\af31506\dbch\af31505\loch\f31506  val_loss: 1.1474 - val_accuracy: 0.6400
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 15/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 0.5995 - accuracy: 0.7735 - val_loss: 1.1855 - val_accuracy: 0.6459
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 16/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 0.5933 - accuracy: 0.7772 - val_loss: 1.3736 - val_accuracy: 0.6397
\par \hich\af31506\dbch\af31505\loch\f31506 process = 18822.279168 total = 34176.229376 available = 13702.467584 used = 20473.761792 free = 13702.467584 percent = 59.9
\par \hich\af31506\dbch\af31505\loch\f31506 No weights found or loading not requested for fold 4, fea\hich\af31506\dbch\af31505\loch\f31506 ture 4. Starting training.
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 1/100
\par \hich\af31506\dbch\af31505\loch\f31506 
  1/233 [..............................] - ETA: 0s - loss: 4.1742 - accuracy: 0.0000e+00WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0090s vs `on_train_batch_end` time: 0.0140s). Check your cal
\hich\af31506\dbch\af31505\loch\f31506 lbacks.
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 1.0260 - accuracy: 0.7053 - val_loss: 0.5570 - val_accuracy: 0.8243
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 2/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 0.4062 - accuracy: 0.8644 - val_loss: 0.4638 - val_accuracy: 0.8495
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 3/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 0.2589 - accuracy: 0.9104 - val_loss: 0.4458 - val_accuracy: 0.8565
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 4/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 0.1827 - accurac\hich\af31506\dbch\af31505\loch\f31506 y: 0.9359 - val_loss: 0.4253 - val_accuracy: 0.8745
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 5/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 29ms/step - loss: 0.1280 - accuracy: 0.9571 - val_loss: 0.4715 - val_accuracy: 0.8716
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 6/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 0.0967 - accuracy: 0.9679 - val_loss: 0.5358 - val_accuracy: 0.8735
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 7/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 6s 28ms/step - loss: 0.0831 - accuracy: 0.9725 - val_loss: 0.4873 - val_accuracy: 0.8791
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 8/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [=======\hich\af31506\dbch\af31505\loch\f31506 =======================] - 7s 28ms/step - loss: 0.0641 - accuracy: 0.9788 - val_loss: 0.5479 - val_accuracy: 0.8737
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 9/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 29ms/step - loss: 0.0633 - accuracy: 0.9795 - val_loss: 0.6009 - val_accuracy: 0.8771
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 10/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 6s 28ms/step - loss: 0.0524 - accuracy: 0.9826 - val_loss: 0.6464 - val_accuracy: 0.8799
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 11/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 6s 27ms/step - loss: 0.0465 - accuracy: 0.9854 - va\hich\af31506\dbch\af31505\loch\f31506 l_loss: 0.6089 - val_accuracy: 0.8841
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 12/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 6s 28ms/step - loss: 0.0315 - accuracy: 0.9908 - val_loss: 0.6398 - val_accuracy: 0.8833
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 13/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 0.0328 - accuracy: 0.9900 - val_loss: 0.6629 - val_accuracy: 0.8788
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 14/100
\par \hich\af31506\dbch\af31505\loch\f31506 233/233 [==============================] - 7s 28ms/step - loss: 0.0392 - accuracy: 0.9877 - val_loss: 0.6491 - val_accuracy: 0.8786
\par \hich\af31506\dbch\af31505\loch\f31506 process = 18289.004544 total = 34176.22\hich\af31506\dbch\af31505\loch\f31506 9376 available = 14580.51072 used = 19595.718656 free = 14580.51072 percent = 57.3
\par \hich\af31506\dbch\af31505\loch\f31506 No weights found or loading not requested for fold 5, feature 1. Starting training.
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 1/100
\par \hich\af31506\dbch\af31505\loch\f31506 234/234 [==============================] - 7s 29ms/step - loss: 1.1633 - accuracy: 0.6533 - val_loss: 0.7163 - val_accuracy: 0.7590
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 2/100
\par \hich\af31506\dbch\af31505\loch\f31506 234/234 [==============================] - 7s 28ms/step - loss: 0.5907 - accuracy: 0.7972 - val_loss: 0.5921 - val_accuracy: 0.7967
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 3/100
\par \hich\af31506\dbch\af31505\loch\f31506 234/234 [==============================] - 7s 28ms/step - loss: 0.4416 - accuracy: 0.8444 - val_loss: 0.6231 - val_accuracy: 0.7874
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 4/100
\par \hich\af31506\dbch\af31505\loch\f31506 234/234 [==============================] - 7s 28ms/step - loss: 0.3703 - accurac\hich\af31506\dbch\af31505\loch\f31506 y: 0.8676 - val_loss: 0.5777 - val_accuracy: 0.8144
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 5/100
\par \hich\af31506\dbch\af31505\loch\f31506 234/234 [==============================] - 7s 28ms/step - loss: 0.3106 - accuracy: 0.8869 - val_loss: 0.5744 - val_accuracy: 0.8111
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 6/100
\par \hich\af31506\dbch\af31505\loch\f31506 234/234 [==============================] - 6s 28ms/step - loss: 0.2786 - accuracy: 0.8997 - val_loss: 0.5888 - val_accuracy: 0.8100
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 7/100
\par \hich\af31506\dbch\af31505\loch\f31506 234/234 [==============================] - 7s 28ms/step - loss: 0.2483 - accuracy: 0.9083 - val_loss: 0.5668 - val_accuracy: 0.8148
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 8/100
\par \hich\af31506\dbch\af31505\loch\f31506 234/234 [=======\hich\af31506\dbch\af31505\loch\f31506 =======================] - 7s 28ms/step - loss: 0.2334 - accuracy: 0.9133 - val_loss: 0.5789 - val_accuracy: 0.8101
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 9/100
\par \hich\af31506\dbch\af31505\loch\f31506 234/234 [==============================] - 6s 27ms/step - loss: 0.2267 - accuracy: 0.9144 - val_loss: 0.5754 - val_accuracy: 0.8198
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 10/100
\par \hich\af31506\dbch\af31505\loch\f31506 234/234 [==============================] - 7s 28ms/step - loss: 0.2137 - accuracy: 0.9185 - val_loss: 0.5723 - val_accuracy: 0.8202
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 11/100
\par \hich\af31506\dbch\af31505\loch\f31506 234/234 [==============================] - 6s 28ms/step - loss: 0.2057 - accuracy: 0.9215 - va\hich\af31506\dbch\af31505\loch\f31506 l_loss: 0.6036 - val_accuracy: 0.8168
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 12/100
\par \hich\af31506\dbch\af31505\loch\f31506 234/234 [==============================] - 7s 28ms/step - loss: 0.1963 - accuracy: 0.9241 - val_loss: 0.6007 - val_accuracy: 0.8232
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 13/100
\par \hich\af31506\dbch\af31505\loch\f31506 234/234 [==============================] - 6s 27ms/step - loss: 0.1931 - accuracy: 0.9244 - val_loss: 0.6442 - val_accuracy: 0.8205
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 14/100
\par \hich\af31506\dbch\af31505\loch\f31506 234/234 [==============================] - 6s 28ms/step - loss: 0.1931 - accuracy: 0.9253 - val_loss: 0.6510 - val_accuracy: 0.8199
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 15/100
\par \hich\af31506\dbch\af31505\loch\f31506 234/234 [==============================] - 7s 28ms/step - loss: 0.1915 - accuracy: 0.9247 - val_loss: 0.6375 - val_accuracy: 0.8148
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 16/100
\par \hich\af31506\dbch\af31505\loch\f31506 234/234 [==============================] - 7s 28ms/step - loss: 0.1877 - accuracy: 0.9255 - val_loss: 0.6137 - val_accuracy: 0.8201
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 17/100
\par \hich\af31506\dbch\af31505\loch\f31506 234/234 [==============================] - 6s 28ms/step - loss: 0.1803 - accuracy: 0.9271 - val_loss: 0.5882 - val_accuracy: 0.8177
\par \hich\af31506\dbch\af31505\loch\f31506 process = 18503.757824 total = 34176.229376 available = 14373.02784 used = 19803.201536 fr\hich\af31506\dbch\af31505\loch\f31506 ee = 14373.02784 percent = 57.9
\par \hich\af31506\dbch\af31505\loch\f31506 No weights found or loading not requested for fold 5, feature 2. Starting training.
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 1/100
\par \hich\af31506\dbch\af31505\loch\f31506 234/234 [==============================] - 7s 28ms/step - loss: 1.2103 - accuracy: 0.6467 - val_loss: 0.7494 - val_accuracy: 0.7574
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 2/100
\par \hich\af31506\dbch\af31505\loch\f31506 234/234 [==============================] - 7s 28ms/step - loss: 0.5916 - accuracy: 0.7997 - val_loss: 0.5888 - val_accuracy: 0.8034
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 3/100
\par \hich\af31506\dbch\af31505\loch\f31506 234/234 [==============================] - 6s 28ms/step - loss: 0.4385 - accuracy: 0.8451 - val_\hich\af31506\dbch\af31505\loch\f31506 loss: 0.5491 - val_accuracy: 0.8132
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 4/100
\par \hich\af31506\dbch\af31505\loch\f31506 234/234 [==============================] - 7s 28ms/step - loss: 0.3498 - accuracy: 0.8734 - val_loss: 0.5431 - val_accuracy: 0.8112
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 5/100
\par \hich\af31506\dbch\af31505\loch\f31506 234/234 [==============================] - 7s 28ms/step - loss: 0.3034 - accuracy: 0.8921 - val_loss: 0.5664 - val_accuracy: 0.8226
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 6/100
\par \hich\af31506\dbch\af31505\loch\f31506 234/234 [==============================] - 7s 28ms/step - loss: 0.2581 - accuracy: 0.9063 - val_loss: 0.5641 - val_accuracy: 0.8269
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 7/100
\par \hich\af31506\dbch\af31505\loch\f31506 234/234 [=======================\hich\af31506\dbch\af31505\loch\f31506 =======] - 6s 28ms/step - loss: 0.2346 - accuracy: 0.9152 - val_loss: 0.5477 - val_accuracy: 0.8279
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 8/100
\par \hich\af31506\dbch\af31505\loch\f31506 234/234 [==============================] - 7s 28ms/step - loss: 0.2173 - accuracy: 0.9220 - val_loss: 0.5657 - val_accuracy: 0.8268
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 9/100
\par \hich\af31506\dbch\af31505\loch\f31506 234/234 [==============================] - 7s 28ms/step - loss: 0.2032 - accuracy: 0.9272 - val_loss: 0.5558 - val_accuracy: 0.8302
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 10/100
\par \hich\af31506\dbch\af31505\loch\f31506 234/234 [==============================] - 7s 28ms/step - loss: 0.1940 - accuracy: 0.9285 - val_loss: 0.6178 - \hich\af31506\dbch\af31505\loch\f31506 val_accuracy: 0.8286
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 11/100
\par \hich\af31506\dbch\af31505\loch\f31506 234/234 [==============================] - 7s 28ms/step - loss: 0.1822 - accuracy: 0.9326 - val_loss: 0.6070 - val_accuracy: 0.8299
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 12/100
\par \hich\af31506\dbch\af31505\loch\f31506 234/234 [==============================] - 7s 28ms/step - loss: 0.1797 - accuracy: 0.9317 - val_loss: 0.5859 - val_accuracy: 0.8229
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 13/100
\par \hich\af31506\dbch\af31505\loch\f31506 234/234 [==============================] - 7s 28ms/step - loss: 0.1753 - accuracy: 0.9332 - val_loss: 0.5839 - val_accuracy: 0.8290
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 14/100
\par \hich\af31506\dbch\af31505\loch\f31506 234/234 [==============================] - 7s 28ms/step - loss: 0.1681 - accuracy: 0.9353 - val_loss: 0.6026 - val_accuracy: 0.8311
\par \hich\af31506\dbch\af31505\loch\f31506 process = 18684.440576 total = 34176.229376 available = 14158.70464 used = 20017.524736 fr\hich\af31506\dbch\af31505\loch\f31506 ee = 14158.70464 percent = 58.6
\par \hich\af31506\dbch\af31505\loch\f31506 No weights found or loading not requested for fold 5, feature 3. Starting training.
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 1/100
\par \hich\af31506\dbch\af31505\loch\f31506 234/234 [==============================] - 7s 28ms/step - loss: 1.6321 - accuracy: 0.5283 - val_loss: 1.2647 - val_accuracy: 0.6058
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 2/100
\par \hich\af31506\dbch\af31505\loch\f31506 234/234 [==============================] - 7s 28ms/step - loss: 1.1077 - accuracy: 0.6410 - val_loss: 1.0622 - val_accuracy: 0.6529
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 3/100
\par \hich\af31506\dbch\af31505\loch\f31506 234/234 [==============================] - 7s 28ms/step - loss: 0.9551 - accuracy: 0.6769 - val_\hich\af31506\dbch\af31505\loch\f31506 loss: 1.0009 - val_accuracy: 0.6621
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 4/100
\par \hich\af31506\dbch\af31505\loch\f31506 234/234 [==============================] - 7s 28ms/step - loss: 0.8741 - accuracy: 0.6985 - val_loss: 1.0061 - val_accuracy: 0.6634
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 5/100
\par \hich\af31506\dbch\af31505\loch\f31506 234/234 [==============================] - 7s 28ms/step - loss: 0.8117 - accuracy: 0.7171 - val_loss: 1.0448 - val_accuracy: 0.6585
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 6/100
\par \hich\af31506\dbch\af31505\loch\f31506 234/234 [==============================] - 7s 28ms/step - loss: 0.7672 - accuracy: 0.7268 - val_loss: 1.0015 - val_accuracy: 0.6577
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 7/100
\par \hich\af31506\dbch\af31505\loch\f31506 234/234 [=======================\hich\af31506\dbch\af31505\loch\f31506 =======] - 7s 28ms/step - loss: 0.7365 - accuracy: 0.7318 - val_loss: 1.0334 - val_accuracy: 0.6644
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 8/100
\par \hich\af31506\dbch\af31505\loch\f31506 234/234 [==============================] - 7s 28ms/step - loss: 0.7139 - accuracy: 0.7445 - val_loss: 1.0048 - val_accuracy: 0.6706
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 9/100
\par \hich\af31506\dbch\af31505\loch\f31506 234/234 [==============================] - 7s 28ms/step - loss: 0.6819 - accuracy: 0.7475 - val_loss: 1.0490 - val_accuracy: 0.6642
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 10/100
\par \hich\af31506\dbch\af31505\loch\f31506 234/234 [==============================] - 7s 28ms/step - loss: 0.6676 - accuracy: 0.7535 - val_loss: 1.0216 - \hich\af31506\dbch\af31505\loch\f31506 val_accuracy: 0.6626
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 11/100
\par \hich\af31506\dbch\af31505\loch\f31506 234/234 [==============================] - 7s 28ms/step - loss: 0.6608 - accuracy: 0.7571 - val_loss: 1.0879 - val_accuracy: 0.6683
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 12/100
\par \hich\af31506\dbch\af31505\loch\f31506 234/234 [==============================] - 7s 28ms/step - loss: 0.6514 - accuracy: 0.7614 - val_loss: 1.0807 - val_accuracy: 0.6597
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 13/100
\par \hich\af31506\dbch\af31505\loch\f31506 234/234 [==============================] - 7s 28ms/step - loss: 0.6375 - accuracy: 0.7635 - val_loss: 1.0513 - val_accuracy: 0.6583
\par \hich\af31506\dbch\af31505\loch\f31506 process = 18829.111296 total = 34176.229376 available = 14023.688192 used = 20152.541184 f\hich\af31506\dbch\af31505\loch\f31506 ree = 14023.688192 percent = 59.0
\par \hich\af31506\dbch\af31505\loch\f31506 No weights found or loading not requested for fold 5, feature 4. Starting training.
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 1/100
\par \hich\af31506\dbch\af31505\loch\f31506 234/234 [==============================] - 7s 28ms/step - loss: 1.0738 - accuracy: 0.6902 - val_loss: 0.5480 - val_accuracy: 0.8179
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 2/100
\par \hich\af31506\dbch\af31505\loch\f31506 234/234 [==============================] - 7s 28ms/step - loss: 0.4172 - accuracy: 0.8604 - val_loss: 0.4117 - val_accuracy: 0.8648
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 3/100
\par \hich\af31506\dbch\af31505\loch\f31506 234/234 [==============================] - 7s 28ms/step - loss: 0.2661 - accuracy: 0.9102 - va\hich\af31506\dbch\af31505\loch\f31506 l_loss: 0.3906 - val_accuracy: 0.8735
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 4/100
\par \hich\af31506\dbch\af31505\loch\f31506 234/234 [==============================] - 7s 28ms/step - loss: 0.1866 - accuracy: 0.9355 - val_loss: 0.4068 - val_accuracy: 0.8777
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 5/100
\par \hich\af31506\dbch\af31505\loch\f31506 234/234 [==============================] - 6s 27ms/step - loss: 0.1286 - accuracy: 0.9555 - val_loss: 0.4787 - val_accuracy: 0.8665
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 6/100
\par \hich\af31506\dbch\af31505\loch\f31506 234/234 [==============================] - 6s 27ms/step - loss: 0.1074 - accuracy: 0.9631 - val_loss: 0.4684 - val_accuracy: 0.8829
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 7/100
\par \hich\af31506\dbch\af31505\loch\f31506 234/234 [=====================\hich\af31506\dbch\af31505\loch\f31506 =========] - 6s 27ms/step - loss: 0.0822 - accuracy: 0.9722 - val_loss: 0.5259 - val_accuracy: 0.8730
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 8/100
\par \hich\af31506\dbch\af31505\loch\f31506 234/234 [==============================] - 7s 28ms/step - loss: 0.0659 - accuracy: 0.9778 - val_loss: 0.5081 - val_accuracy: 0.8804
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 9/100
\par \hich\af31506\dbch\af31505\loch\f31506 234/234 [==============================] - 7s 28ms/step - loss: 0.0502 - accuracy: 0.9835 - val_loss: 0.5468 - val_accuracy: 0.8833
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 10/100
\par \hich\af31506\dbch\af31505\loch\f31506 234/234 [==============================] - 7s 28ms/step - loss: 0.0460 - accuracy: 0.9855 - val_loss: 0.6179 \hich\af31506\dbch\af31505\loch\f31506 - val_accuracy: 0.8765
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 11/100
\par \hich\af31506\dbch\af31505\loch\f31506 234/234 [==============================] - 6s 27ms/step - loss: 0.0577 - accuracy: 0.9816 - val_loss: 0.4943 - val_accuracy: 0.8853
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 12/100
\par \hich\af31506\dbch\af31505\loch\f31506 234/234 [==============================] - 6s 27ms/step - loss: 0.0406 - accuracy: 0.9872 - val_loss: 0.5767 - val_accuracy: 0.8866
\par \hich\af31506\dbch\af31505\loch\f31506 Epoch 13/100
\par \hich\af31506\dbch\af31505\loch\f31506 234/234 [==============================] - 6s 27ms/step - loss: 0.0467 - accuracy: 0.9848 - val_loss: 0.5723 - val_accuracy: 0.8855
\par \hich\af31506\dbch\af31505\loch\f31506 H:\\CondaEnv\\CNNDDIV4\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
\par \hich\af31506\dbch\af31505\loch\f31506   'precision', 'predicted', average, warn_for)
\par \hich\af31506\dbch\af31505\loch\f31506 H:\\C\hich\af31506\dbch\af31505\loch\f31506 ondaEnv\\CNNDDIV4\\lib\\site-packages\\sklearn\\metrics\\
classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
\par \hich\af31506\dbch\af31505\loch\f31506   'precision', 'predicted', average, warn_for)
\par \hich\af31506\dbch\af31505\loch\f31506 H:\\CondaEnv\\CNNDDIV4\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.
\par \hich\af31506\dbch\af31505\loch\f31506   'precision', 'predicted', average, warn_for)
\par \hich\af31506\dbch\af31505\loch\f31506 H:\\CondaEnv\\CNNDDIV4\\lib\\site-packages\\sklearn\\metrics\\class\hich\af31506\dbch\af31505\loch\f31506 
ification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.
\par \hich\af31506\dbch\af31505\loch\f31506   'precision', 'predicted', average, warn_for)
\par \hich\af31506\dbch\af31505\loch\f31506 H:\\CondaEnv\\CNNDDIV4\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.
\par \hich\af31506\dbch\af31505\loch\f31506   'precision', 'predicted', average, warn_for)
\par \hich\af31506\dbch\af31505\loch\f31506 H:\\CondaEnv\\CNNDDIV4\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defi\hich\af31506\dbch\af31505\loch\f31506 
ned and being set to 0.0 due to no predicted samples.
\par \hich\af31506\dbch\af31505\loch\f31506   'precision', 'predicted', average, warn_for)
\par \hich\af31506\dbch\af31505\loch\f31506 
   Accuracy  AUPR (micro-averaged)  AUPR (macro-averaged)  AUC (micro-averaged)  AUC (macro-averaged)  ...  Precision (micro-averaged)  Precision (macro-averaged)  Recall (micro-averaged)  Recall (macro-averaged)     Time (s)
\par \hich\af31506\dbch\af31505\loch\f31506 0  0.881414               0.937987               0.836454              0.997907              0.986606  ...                    0.881414                     0.84733                 0.8814
\hich\af31506\dbch\af31505\loch\f31506 14                 0.735267  1916.163714
\par 
\par \hich\af31506\dbch\af31505\loch\f31506 [1 rows x 12 columns]
\par \hich\af31506\dbch\af31505\loch\f31506 time used for CNN_DDI: 1916.1637143
\par \hich\af31506\dbch\af31505\loch\f31506 Total time used: 1916.179158
\par \hich\af31506\dbch\af31505\loch\f31506 done}{\rtlch\fcs1 \af31507 \ltrch\fcs0 \insrsid9832040 
\par }{\*\themedata 504b030414000600080000002100e9de0fbfff0000001c020000130000005b436f6e74656e745f54797065735d2e786d6cac91cb4ec3301045f748fc83e52d4a
9cb2400825e982c78ec7a27cc0c8992416c9d8b2a755fbf74cd25442a820166c2cd933f79e3be372bd1f07b5c3989ca74aaff2422b24eb1b475da5df374fd9ad
5689811a183c61a50f98f4babebc2837878049899a52a57be670674cb23d8e90721f90a4d2fa3802cb35762680fd800ecd7551dc18eb899138e3c943d7e503b6
b01d583deee5f99824e290b4ba3f364eac4a430883b3c092d4eca8f946c916422ecab927f52ea42b89a1cd59c254f919b0e85e6535d135a8de20f20b8c12c3b0
0c895fcf6720192de6bf3b9e89ecdbd6596cbcdd8eb28e7c365ecc4ec1ff1460f53fe813d3cc7f5b7f020000ffff0300504b030414000600080000002100a5d6
a7e7c0000000360100000b0000005f72656c732f2e72656c73848fcf6ac3300c87ef85bd83d17d51d2c31825762fa590432fa37d00e1287f68221bdb1bebdb4f
c7060abb0884a4eff7a93dfeae8bf9e194e720169aaa06c3e2433fcb68e1763dbf7f82c985a4a725085b787086a37bdbb55fbc50d1a33ccd311ba548b6309512
0f88d94fbc52ae4264d1c910d24a45db3462247fa791715fd71f989e19e0364cd3f51652d73760ae8fa8c9ffb3c330cc9e4fc17faf2ce545046e37944c69e462
a1a82fe353bd90a865aad41ed0b5b8f9d6fd010000ffff0300504b0304140006000800000021006b799616830000008a0000001c0000007468656d652f746865
6d652f7468656d654d616e616765722e786d6c0ccc4d0ac3201040e17da17790d93763bb284562b2cbaebbf600439c1a41c7a0d29fdbd7e5e38337cedf14d59b
4b0d592c9c070d8a65cd2e88b7f07c2ca71ba8da481cc52c6ce1c715e6e97818c9b48d13df49c873517d23d59085adb5dd20d6b52bd521ef2cdd5eb9246a3d8b
4757e8d3f729e245eb2b260a0238fd010000ffff0300504b03041400060008000000210094a9528694070000c7200000160000007468656d652f7468656d652f
7468656d65312e786d6cec595f8b1bc9117f0fe43b0cf32e6b66248da4c5f2a1bfdeb3776d63c90ef7d82bb566dadb333d4cb7762d8e83e07bca4b207077e421
0779cb430839c8418ebce4c3186c92cb874875cf68d42db5bc7f30c184dd7dd1b47e55fd9baaeaaa52f5fdcf5e27d4b9c039272cedb9fe3dcf75703a670b9246
3df7c56c52ebb80e17285d20ca52dc73d798bb9f3df8e52feea32311e3043b209ff223d4736321b2a37a9dcf6119f17b2cc3297cb7647982043ce6517d91a34b
d09bd07ae079613d4124759d1425a0f6e97249e6d8994995ee838df23185c75470b930a7f954aac68684c22ece7d89e06b3ea4b9738168cf857d16ec72865f0b
d7a1880bf8a2e77aeacfad3fb85f4747a51015076435b989fa2be54a81c579a0f6cca3b36a536f1c749a7ea55f01a8d8c78d3bf2bfd2a700683e87372db8e83a
fd56e8758212ab818a8f16ddddb6df30f19afec61e67bf1b0e82a6a15f810afdcd3dbc37e98e472d03af4005beb587ef7bc1a0db30f00a54e0c33d7c73dc6f07
6303af403125e9f93e3a6c773a6189ae204b468fadf06e187aed5109dfa2201aaae8925b2c592a0ec55a825eb17c020009a44890d411eb0c2fd11ca2b89f09c6
9d11e119456bd7c950ca382c7b81ef43e835bda0fa571647471869d2921730e17b4b928fc3e739c944cf7d045a5d0df2eea79fdebef9f1ed9bbfbffdfaebb76f
feea9c902816852a43ee18a5912ef7f39f7ef79fef7fedfcfb6f7ffcf99b6fed78aee3dfffe537effff1cf0fa987a3b635c5bbef7e78ffe30fef7effdb7ffdf9
1b8bf67e8ece74f88c24983b4ff0a5f39c25f082ca14267f7c96df4c621623a24bf4d388a314c95d2cfac72236d04fd688220b6e804d3bbecc21d5d8800f57af
0cc2d3385f0962d1f8384e0ce0296374c072ab151ecbbd3433cf566964df3c5fe9b8e7085dd8f61ea2d4f0f27895418e253695c3181b349f51940a14e1140b47
7ec7ce31b6bcdd178418763d25f39c71b614ce17c419206235c98c9c19d1b4153a2609f8656d2308fe366c73fad219306a7beb11be3091703610b5909f616a98
f1215a0994d854ce504275839f2011db484ed7f95cc78db9004f47983267bcc09cdb649ee6f0be9ad31f23c86e56b79fd27562227341ce6d3a4f10633a72c4ce
87314a321b764ad258c77ececf214491f38c091bfc949927443e831f507ad0dd2f0936dc7d75367801594ea7b40d10f9cd2ab7f8f2216646fc4ed77489b02dd5
f4f3c448b1fd9c58a363b08a8cd03ec198a24bb4c0d879f1b985c1806586cdb7a41fc590558eb12db01e213356e5738a39f44ab2b9d9cf9327841b213bc5113b
c0e774bd9378d6284d507e48f313f0ba6ef3f1590e87d142e1299d9febc027047a408817ab519e72d0a105f741adcf62641430f9ccedf1bace0dff5de78cc1b9
7c65d0b8c6b904197c631948ecbacc076d3343d4d8601b3033449c135bba0511c3fd5b11595c95d8ca2ab7340fedd60dd01d194d4f42d22b3aa0ff5de703fdc5
bb3f7c6f09c18fd3edd8151ba9ea867dcea15472bcd3dd1cc2edf63443962fc8a7dfd28cd02a7d86a18aece7abbb8ee6aea371ffef3b9a43e7f9ae8f39d46ddc
f5312ef417777d4c395af9387dccb67581ae468e178a318f1afa2407673e4b42e954ac293ee16aecc3e1d7cc62028b524ecd3b713503cc62f828cb1c6c60e0a2
1c29192767e25744c4d31865301bf25da924e2a5ea883b19e3303252cb56dd124f57c9295b14a34e355bf28acaca91d8ae7b2d183a15eb30a612053a6c978b92
9f9aa7025fc5365263d60d01297b1312da6626898685447bb37805093935fb382cba16161da97ee3aa3d5300b5ca2bf073db811fe93db7d594846046cee7d09a
2fa49f0a576fbcab9cf9313d7dc8984604c058b1781318ca579eee4aae075f4fbe5d116ad7f0b4414239a5082b9384b28c6af0780c3f82cbe894abd7a171535f
77b72e35e84953a8fd20beb734da9d0fb1b8adaf416e3737d054cf1434752e7b6ed86841c8cc51d673973032868f4906b1c3e52f2e4423b877998bbc38f0b7c9
2c59cec508f1b830b84a3a857b122270ee5092f45cf9fa951b68aa7288e2e60790103e59725d482b9f1a3970bae964bc5ce2b9d0ddaead484b178f90e18b5c61
fd5689df1e2c25d90adc3d8d1797ce195de5cf118458abed4b032e08879b03bfb0e682c0555895c8b6f1b75398cae4afdf45a9182ad611cd625456143d991770
554f2a3aeaa9b281f654be33185433495908cf22596075a31ad5b42a5d05878355f76a2169392d696e6ba6915564d5b4673163874d19d8b1e5ed8abcc66a6362
c8697a852f52f76ecaed6e72dd4e9f505509307865bfdb957e8dda7633839a64bc9f8665ce2e57cddab179c12ba85da74868593fdca8ddb15b5523acdbc1e2ad
2a3fc8ed462d2c2d377da5b2b4ba33d7afb5d9d92b481e23e872575470e54a98ebe608bab2a9ea498ab40147e4b5288f067c725639e9b95f7aad7e7318b48635
afd31ad79a8da657ebb4fa8d5abfd56af8e396ef8d06c1575058449cf8ade2be7e02d717745ddedaabf5bd9bfb647343736fce923a5337f375455cdddcfbc1e1
9b7b8740d2f93218fbcda01f0c6bc3911fd69ac128ac75da8d7e6d1884a3a00f293d9cf4bf729d0b05f607a3d164d20a6ae110704dafdfaaf5078d612dec8c07
c1c41f37471e80cbccf91afa6fb0e9c616f051f17af05f000000ffff0300504b0304140006000800000021000dd1909fb60000001b010000270000007468656d
652f7468656d652f5f72656c732f7468656d654d616e616765722e786d6c2e72656c73848f4d0ac2301484f78277086f6fd3ba109126dd88d0add40384e4350d
363f2451eced0dae2c082e8761be9969bb979dc9136332de3168aa1a083ae995719ac16db8ec8e4052164e89d93b64b060828e6f37ed1567914b284d26245228
2e3198720e274a939cd08a54f980ae38a38f56e422a3a641c8bbd048f7757da0f19b017cc524bd62107bd5001996509affb3fd381a89672f1f165dfe514173d9
850528a2c6cce0239baa4c04ca5bbabac4df000000ffff0300504b01022d0014000600080000002100e9de0fbfff0000001c0200001300000000000000000000
000000000000005b436f6e74656e745f54797065735d2e786d6c504b01022d0014000600080000002100a5d6a7e7c0000000360100000b000000000000000000
00000000300100005f72656c732f2e72656c73504b01022d00140006000800000021006b799616830000008a0000001c00000000000000000000000000190200
007468656d652f7468656d652f7468656d654d616e616765722e786d6c504b01022d001400060008000000210094a9528694070000c720000016000000000000
00000000000000d60200007468656d652f7468656d652f7468656d65312e786d6c504b01022d00140006000800000021000dd1909fb60000001b010000270000
00000000000000000000009e0a00007468656d652f7468656d652f5f72656c732f7468656d654d616e616765722e786d6c2e72656c73504b050600000000050005005d010000990b00000000}
{\*\colorschememapping 3c3f786d6c2076657273696f6e3d22312e302220656e636f64696e673d225554462d3822207374616e64616c6f6e653d22796573223f3e0d0a3c613a636c724d
617020786d6c6e733a613d22687474703a2f2f736368656d61732e6f70656e786d6c666f726d6174732e6f72672f64726177696e676d6c2f323030362f6d6169
6e22206267313d226c743122207478313d22646b3122206267323d226c743222207478323d22646b322220616363656e74313d22616363656e74312220616363
656e74323d22616363656e74322220616363656e74333d22616363656e74332220616363656e74343d22616363656e74342220616363656e74353d22616363656e74352220616363656e74363d22616363656e74362220686c696e6b3d22686c696e6b2220666f6c486c696e6b3d22666f6c486c696e6b222f3e}
{\*\latentstyles\lsdstimax376\lsdlockeddef0\lsdsemihiddendef0\lsdunhideuseddef0\lsdqformatdef0\lsdprioritydef99{\lsdlockedexcept \lsdqformat1 \lsdpriority0 \lsdlocked0 Normal;\lsdqformat1 \lsdpriority9 \lsdlocked0 heading 1;
\lsdsemihidden1 \lsdunhideused1 \lsdqformat1 \lsdpriority9 \lsdlocked0 heading 2;\lsdsemihidden1 \lsdunhideused1 \lsdqformat1 \lsdpriority9 \lsdlocked0 heading 3;\lsdsemihidden1 \lsdunhideused1 \lsdqformat1 \lsdpriority9 \lsdlocked0 heading 4;
\lsdsemihidden1 \lsdunhideused1 \lsdqformat1 \lsdpriority9 \lsdlocked0 heading 5;\lsdsemihidden1 \lsdunhideused1 \lsdqformat1 \lsdpriority9 \lsdlocked0 heading 6;\lsdsemihidden1 \lsdunhideused1 \lsdqformat1 \lsdpriority9 \lsdlocked0 heading 7;
\lsdsemihidden1 \lsdunhideused1 \lsdqformat1 \lsdpriority9 \lsdlocked0 heading 8;\lsdsemihidden1 \lsdunhideused1 \lsdqformat1 \lsdpriority9 \lsdlocked0 heading 9;\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 index 1;
\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 index 2;\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 index 3;\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 index 4;\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 index 5;
\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 index 6;\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 index 7;\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 index 8;\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 index 9;
\lsdsemihidden1 \lsdunhideused1 \lsdpriority39 \lsdlocked0 toc 1;\lsdsemihidden1 \lsdunhideused1 \lsdpriority39 \lsdlocked0 toc 2;\lsdsemihidden1 \lsdunhideused1 \lsdpriority39 \lsdlocked0 toc 3;
\lsdsemihidden1 \lsdunhideused1 \lsdpriority39 \lsdlocked0 toc 4;\lsdsemihidden1 \lsdunhideused1 \lsdpriority39 \lsdlocked0 toc 5;\lsdsemihidden1 \lsdunhideused1 \lsdpriority39 \lsdlocked0 toc 6;
\lsdsemihidden1 \lsdunhideused1 \lsdpriority39 \lsdlocked0 toc 7;\lsdsemihidden1 \lsdunhideused1 \lsdpriority39 \lsdlocked0 toc 8;\lsdsemihidden1 \lsdunhideused1 \lsdpriority39 \lsdlocked0 toc 9;\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 Normal Indent;
\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 footnote text;\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 annotation text;\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 header;\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 footer;
\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 index heading;\lsdsemihidden1 \lsdunhideused1 \lsdqformat1 \lsdpriority35 \lsdlocked0 caption;\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 table of figures;
\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 envelope address;\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 envelope return;\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 footnote reference;\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 annotation reference;
\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 line number;\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 page number;\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 endnote reference;\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 endnote text;
\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 table of authorities;\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 macro;\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 toa heading;\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 List;
\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 List Bullet;\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 List Number;\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 List 2;\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 List 3;
\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 List 4;\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 List 5;\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 List Bullet 2;\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 List Bullet 3;
\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 List Bullet 4;\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 List Bullet 5;\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 List Number 2;\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 List Number 3;
\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 List Number 4;\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 List Number 5;\lsdqformat1 \lsdpriority10 \lsdlocked0 Title;\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 Closing;
\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 Signature;\lsdsemihidden1 \lsdunhideused1 \lsdpriority1 \lsdlocked0 Default Paragraph Font;\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 Body Text;\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 Body Text Indent;
\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 List Continue;\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 List Continue 2;\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 List Continue 3;\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 List Continue 4;
\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 List Continue 5;\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 Message Header;\lsdqformat1 \lsdpriority11 \lsdlocked0 Subtitle;\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 Salutation;
\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 Date;\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 Body Text First Indent;\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 Body Text First Indent 2;\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 Note Heading;
\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 Body Text 2;\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 Body Text 3;\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 Body Text Indent 2;\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 Body Text Indent 3;
\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 Block Text;\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 Hyperlink;\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 FollowedHyperlink;\lsdqformat1 \lsdpriority22 \lsdlocked0 Strong;
\lsdqformat1 \lsdpriority20 \lsdlocked0 Emphasis;\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 Document Map;\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 Plain Text;\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 E-mail Signature;
\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 HTML Top of Form;\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 HTML Bottom of Form;\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 Normal (Web);\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 HTML Acronym;
\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 HTML Address;\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 HTML Cite;\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 HTML Code;\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 HTML Definition;
\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 HTML Keyboard;\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 HTML Preformatted;\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 HTML Sample;\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 HTML Typewriter;
\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 HTML Variable;\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 Normal Table;\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 annotation subject;\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 No List;
\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 Outline List 1;\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 Outline List 2;\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 Outline List 3;\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 Table Simple 1;
\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 Table Simple 2;\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 Table Simple 3;\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 Table Classic 1;\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 Table Classic 2;
\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 Table Classic 3;\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 Table Classic 4;\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 Table Colorful 1;\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 Table Colorful 2;
\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 Table Colorful 3;\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 Table Columns 1;\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 Table Columns 2;\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 Table Columns 3;
\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 Table Columns 4;\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 Table Columns 5;\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 Table Grid 1;\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 Table Grid 2;
\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 Table Grid 3;\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 Table Grid 4;\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 Table Grid 5;\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 Table Grid 6;
\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 Table Grid 7;\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 Table Grid 8;\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 Table List 1;\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 Table List 2;
\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 Table List 3;\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 Table List 4;\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 Table List 5;\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 Table List 6;
\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 Table List 7;\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 Table List 8;\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 Table 3D effects 1;\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 Table 3D effects 2;
\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 Table 3D effects 3;\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 Table Contemporary;\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 Table Elegant;\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 Table Professional;
\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 Table Subtle 1;\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 Table Subtle 2;\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 Table Web 1;\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 Table Web 2;
\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 Table Web 3;\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 Balloon Text;\lsdpriority39 \lsdlocked0 Table Grid;\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 Table Theme;\lsdsemihidden1 \lsdlocked0 Placeholder Text;
\lsdqformat1 \lsdpriority1 \lsdlocked0 No Spacing;\lsdpriority60 \lsdlocked0 Light Shading;\lsdpriority61 \lsdlocked0 Light List;\lsdpriority62 \lsdlocked0 Light Grid;\lsdpriority63 \lsdlocked0 Medium Shading 1;\lsdpriority64 \lsdlocked0 Medium Shading 2;
\lsdpriority65 \lsdlocked0 Medium List 1;\lsdpriority66 \lsdlocked0 Medium List 2;\lsdpriority67 \lsdlocked0 Medium Grid 1;\lsdpriority68 \lsdlocked0 Medium Grid 2;\lsdpriority69 \lsdlocked0 Medium Grid 3;\lsdpriority70 \lsdlocked0 Dark List;
\lsdpriority71 \lsdlocked0 Colorful Shading;\lsdpriority72 \lsdlocked0 Colorful List;\lsdpriority73 \lsdlocked0 Colorful Grid;\lsdpriority60 \lsdlocked0 Light Shading Accent 1;\lsdpriority61 \lsdlocked0 Light List Accent 1;
\lsdpriority62 \lsdlocked0 Light Grid Accent 1;\lsdpriority63 \lsdlocked0 Medium Shading 1 Accent 1;\lsdpriority64 \lsdlocked0 Medium Shading 2 Accent 1;\lsdpriority65 \lsdlocked0 Medium List 1 Accent 1;\lsdsemihidden1 \lsdlocked0 Revision;
\lsdqformat1 \lsdpriority34 \lsdlocked0 List Paragraph;\lsdqformat1 \lsdpriority29 \lsdlocked0 Quote;\lsdqformat1 \lsdpriority30 \lsdlocked0 Intense Quote;\lsdpriority66 \lsdlocked0 Medium List 2 Accent 1;\lsdpriority67 \lsdlocked0 Medium Grid 1 Accent 1;
\lsdpriority68 \lsdlocked0 Medium Grid 2 Accent 1;\lsdpriority69 \lsdlocked0 Medium Grid 3 Accent 1;\lsdpriority70 \lsdlocked0 Dark List Accent 1;\lsdpriority71 \lsdlocked0 Colorful Shading Accent 1;\lsdpriority72 \lsdlocked0 Colorful List Accent 1;
\lsdpriority73 \lsdlocked0 Colorful Grid Accent 1;\lsdpriority60 \lsdlocked0 Light Shading Accent 2;\lsdpriority61 \lsdlocked0 Light List Accent 2;\lsdpriority62 \lsdlocked0 Light Grid Accent 2;\lsdpriority63 \lsdlocked0 Medium Shading 1 Accent 2;
\lsdpriority64 \lsdlocked0 Medium Shading 2 Accent 2;\lsdpriority65 \lsdlocked0 Medium List 1 Accent 2;\lsdpriority66 \lsdlocked0 Medium List 2 Accent 2;\lsdpriority67 \lsdlocked0 Medium Grid 1 Accent 2;\lsdpriority68 \lsdlocked0 Medium Grid 2 Accent 2;
\lsdpriority69 \lsdlocked0 Medium Grid 3 Accent 2;\lsdpriority70 \lsdlocked0 Dark List Accent 2;\lsdpriority71 \lsdlocked0 Colorful Shading Accent 2;\lsdpriority72 \lsdlocked0 Colorful List Accent 2;\lsdpriority73 \lsdlocked0 Colorful Grid Accent 2;
\lsdpriority60 \lsdlocked0 Light Shading Accent 3;\lsdpriority61 \lsdlocked0 Light List Accent 3;\lsdpriority62 \lsdlocked0 Light Grid Accent 3;\lsdpriority63 \lsdlocked0 Medium Shading 1 Accent 3;\lsdpriority64 \lsdlocked0 Medium Shading 2 Accent 3;
\lsdpriority65 \lsdlocked0 Medium List 1 Accent 3;\lsdpriority66 \lsdlocked0 Medium List 2 Accent 3;\lsdpriority67 \lsdlocked0 Medium Grid 1 Accent 3;\lsdpriority68 \lsdlocked0 Medium Grid 2 Accent 3;\lsdpriority69 \lsdlocked0 Medium Grid 3 Accent 3;
\lsdpriority70 \lsdlocked0 Dark List Accent 3;\lsdpriority71 \lsdlocked0 Colorful Shading Accent 3;\lsdpriority72 \lsdlocked0 Colorful List Accent 3;\lsdpriority73 \lsdlocked0 Colorful Grid Accent 3;\lsdpriority60 \lsdlocked0 Light Shading Accent 4;
\lsdpriority61 \lsdlocked0 Light List Accent 4;\lsdpriority62 \lsdlocked0 Light Grid Accent 4;\lsdpriority63 \lsdlocked0 Medium Shading 1 Accent 4;\lsdpriority64 \lsdlocked0 Medium Shading 2 Accent 4;\lsdpriority65 \lsdlocked0 Medium List 1 Accent 4;
\lsdpriority66 \lsdlocked0 Medium List 2 Accent 4;\lsdpriority67 \lsdlocked0 Medium Grid 1 Accent 4;\lsdpriority68 \lsdlocked0 Medium Grid 2 Accent 4;\lsdpriority69 \lsdlocked0 Medium Grid 3 Accent 4;\lsdpriority70 \lsdlocked0 Dark List Accent 4;
\lsdpriority71 \lsdlocked0 Colorful Shading Accent 4;\lsdpriority72 \lsdlocked0 Colorful List Accent 4;\lsdpriority73 \lsdlocked0 Colorful Grid Accent 4;\lsdpriority60 \lsdlocked0 Light Shading Accent 5;\lsdpriority61 \lsdlocked0 Light List Accent 5;
\lsdpriority62 \lsdlocked0 Light Grid Accent 5;\lsdpriority63 \lsdlocked0 Medium Shading 1 Accent 5;\lsdpriority64 \lsdlocked0 Medium Shading 2 Accent 5;\lsdpriority65 \lsdlocked0 Medium List 1 Accent 5;\lsdpriority66 \lsdlocked0 Medium List 2 Accent 5;
\lsdpriority67 \lsdlocked0 Medium Grid 1 Accent 5;\lsdpriority68 \lsdlocked0 Medium Grid 2 Accent 5;\lsdpriority69 \lsdlocked0 Medium Grid 3 Accent 5;\lsdpriority70 \lsdlocked0 Dark List Accent 5;\lsdpriority71 \lsdlocked0 Colorful Shading Accent 5;
\lsdpriority72 \lsdlocked0 Colorful List Accent 5;\lsdpriority73 \lsdlocked0 Colorful Grid Accent 5;\lsdpriority60 \lsdlocked0 Light Shading Accent 6;\lsdpriority61 \lsdlocked0 Light List Accent 6;\lsdpriority62 \lsdlocked0 Light Grid Accent 6;
\lsdpriority63 \lsdlocked0 Medium Shading 1 Accent 6;\lsdpriority64 \lsdlocked0 Medium Shading 2 Accent 6;\lsdpriority65 \lsdlocked0 Medium List 1 Accent 6;\lsdpriority66 \lsdlocked0 Medium List 2 Accent 6;
\lsdpriority67 \lsdlocked0 Medium Grid 1 Accent 6;\lsdpriority68 \lsdlocked0 Medium Grid 2 Accent 6;\lsdpriority69 \lsdlocked0 Medium Grid 3 Accent 6;\lsdpriority70 \lsdlocked0 Dark List Accent 6;\lsdpriority71 \lsdlocked0 Colorful Shading Accent 6;
\lsdpriority72 \lsdlocked0 Colorful List Accent 6;\lsdpriority73 \lsdlocked0 Colorful Grid Accent 6;\lsdqformat1 \lsdpriority19 \lsdlocked0 Subtle Emphasis;\lsdqformat1 \lsdpriority21 \lsdlocked0 Intense Emphasis;
\lsdqformat1 \lsdpriority31 \lsdlocked0 Subtle Reference;\lsdqformat1 \lsdpriority32 \lsdlocked0 Intense Reference;\lsdqformat1 \lsdpriority33 \lsdlocked0 Book Title;\lsdsemihidden1 \lsdunhideused1 \lsdpriority37 \lsdlocked0 Bibliography;
\lsdsemihidden1 \lsdunhideused1 \lsdqformat1 \lsdpriority39 \lsdlocked0 TOC Heading;\lsdpriority41 \lsdlocked0 Plain Table 1;\lsdpriority42 \lsdlocked0 Plain Table 2;\lsdpriority43 \lsdlocked0 Plain Table 3;\lsdpriority44 \lsdlocked0 Plain Table 4;
\lsdpriority45 \lsdlocked0 Plain Table 5;\lsdpriority40 \lsdlocked0 Grid Table Light;\lsdpriority46 \lsdlocked0 Grid Table 1 Light;\lsdpriority47 \lsdlocked0 Grid Table 2;\lsdpriority48 \lsdlocked0 Grid Table 3;\lsdpriority49 \lsdlocked0 Grid Table 4;
\lsdpriority50 \lsdlocked0 Grid Table 5 Dark;\lsdpriority51 \lsdlocked0 Grid Table 6 Colorful;\lsdpriority52 \lsdlocked0 Grid Table 7 Colorful;\lsdpriority46 \lsdlocked0 Grid Table 1 Light Accent 1;\lsdpriority47 \lsdlocked0 Grid Table 2 Accent 1;
\lsdpriority48 \lsdlocked0 Grid Table 3 Accent 1;\lsdpriority49 \lsdlocked0 Grid Table 4 Accent 1;\lsdpriority50 \lsdlocked0 Grid Table 5 Dark Accent 1;\lsdpriority51 \lsdlocked0 Grid Table 6 Colorful Accent 1;
\lsdpriority52 \lsdlocked0 Grid Table 7 Colorful Accent 1;\lsdpriority46 \lsdlocked0 Grid Table 1 Light Accent 2;\lsdpriority47 \lsdlocked0 Grid Table 2 Accent 2;\lsdpriority48 \lsdlocked0 Grid Table 3 Accent 2;
\lsdpriority49 \lsdlocked0 Grid Table 4 Accent 2;\lsdpriority50 \lsdlocked0 Grid Table 5 Dark Accent 2;\lsdpriority51 \lsdlocked0 Grid Table 6 Colorful Accent 2;\lsdpriority52 \lsdlocked0 Grid Table 7 Colorful Accent 2;
\lsdpriority46 \lsdlocked0 Grid Table 1 Light Accent 3;\lsdpriority47 \lsdlocked0 Grid Table 2 Accent 3;\lsdpriority48 \lsdlocked0 Grid Table 3 Accent 3;\lsdpriority49 \lsdlocked0 Grid Table 4 Accent 3;
\lsdpriority50 \lsdlocked0 Grid Table 5 Dark Accent 3;\lsdpriority51 \lsdlocked0 Grid Table 6 Colorful Accent 3;\lsdpriority52 \lsdlocked0 Grid Table 7 Colorful Accent 3;\lsdpriority46 \lsdlocked0 Grid Table 1 Light Accent 4;
\lsdpriority47 \lsdlocked0 Grid Table 2 Accent 4;\lsdpriority48 \lsdlocked0 Grid Table 3 Accent 4;\lsdpriority49 \lsdlocked0 Grid Table 4 Accent 4;\lsdpriority50 \lsdlocked0 Grid Table 5 Dark Accent 4;
\lsdpriority51 \lsdlocked0 Grid Table 6 Colorful Accent 4;\lsdpriority52 \lsdlocked0 Grid Table 7 Colorful Accent 4;\lsdpriority46 \lsdlocked0 Grid Table 1 Light Accent 5;\lsdpriority47 \lsdlocked0 Grid Table 2 Accent 5;
\lsdpriority48 \lsdlocked0 Grid Table 3 Accent 5;\lsdpriority49 \lsdlocked0 Grid Table 4 Accent 5;\lsdpriority50 \lsdlocked0 Grid Table 5 Dark Accent 5;\lsdpriority51 \lsdlocked0 Grid Table 6 Colorful Accent 5;
\lsdpriority52 \lsdlocked0 Grid Table 7 Colorful Accent 5;\lsdpriority46 \lsdlocked0 Grid Table 1 Light Accent 6;\lsdpriority47 \lsdlocked0 Grid Table 2 Accent 6;\lsdpriority48 \lsdlocked0 Grid Table 3 Accent 6;
\lsdpriority49 \lsdlocked0 Grid Table 4 Accent 6;\lsdpriority50 \lsdlocked0 Grid Table 5 Dark Accent 6;\lsdpriority51 \lsdlocked0 Grid Table 6 Colorful Accent 6;\lsdpriority52 \lsdlocked0 Grid Table 7 Colorful Accent 6;
\lsdpriority46 \lsdlocked0 List Table 1 Light;\lsdpriority47 \lsdlocked0 List Table 2;\lsdpriority48 \lsdlocked0 List Table 3;\lsdpriority49 \lsdlocked0 List Table 4;\lsdpriority50 \lsdlocked0 List Table 5 Dark;
\lsdpriority51 \lsdlocked0 List Table 6 Colorful;\lsdpriority52 \lsdlocked0 List Table 7 Colorful;\lsdpriority46 \lsdlocked0 List Table 1 Light Accent 1;\lsdpriority47 \lsdlocked0 List Table 2 Accent 1;\lsdpriority48 \lsdlocked0 List Table 3 Accent 1;
\lsdpriority49 \lsdlocked0 List Table 4 Accent 1;\lsdpriority50 \lsdlocked0 List Table 5 Dark Accent 1;\lsdpriority51 \lsdlocked0 List Table 6 Colorful Accent 1;\lsdpriority52 \lsdlocked0 List Table 7 Colorful Accent 1;
\lsdpriority46 \lsdlocked0 List Table 1 Light Accent 2;\lsdpriority47 \lsdlocked0 List Table 2 Accent 2;\lsdpriority48 \lsdlocked0 List Table 3 Accent 2;\lsdpriority49 \lsdlocked0 List Table 4 Accent 2;
\lsdpriority50 \lsdlocked0 List Table 5 Dark Accent 2;\lsdpriority51 \lsdlocked0 List Table 6 Colorful Accent 2;\lsdpriority52 \lsdlocked0 List Table 7 Colorful Accent 2;\lsdpriority46 \lsdlocked0 List Table 1 Light Accent 3;
\lsdpriority47 \lsdlocked0 List Table 2 Accent 3;\lsdpriority48 \lsdlocked0 List Table 3 Accent 3;\lsdpriority49 \lsdlocked0 List Table 4 Accent 3;\lsdpriority50 \lsdlocked0 List Table 5 Dark Accent 3;
\lsdpriority51 \lsdlocked0 List Table 6 Colorful Accent 3;\lsdpriority52 \lsdlocked0 List Table 7 Colorful Accent 3;\lsdpriority46 \lsdlocked0 List Table 1 Light Accent 4;\lsdpriority47 \lsdlocked0 List Table 2 Accent 4;
\lsdpriority48 \lsdlocked0 List Table 3 Accent 4;\lsdpriority49 \lsdlocked0 List Table 4 Accent 4;\lsdpriority50 \lsdlocked0 List Table 5 Dark Accent 4;\lsdpriority51 \lsdlocked0 List Table 6 Colorful Accent 4;
\lsdpriority52 \lsdlocked0 List Table 7 Colorful Accent 4;\lsdpriority46 \lsdlocked0 List Table 1 Light Accent 5;\lsdpriority47 \lsdlocked0 List Table 2 Accent 5;\lsdpriority48 \lsdlocked0 List Table 3 Accent 5;
\lsdpriority49 \lsdlocked0 List Table 4 Accent 5;\lsdpriority50 \lsdlocked0 List Table 5 Dark Accent 5;\lsdpriority51 \lsdlocked0 List Table 6 Colorful Accent 5;\lsdpriority52 \lsdlocked0 List Table 7 Colorful Accent 5;
\lsdpriority46 \lsdlocked0 List Table 1 Light Accent 6;\lsdpriority47 \lsdlocked0 List Table 2 Accent 6;\lsdpriority48 \lsdlocked0 List Table 3 Accent 6;\lsdpriority49 \lsdlocked0 List Table 4 Accent 6;
\lsdpriority50 \lsdlocked0 List Table 5 Dark Accent 6;\lsdpriority51 \lsdlocked0 List Table 6 Colorful Accent 6;\lsdpriority52 \lsdlocked0 List Table 7 Colorful Accent 6;\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 Mention;
\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 Smart Hyperlink;\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 Hashtag;\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 Unresolved Mention;\lsdsemihidden1 \lsdunhideused1 \lsdlocked0 Smart Link;}}{\*\datastore 01050000
02000000180000004d73786d6c322e534158584d4c5265616465722e362e3000000000000000000000060000
d0cf11e0a1b11ae1000000000000000000000000000000003e000300feff090006000000000000000000000001000000010000000000000000100000feffffff00000000feffffff0000000000000000ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
fffffffffffffffffdfffffffeffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
ffffffffffffffffffffffffffffffff52006f006f007400200045006e00740072007900000000000000000000000000000000000000000000000000000000000000000000000000000000000000000016000500ffffffffffffffffffffffff0c6ad98892f1d411a65f0040963251e50000000000000000000000008085
95fddd98da01feffffff00000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000ffffffffffffffffffffffff00000000000000000000000000000000000000000000000000000000
00000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000ffffffffffffffffffffffff0000000000000000000000000000000000000000000000000000
000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000ffffffffffffffffffffffff000000000000000000000000000000000000000000000000
0000000000000000000000000000000000000000000000000105000000000000}}